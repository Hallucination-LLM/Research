{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T07:36:13.808050Z",
     "iopub.status.busy": "2024-08-25T07:36:13.807429Z",
     "iopub.status.idle": "2024-08-25T07:36:17.927601Z",
     "shell.execute_reply": "2024-08-25T07:36:17.926713Z",
     "shell.execute_reply.started": "2024-08-25T07:36:13.808010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad-kielczynski/miniconda3/envs/golem-ner/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will load our standard `unsloth/gemma-2-9b-it-bnb-4bit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID = \"unsloth/gemma-2-9b-it-bnb-4bit\"\n",
    "DTYPE = torch.float16\n",
    "LOAD_IN_4BIT = True\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T05:33:23.262495Z",
     "iopub.status.busy": "2024-08-24T05:33:23.259909Z",
     "iopub.status.idle": "2024-08-24T05:34:08.555677Z",
     "shell.execute_reply": "2024-08-24T05:34:08.553960Z",
     "shell.execute_reply.started": "2024-08-24T05:33:23.262444Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=os.environ[\"HF_TOKEN\"])\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map={\"\": device},\n",
    "    torch_dtype=DTYPE,\n",
    "    token=os.environ[\"HF_TOKEN\"],\n",
    "    use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_tokenizer = {v: k for k, v in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(text, model, tokenizer, device):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        outputs = model(\n",
    "            **inputs,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6724,  0.1553,  0.4824,  ..., -0.0379,  0.2595,  0.1982],\n",
       "          [ 1.3672,  1.5127,  0.4058,  ...,  1.3301, -2.4414, -1.9883],\n",
       "          [-0.7710,  1.8643, -0.4275,  ..., -0.3965, -0.9429, -0.8662],\n",
       "          [ 1.4619,  0.8149,  0.1028,  ...,  1.9004,  0.1041, -1.5205],\n",
       "          [-0.0482, -1.0449, -2.5137,  ...,  1.4326,  0.6250,  0.7710],\n",
       "          [-0.7124, -1.0889, -0.5918,  ...,  0.3984,  1.2354, -0.3381]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.2334, -1.9648, -0.0709,  ..., -0.1409,  0.0360,  0.2175],\n",
       "          [ 2.2305,  5.3086,  0.6084,  ...,  1.1104, -0.8760, -1.8389],\n",
       "          [-0.1729,  1.9502, -0.1769,  ..., -0.0920, -0.2434, -0.2148],\n",
       "          [ 0.9985,  3.2012, -0.4641,  ...,  1.0625,  0.8628, -1.0742],\n",
       "          [ 0.1587,  2.9277, -1.7773,  ...,  0.6489,  1.4004,  0.1431],\n",
       "          [-0.6655,  2.4609, -0.4707,  ..., -0.0349,  1.4053, -0.5127]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.1033, -3.3652, -0.0719,  ..., -0.0399,  0.3989,  0.4548],\n",
       "          [ 2.5293,  4.0273,  0.0718,  ...,  1.1836, -0.9248, -1.3711],\n",
       "          [-0.1237,  0.7139, -0.1560,  ...,  0.2319, -0.3018,  0.1691],\n",
       "          [ 0.6768,  2.5898, -0.2322,  ...,  1.1943,  0.6172, -0.9253],\n",
       "          [-0.1876,  2.0566, -1.5244,  ...,  1.1055,  0.8911, -0.4746],\n",
       "          [-0.5693,  2.3770, -0.4856,  ..., -0.0048,  0.9023, -0.0522]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.0393, -1.9512, -0.4165,  ..., -0.3584,  0.5073,  0.1008],\n",
       "          [ 2.6289,  3.8301, -0.8062,  ...,  1.3193, -0.8672, -1.0205],\n",
       "          [ 0.1759,  0.0824, -0.0972,  ..., -0.5752, -0.3167,  0.8506],\n",
       "          [ 0.6553,  1.4941, -1.1836,  ...,  0.3267,  0.1914, -0.6641],\n",
       "          [-0.3638,  0.4336, -1.5117,  ...,  1.4434,  0.6875, -0.0107],\n",
       "          [-0.4570,  3.0469, -1.6035,  ..., -0.0496,  0.4517, -1.0889]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.1774, -0.6440, -0.2177,  ..., -0.7954,  0.5742, -0.1910],\n",
       "          [ 2.2930,  4.0000, -1.3701,  ...,  1.0215, -0.2461, -1.0410],\n",
       "          [ 1.7266,  0.7959, -1.8008,  ...,  0.1345, -0.8584,  0.4934],\n",
       "          [ 0.7734,  2.0078, -2.0391,  ...,  0.5942,  0.1768, -1.0684],\n",
       "          [-0.8193,  0.4819, -1.8916,  ...,  1.2559,  1.0947, -0.9619],\n",
       "          [ 0.8608,  1.7852, -1.2383,  ..., -0.0678,  1.3750, -0.8877]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 0.0694, -0.0612, -0.1858,  ..., -0.5010,  0.1523, -0.1310],\n",
       "          [ 1.9062,  2.4316, -1.7207,  ...,  0.3816,  0.0132, -1.1709],\n",
       "          [ 1.2129,  0.1321, -2.4160,  ..., -0.0747, -0.3379,  0.2910],\n",
       "          [ 0.6670,  1.9082, -3.1230,  ..., -0.3281,  0.1753, -0.3979],\n",
       "          [-1.7559,  0.3076, -2.8477,  ...,  1.4717,  1.9707, -1.0967],\n",
       "          [ 0.2393,  1.1035, -1.6543,  ...,  0.4771,  2.2383, -1.2725]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-9.8694e-02,  2.8662e-01, -2.5146e-01,  ..., -5.2734e-01,\n",
       "            6.7285e-01, -5.4004e-01],\n",
       "          [ 1.6992e+00,  3.2871e+00, -4.4688e+00,  ...,  4.1504e-03,\n",
       "           -1.1572e-01, -9.4727e-01],\n",
       "          [ 2.4258e+00,  4.9805e-02, -4.0977e+00,  ..., -9.4922e-01,\n",
       "           -4.0820e-01,  4.5654e-02],\n",
       "          [ 4.3774e-01,  4.3984e+00, -2.7930e+00,  ...,  3.3521e-01,\n",
       "            5.2734e-02, -5.2490e-01],\n",
       "          [-2.0684e+00,  6.9922e-01, -1.7480e+00,  ...,  1.5225e+00,\n",
       "            1.2803e+00, -1.0186e+00],\n",
       "          [ 2.3096e-01,  5.3711e-01, -3.8232e-01,  ...,  2.4414e-01,\n",
       "            2.1836e+00, -1.4971e+00]]], device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.4280, -0.4766, -0.4478,  ..., -0.5239,  0.8867, -0.9150],\n",
       "          [ 1.5469,  3.4707, -3.7051,  ..., -0.1973, -0.7637, -0.3916],\n",
       "          [ 2.5039, -1.1055, -3.3184,  ..., -1.3086, -1.3252,  0.4629],\n",
       "          [-0.9580,  2.9844, -1.8574,  ...,  0.3372,  0.9668,  0.1172],\n",
       "          [-1.2344, -1.7070, -0.0576,  ...,  3.1367,  2.1133, -2.0273],\n",
       "          [ 0.6729, -2.8828,  0.8994,  ...,  1.7412,  2.8145, -1.7412]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-1.1826, -0.6440, -1.5439,  ..., -0.3203,  0.8809, -1.5889],\n",
       "          [ 1.8975,  3.4590, -4.1953,  ..., -0.5527, -0.2134, -0.4536],\n",
       "          [ 3.3770,  0.5605, -4.5156,  ..., -0.9214, -1.1416, -0.4199],\n",
       "          [-0.7798,  3.9766, -2.4609,  ...,  1.2344,  0.7412, -1.0449],\n",
       "          [-1.8652, -1.4062, -0.5254,  ...,  2.7324,  2.4297, -2.7207],\n",
       "          [ 0.1641, -1.5869,  1.2305,  ...,  1.0918,  1.9102, -1.8857]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.7432, -0.6787, -2.2051,  ..., -0.5210,  0.5869, -1.5947],\n",
       "          [ 1.5186,  6.4219, -3.4219,  ..., -1.0459,  0.4624,  1.1621],\n",
       "          [ 3.5000,  1.0996, -3.8887,  ..., -0.2178, -1.8652, -0.4873],\n",
       "          [-0.9741,  3.3535, -1.8398,  ...,  0.6626,  1.2422, -2.9141],\n",
       "          [-3.2500, -1.3711, -1.9941,  ...,  3.3789,  2.2227, -3.1191],\n",
       "          [-0.0080, -1.5947,  1.3193,  ...,  1.4375,  0.8594, -2.4258]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.7393, -0.7725, -3.6680,  ..., -0.7773,  0.7744, -2.9570],\n",
       "          [ 1.5859,  5.7539, -2.9453,  ..., -0.8921,  0.5161,  1.2949],\n",
       "          [ 2.5957,  1.7969, -3.5566,  ...,  0.8779, -2.6914, -1.2529],\n",
       "          [-1.5898,  3.0996, -1.6465,  ...,  0.8882,  0.3164, -3.8301],\n",
       "          [-2.8008, -0.5420, -2.9629,  ...,  4.3203,  2.2188, -4.1367],\n",
       "          [-0.6367, -0.7451,  0.2803,  ...,  1.5068,  1.2627, -3.2148]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.5225, -0.3003, -3.9844,  ..., -0.4248,  0.9707, -2.7715],\n",
       "          [ 0.8613,  4.6523, -3.3711,  ..., -0.0093, -0.1299,  2.3574],\n",
       "          [ 1.9902,  2.1953, -4.7656,  ...,  1.9492, -2.4512,  0.5898],\n",
       "          [-3.0781,  2.5391, -2.6191,  ...,  0.6592,  1.6318, -2.0098],\n",
       "          [-2.2637, -0.0820, -3.4297,  ...,  3.8047,  1.4805, -3.1562],\n",
       "          [-0.4736, -0.1987,  0.3411,  ...,  1.6016,  1.4512, -1.9102]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.3269,  0.5850, -4.1016,  ...,  0.6426,  0.9360, -3.0215],\n",
       "          [ 1.4365,  3.9648, -2.4023,  ..., -0.4919,  1.6982,  1.8447],\n",
       "          [ 2.6582,  1.0273, -4.9336,  ...,  0.7778, -2.6133,  1.8223],\n",
       "          [-2.0137,  0.6963, -2.5586,  ...,  0.1907,  0.3809, -0.4170],\n",
       "          [-1.3066, -0.6104, -3.6875,  ...,  3.8340,  0.2217, -1.9043],\n",
       "          [ 0.1619, -0.4028,  0.2773,  ...,  0.8848,  0.7451, -0.5889]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.2620, -1.3320, -3.9316,  ...,  0.4041,  0.5498, -3.0527],\n",
       "          [ 0.5933,  2.1406, -2.5977,  ..., -1.1846,  2.5703,  2.2480],\n",
       "          [ 2.1152,  0.1857, -5.2148,  ...,  0.8916, -2.1953,  2.5137],\n",
       "          [-3.7422, -0.7051, -2.6484,  ...,  0.6172,  0.9385, -0.4458],\n",
       "          [-3.0625, -1.1133, -3.4473,  ...,  5.4727,  1.2139, -0.8818],\n",
       "          [-1.6094, -1.3701,  0.8267,  ...,  1.9854,  1.7969,  0.7065]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 0.2294, -0.9204, -3.7598,  ...,  1.5430,  0.3242, -3.3359],\n",
       "          [ 1.7959,  2.9453, -1.5605,  ..., -2.0664,  3.5020,  1.3643],\n",
       "          [ 1.6621, -0.2883, -5.8984,  ...,  0.0881, -0.5811,  2.5488],\n",
       "          [-3.8652, -0.7129, -2.7871,  ..., -0.4106,  1.8145,  0.9238],\n",
       "          [-4.8242,  1.0098, -4.8281,  ...,  4.5859,  1.0674, -0.0771],\n",
       "          [-2.1543, -0.2407,  0.1597,  ...,  1.7217,  2.8398,  1.0430]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 0.9004, -1.6533, -3.9590,  ...,  0.1892,  0.8638, -4.5703],\n",
       "          [ 1.9746,  1.3672, -0.8984,  ..., -2.6445,  4.5742,  2.0059],\n",
       "          [ 1.7969, -0.2939, -6.9844,  ..., -1.6885,  0.0918,  2.5273],\n",
       "          [-4.1289, -1.6875, -3.8145,  ..., -0.7617,  2.0117,  0.5205],\n",
       "          [-4.1914,  0.2423, -5.0117,  ...,  3.5020,  3.5469,  0.1458],\n",
       "          [-1.7295, -0.4316,  0.8828,  ...,  0.2192,  5.0156,  0.3110]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 0.6826, -0.3369, -3.2520,  ...,  0.0801,  0.7266, -3.5039],\n",
       "          [ 1.2725,  1.1338,  0.3044,  ..., -0.2188,  6.4375,  3.6504],\n",
       "          [ 1.9912, -0.0342, -7.4062,  ..., -1.8223,  0.5713,  2.4766],\n",
       "          [-4.8906, -2.5703, -3.9180,  ..., -1.1035,  1.6494,  0.9463],\n",
       "          [-4.7578,  0.8755, -5.8984,  ...,  4.1172,  2.7305, -0.2095],\n",
       "          [-2.8867, -0.0104,  0.7676,  ...,  1.1904,  4.3984, -0.3459]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 0.7837,  0.6650, -2.3672,  ...,  0.6465,  1.0605, -3.8555],\n",
       "          [ 0.3105,  0.5459,  2.5684,  ..., -1.0117,  7.2773,  4.9922],\n",
       "          [ 2.2559, -1.2617, -8.3906,  ..., -0.7451,  0.3962,  2.9180],\n",
       "          [-3.7520, -1.6572, -4.8047,  ..., -3.3281,  1.6250,  1.5176],\n",
       "          [-1.4766,  1.0596, -6.0078,  ...,  1.4414,  1.9502, -0.0705],\n",
       "          [-0.5684, -1.3096,  0.8770,  ...,  0.5884,  3.6523,  0.3462]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 0.5601,  0.3699, -1.5664,  ...,  0.2505,  0.3887, -3.8535],\n",
       "          [ 2.6445,  0.1182,  4.3359,  ..., -1.0742,  8.3984,  4.8867],\n",
       "          [ 2.1934, -1.4043, -9.0156,  ...,  0.6274,  0.4272,  3.4238],\n",
       "          [-2.7793, -3.4805, -4.7148,  ..., -2.0703,  1.4639,  1.2305],\n",
       "          [-1.6016,  0.0186, -5.8008,  ...,  1.6973,  0.3193, -1.3359],\n",
       "          [ 0.5547, -1.1045,  1.4668,  ..., -0.6187,  2.2891, -0.5596]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 1.2080e+00, -8.4180e-01, -1.2305e+00,  ...,  4.4629e-01,\n",
       "            4.3164e-01, -3.3652e+00],\n",
       "          [ 3.0664e+00, -6.6162e-01,  4.3984e+00,  ..., -1.4990e+00,\n",
       "            8.1719e+00,  5.1445e+00],\n",
       "          [ 2.1758e+00, -1.7090e+00, -8.9609e+00,  ...,  4.0405e-01,\n",
       "            9.7021e-01,  4.0547e+00],\n",
       "          [-2.3281e+00, -2.8633e+00, -4.6367e+00,  ..., -1.3330e+00,\n",
       "            1.0674e+00,  2.0605e+00],\n",
       "          [ 1.1191e+00,  7.9346e-04, -5.9414e+00,  ...,  1.0361e+00,\n",
       "            1.1621e+00, -1.6367e+00],\n",
       "          [ 2.3242e+00, -1.1875e+00,  7.1094e-01,  ..., -1.6406e+00,\n",
       "            3.3750e+00, -8.5742e-01]]], device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 1.0498, -1.1650, -1.1514,  ..., -0.2749,  0.9629, -3.3945],\n",
       "          [ 2.6074, -0.5063,  4.7188,  ..., -1.7891,  9.0234,  4.8828],\n",
       "          [ 3.1289, -1.2559, -8.4141,  ...,  0.0208,  1.6768,  4.2852],\n",
       "          [-0.5850, -0.4678, -4.7383,  ..., -2.2344,  0.9546,  1.8447],\n",
       "          [ 1.1699,  3.6582, -6.2031,  ...,  1.4668,  0.9272, -0.6616],\n",
       "          [ 2.0312,  0.2041,  0.1177,  ..., -3.5098,  2.2969, -0.3210]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 2.0820, -1.5215, -0.2358,  ..., -1.4404,  2.2598, -3.4824],\n",
       "          [ 2.3086, -0.1815,  5.1250,  ..., -1.4023,  8.9141,  4.8906],\n",
       "          [ 4.6133, -0.4219, -7.9141,  ..., -0.5039,  2.6992,  4.7266],\n",
       "          [ 1.5469,  0.0161, -3.5449,  ..., -2.2246,  2.5391,  2.7148],\n",
       "          [ 0.9888,  4.0352, -5.3789,  ...,  2.4746,  2.6133, -1.1279],\n",
       "          [ 2.7871,  1.0762,  0.9863,  ..., -2.6406,  4.0430,  0.4656]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 1.6211, -2.3164, -0.0988,  ..., -1.8525,  1.9297, -1.7578],\n",
       "          [ 2.0957, -0.0658,  5.3164,  ..., -2.4316,  8.6172,  5.7969],\n",
       "          [ 4.0078, -1.7109, -7.4375,  ..., -0.7388,  2.7656,  5.8750],\n",
       "          [ 2.8418,  0.0933, -3.6113,  ..., -2.2422,  3.3633,  2.7148],\n",
       "          [ 2.1191,  2.6875, -5.1328,  ...,  2.4727,  2.3359, -1.5449],\n",
       "          [ 3.0137,  1.9053,  1.1592,  ..., -2.1641,  4.5625,  0.1025]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 1.4297, -2.7422, -0.3301,  ..., -3.1523,  2.4648, -0.6133],\n",
       "          [ 1.7744, -1.1787,  4.4531,  ..., -2.7031,  7.7734,  6.1016],\n",
       "          [ 4.0156, -0.5625, -8.5625,  ..., -1.3340,  1.8604,  4.9922],\n",
       "          [ 1.7080, -1.5684, -4.0898,  ...,  0.5039,  1.6680,  0.8652],\n",
       "          [ 1.3877,  1.3691, -5.3789,  ...,  2.1152, -1.1699, -2.6133],\n",
       "          [ 3.1875, -0.4580,  1.4062,  ..., -1.9014,  1.8633, -0.8823]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 0.7222, -2.0020, -0.0481,  ..., -1.9453,  2.6621, -1.2656],\n",
       "          [ 1.0938, -2.2578,  4.0039,  ..., -1.3203,  6.7109,  6.3633],\n",
       "          [ 8.1172, -0.8281, -8.7969,  ..., -0.5757,  2.3535,  4.5938],\n",
       "          [ 1.5752, -0.7793, -4.2344,  ...,  1.1533,  2.0586,  1.2100],\n",
       "          [ 1.9297, -0.5303, -5.3828,  ...,  0.6992, -1.1250, -3.0234],\n",
       "          [ 4.5156, -1.7559,  1.3242,  ..., -1.2158,  1.4062, -1.2393]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 2.5781,  0.8545, -1.4648,  ...,  0.6499,  2.0195, -2.7754],\n",
       "          [ 0.0908, -3.2383,  4.1250,  ...,  0.0903,  5.4141,  4.9023],\n",
       "          [ 6.2031, -2.8359, -8.5000,  ..., -2.9453, -0.9961,  5.3867],\n",
       "          [-0.5215, -2.4844, -3.2031,  ..., -0.2627,  2.9648,  0.4744],\n",
       "          [ 0.1045, -1.2891, -4.9648,  ..., -1.8525, -0.7939, -4.9258],\n",
       "          [ 2.9727, -2.5156,  1.5283,  ..., -1.7783,  0.8291, -1.8984]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 2.4355,  2.3242, -2.5684,  ...,  3.3672,  1.2783, -4.2500],\n",
       "          [-0.1790, -2.6270,  3.4980,  ..., -0.9180,  5.2188,  4.6055],\n",
       "          [ 8.6016, -2.5059, -8.6094,  ..., -3.4961, -3.4219,  5.8398],\n",
       "          [ 2.1152, -4.3242, -2.3145,  ..., -0.6504,  3.5859,  3.5566],\n",
       "          [ 2.4180, -3.0664, -4.5781,  ..., -3.4219, -0.4028, -4.5430],\n",
       "          [ 4.0508, -2.2480,  2.4316,  ..., -3.3926,  2.1055, -2.3105]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 2.5039, -0.0273, -2.6602,  ...,  3.2949,  2.2988, -2.8555],\n",
       "          [-0.5854, -0.1465,  0.8447,  ..., -0.1338,  3.2949,  2.4062],\n",
       "          [ 9.0000, -4.4375, -9.4141,  ..., -3.6973, -1.5635,  7.7500],\n",
       "          [ 9.3906, -3.2676, -3.8535,  ..., -2.4453,  5.4492,  2.0273],\n",
       "          [ 4.1523, -3.4629, -5.2656,  ..., -4.4570,  0.5679, -4.5547],\n",
       "          [ 4.3281, -4.6719,  1.8564,  ..., -3.9375,  0.8203, -0.4365]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 2.3359, -1.0430,  0.6299,  ...,  2.3340,  2.3945, -2.2090],\n",
       "          [ 0.1567, -0.3550,  1.1035,  ..., -1.4160,  1.1621,  0.5654],\n",
       "          [ 6.2656, -5.1797, -8.7266,  ..., -2.6660, -0.0820,  3.3398],\n",
       "          [ 7.5312, -4.1016, -3.3125,  ..., -2.7930,  6.6641, -1.2852],\n",
       "          [ 6.3594, -2.1895, -3.3750,  ..., -0.7344,  3.9453, -6.0547],\n",
       "          [ 3.0371, -5.9219,  0.6143,  ..., -5.0938, -0.7334, -0.0624]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 3.1797, -1.7598,  1.1133,  ...,  1.5498,  0.8418, -2.0684],\n",
       "          [-0.2100, -1.3750, -0.4268,  ..., -0.8604, -0.3640, -0.0264],\n",
       "          [12.5234, -2.5801, -9.4922,  ..., -4.2148,  2.3750,  2.8398],\n",
       "          [ 9.7734, -1.9941, -2.3125,  ..., -1.7412,  7.8984, -2.1133],\n",
       "          [ 8.9844, -0.6592, -2.5508,  ..., -4.1016,  4.0586, -3.7266],\n",
       "          [ 2.3535, -5.9023,  0.0555,  ..., -5.9062,  1.2021, -1.4492]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[  0.7808,  -1.9785,   1.0625,  ...,   1.1152,   1.1445,  -3.7695],\n",
       "          [ -0.4285,  -0.4321,  -0.8516,  ...,  -0.4597,  -0.6885,   0.4473],\n",
       "          [ 14.2031,  -0.7295, -14.2891,  ...,  -5.9062,   2.3574,   1.5908],\n",
       "          [  9.5391,  -1.0654,  -5.8828,  ...,  -3.5059,   6.7305,  -1.6270],\n",
       "          [ 11.0469,   2.3438,  -5.6992,  ...,  -2.9844,   4.5664,  -1.6992],\n",
       "          [  5.3125,  -2.7930,  -2.2266,  ...,  -4.5664,  -0.0410,  -2.0352]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[  0.9883,  -0.7920,   0.7290,  ...,   0.9927,   1.1309,  -1.9189],\n",
       "          [  0.0928,  -1.1660,  -1.4707,  ...,  -1.0625,   0.4741,  -0.0618],\n",
       "          [ 13.0547,  -0.1724, -14.1094,  ...,  -3.0957,   4.3125,  -1.2285],\n",
       "          [  6.7422,  -1.4707,  -5.7969,  ...,  -0.7812,   6.2734,  -2.4707],\n",
       "          [  9.3594,   2.6914,  -5.7422,  ...,  -0.9795,   2.7891,  -0.9409],\n",
       "          [  6.1680,  -1.2061,  -3.8535,  ...,  -6.0625,  -0.2430,  -0.3989]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 1.0664e+00,  1.1307e-02,  9.5264e-01,  ...,  5.5127e-01,\n",
       "            1.0264e+00, -1.7002e+00],\n",
       "          [ 3.5449e-01, -1.2861e+00, -6.9824e-01,  ..., -1.5293e+00,\n",
       "            1.5479e+00,  6.7822e-01],\n",
       "          [ 1.5398e+01,  8.3936e-01, -1.3039e+01,  ..., -4.2734e+00,\n",
       "            6.2227e+00, -1.9932e+00],\n",
       "          [ 5.2422e+00, -4.7422e+00, -2.8926e+00,  ..., -1.4844e-01,\n",
       "            9.0391e+00, -5.5664e+00],\n",
       "          [ 6.9180e+00,  1.0801e+00, -2.8750e+00,  ..., -2.5137e+00,\n",
       "            4.5195e+00, -1.5928e+00],\n",
       "          [ 7.1914e+00, -1.7188e+00, -4.1523e+00,  ..., -2.7676e+00,\n",
       "            8.2227e-01, -1.5098e+00]]], device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[  1.0361,  -1.2256,   1.4590,  ...,   0.7974,   1.7881,  -0.5190],\n",
       "          [  0.7114,  -1.0898,  -1.1934,  ...,  -2.3281,   2.2500,   1.2930],\n",
       "          [ 13.7109,  -1.4502, -14.5312,  ...,  -6.2266,   6.9062,  -3.6523],\n",
       "          [  4.9180,  -8.2812,  -4.8438,  ...,  -2.2969,   8.7969,  -4.8711],\n",
       "          [  6.5781,   2.0547,  -4.0234,  ...,  -1.1523,   5.3164,  -3.3828],\n",
       "          [  7.4258,  -4.6641,  -4.6016,  ...,  -3.9375,   1.9258,  -1.3877]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[  1.0039,  -1.5625,   0.5562,  ...,   1.3721,   1.4727,  -0.9873],\n",
       "          [  0.4226,  -0.7827,  -1.7490,  ...,  -2.2441,   1.6221,   0.7227],\n",
       "          [ 12.4609,  -0.2031, -12.7500,  ...,  -3.0410,   5.6680,  -4.4688],\n",
       "          [  3.7578,  -6.9414,  -3.8828,  ...,   2.7363,   9.6484,  -8.2422],\n",
       "          [  3.6602,   4.0938,  -4.2266,  ...,   1.8594,   5.4805,  -3.4648],\n",
       "          [  5.3906,  -5.4922,  -3.6172,  ...,  -2.1699,   1.8672,  -0.1338]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[  0.5928,  -1.5586,  -0.3401,  ...,   0.1016,   1.2852,  -1.3926],\n",
       "          [  0.2241,  -0.5586,  -1.7246,  ...,  -1.5928,   1.8779,   0.9316],\n",
       "          [ 11.9297,   1.8418, -13.0078,  ...,   0.4727,   9.7891,  -4.9570],\n",
       "          [  1.8066,  -4.6172,  -1.9590,  ...,   2.4844,  11.4297,  -8.6406],\n",
       "          [  2.2266,   2.4023,  -2.4043,  ...,   2.7109,   7.3164,  -3.0469],\n",
       "          [  4.1289,  -7.2734,  -2.6855,  ...,  -1.1445,   3.7422,  -1.0615]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[  1.1367,  -0.1113,  -1.9316,  ...,  -0.8838,   1.8916,  -1.0488],\n",
       "          [  1.6758,  -1.4160,  -1.5410,  ...,  -1.3076,   1.2402,   0.4590],\n",
       "          [ 11.3594,   0.2588, -10.9844,  ...,  -0.0972,   9.4844,  -3.9668],\n",
       "          [  2.8516,  -2.4180,  -2.0703,  ...,   5.8477,  11.9844,  -9.9609],\n",
       "          [  4.7070,   1.5840,  -0.7891,  ...,   1.5059,   6.5469,  -7.9531],\n",
       "          [  6.8750, -10.3828,  -0.7383,  ...,  -0.4248,   4.2891,   0.2551]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 0.1133, -1.2402, -3.0332,  ..., -1.3994, -0.1299, -1.0322],\n",
       "          [ 1.9062, -0.7529, -1.9199,  ...,  0.1113,  1.0312,  0.0834],\n",
       "          [10.3359, -1.4756, -9.4531,  ...,  0.7241,  8.2734, -2.4336],\n",
       "          [ 1.2539, -2.4082, -0.9141,  ...,  6.1484,  9.5625, -9.4609],\n",
       "          [ 7.0469,  2.0645, -2.4688,  ...,  1.1143,  7.0273, -6.8984],\n",
       "          [ 8.7656, -8.9141, -0.8945,  ...,  1.6982,  7.1250, -0.1208]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[ 0.1104, -1.2637, -3.1211,  ..., -1.1816,  0.6274, -1.3887],\n",
       "          [ 0.3418, -0.0831, -2.4395,  ...,  0.2910,  0.2090,  0.3491],\n",
       "          [12.1875, -6.6719, -7.1445,  ...,  2.2559, 13.8594, -2.5859],\n",
       "          [-1.8105, -6.0938,  4.1562,  ...,  7.6562,  8.7188, -8.8125],\n",
       "          [ 8.4922,  3.3203, -1.7275,  ...,  5.6484,  5.5938, -6.2656],\n",
       "          [13.0781, -6.1914, -3.3242,  ...,  6.1250,  5.4844,  5.1445]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.8813,  0.3926, -1.1914,  ..., -0.5791, -3.0820,  0.9492],\n",
       "          [ 1.4531, -0.5234, -3.1289,  ..., -0.8291,  1.0645, -0.5039],\n",
       "          [15.7188, -4.2031, -7.9023,  ..., -0.4180, 13.1562, -1.9707],\n",
       "          [-1.3711, -3.5859,  2.2812,  ...,  5.2891,  8.0000, -2.9219],\n",
       "          [ 2.6914,  1.0762, -1.0859,  ...,  1.9570, 10.3281, -7.7148],\n",
       "          [12.0703, -8.0000, -1.7734,  ...,  4.2266,  7.1406,  7.1094]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.9097,  1.1914, -2.3516,  ..., -1.5176, -0.6914,  1.4688],\n",
       "          [ 2.3770, -0.6206, -3.7520,  ..., -0.1353,  1.1963, -0.5293],\n",
       "          [15.4688, -7.6484, -6.9570,  ...,  1.7109, 11.9609, -3.8555],\n",
       "          [-1.8809, -4.9570,  3.4766,  ...,  7.4609, 11.9062, -6.2266],\n",
       "          [ 3.7363,  2.7070, -6.0625,  ...,  5.4219, 12.8359, -5.6484],\n",
       "          [12.4844, -6.5703, -4.2031,  ..., -0.5518,  9.7656,  5.4766]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-3.8770,  0.7061,  1.8086,  ..., -0.9644, -1.6562, -0.0948],\n",
       "          [ 6.0547, -1.1445, -4.8984,  ...,  0.2429,  0.7764, -1.3398],\n",
       "          [12.7969, -9.6484,  3.2070,  ...,  2.0586,  4.0977, -8.6406],\n",
       "          [-3.6953, -2.6934, 10.8203,  ...,  4.7266, 11.8594, -9.0156],\n",
       "          [ 6.1250,  6.5977, -5.6406,  ..., -0.3770,  9.8281, -2.1387],\n",
       "          [14.8906, -9.7969, -4.9062,  ...,  0.4336,  4.7188,  3.8320]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[-0.2534, -0.0274, -0.0078,  ..., -0.0257, -0.1792,  0.0249],\n",
       "          [ 1.2715, -3.6504, -0.8027,  ...,  1.0938,  0.7422, -0.6899],\n",
       "          [ 0.5039, -2.4551,  1.2725,  ...,  0.3342,  0.5713, -0.6372],\n",
       "          [-0.5786, -0.7466,  1.4521,  ...,  0.0820,  0.6797, -0.3057],\n",
       "          [ 0.7739,  0.9365, -0.7666,  ..., -0.2991,  1.4629,  0.3894],\n",
       "          [ 1.3066, -2.5371, -0.8535,  ..., -0.7725,  0.2715,  1.0918]]],\n",
       "        device='cuda:0', dtype=torch.float16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = forward_pass(\"Hello, my name is\", model, tokenizer, device)\n",
    "\n",
    "output['hidden_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output['hidden_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_dict = {}\n",
    "\n",
    "for i, hidden_state in enumerate(output['hidden_states']):\n",
    "    logits = model.lm_head(hidden_state)\n",
    "    logits_dict[i] = logits\n",
    "\n",
    "logits_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 256000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premature_layer = 20\n",
    "\n",
    "logits_dict[premature_layer].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_logits = logits_dict[premature_layer][:, -1, :]\n",
    "\n",
    "base_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _relative_top_filter(\n",
    "    scores: torch.FloatTensor,\n",
    "    baseline_scores: torch.FloatTensor,\n",
    "    relative_top: float = 0.1,\n",
    "    filter_value: float = -float(\"Inf\"),\n",
    "    base_filter_value=-1e-3,\n",
    "    min_tokens_to_keep: int = 1,\n",
    ") -> torch.FloatTensor:\n",
    "    \"\"\"\n",
    "    Reference: https://github.com/XiangLi1999/ContrastiveDecoding/blob/170e9142e92159c1237d731e240f5eb14aabf428/transformers/src/transformers/generation_logits_process.py#L235\n",
    "    Apply filtering to only keep tokens with a probability above a certain threshold. The threshold is defined as `relative_top` * max probability in the distribution.\n",
    "    \"\"\"\n",
    "    scores_normalized = scores.log_softmax(dim=-1)\n",
    "    baseline_scores_normalized = baseline_scores.log_softmax(dim=-1)\n",
    "    sorted_logits, sorted_indices = torch.sort(scores_normalized, descending=True)\n",
    "    min_thresh = sorted_logits[..., min_tokens_to_keep - 1]\n",
    "    probs_max = torch.max(scores_normalized, dim=-1).values\n",
    "    probs_thresh = probs_max + np.log(relative_top)\n",
    "    probs_thresh = torch.min(min_thresh, probs_thresh)\n",
    "    probs_thresh = probs_thresh.unsqueeze(-1)\n",
    "    baseline_scores_normalized[scores_normalized < probs_thresh] = base_filter_value\n",
    "    scores_normalized[scores_normalized < probs_thresh] = filter_value\n",
    "    return scores_normalized, baseline_scores_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits_dict) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logits = logits_dict[len(logits_dict) - 1][:, -1, :]\n",
    "final_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_top = 0.1\n",
    "\n",
    "final_logits, base_logits = _relative_top_filter(final_logits, base_logits, relative_top=relative_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0',\n",
       "       dtype=torch.float16, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits = final_logits - base_logits\n",
    "next_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁**: 50.96875\n",
      "▁Samantha: 41.8125\n",
      "▁Ashley: 39.84375\n",
      "▁Sarah: 36.90625\n",
      "▁Emily: 35.40625\n"
     ]
    }
   ],
   "source": [
    "# Detach, move to CPU, and convert to numpy array\n",
    "logits = next_token_logits.detach().to(torch.float32).cpu().numpy()\n",
    "\n",
    "# Get the top 5 tokens\n",
    "top_5_tokens = logits.argsort()[0][::-1][:5]\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(f\"{reversed_tokenizer[token]}: {logits[0][token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_k_logits(logits, top_k=5):\n",
    "    logits = logits[0].detach().to(torch.float32).cpu().numpy()\n",
    "    top_k_tokens = logits.argsort()[0][::-1][:top_k]\n",
    "    for token in top_k_tokens:\n",
    "        print(f\"{reversed_tokenizer[token]}: {logits[0][token]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def kl_div(logits_dict, candidate_premature_layers, final_logits):\n",
    "    stacked_premature_layers = torch.stack([logits_dict[layer] for layer in candidate_premature_layers], dim=0)\n",
    "\n",
    "    softmax_mature_layer = F.softmax(final_logits, dim=-1)\n",
    "    softmax_premature_layers = F.softmax(stacked_premature_layers, dim=-1)\n",
    "    \n",
    "    # 3. Calculate M, the average distribution\n",
    "    M = 0.5 * (softmax_mature_layer[None, :, :] + softmax_premature_layers)  # shape: (num_premature_layers, batch_size, num_features)\n",
    "\n",
    "    # 4. Calculate log-softmax for the KL divergence\n",
    "    log_softmax_mature_layer = F.log_softmax(final_logits, dim=-1)\n",
    "    log_softmax_premature_layers = F.log_softmax(stacked_premature_layers, dim=-1)  # shape: (num_premature_layers, batch_size, num_features)\n",
    "\n",
    "    # 5. Calculate the KL divergences and then the JS divergences\n",
    "    kl1 = F.kl_div(log_softmax_mature_layer[None, :, :], M, reduction='none').mean(-1)  # shape: (num_premature_layers, batch_size)\n",
    "    kl2 = F.kl_div(log_softmax_premature_layers, M, reduction='none').mean(-1)  # shape: (num_premature_layers, batch_size)\n",
    "    js_divs = 0.5 * (kl1 + kl2)  # shape: (num_premature_layers, batch_size)\n",
    "\n",
    "    # 6. Reduce the batchmean\n",
    "    js_divs = js_divs.mean(-1)  # shape: (num_premature_layers,)\n",
    "    return js_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from transformers import HybridCache\n",
    "\n",
    "def forward_pass(inputs, model, device, distance_fn, candidate_premature_layers=None):\n",
    "    with torch.no_grad():\n",
    "        model_inputs = model.prepare_inputs_for_generation(**inputs)\n",
    "\n",
    "\n",
    "        outputs = model(\n",
    "            **model_inputs,\n",
    "            return_dict=True,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "\n",
    "        final_logits = outputs.logits[:, -1, :].float()\n",
    "\n",
    "\n",
    "        logits_dict = {\n",
    "            exit_layer: model.lm_head(outputs['hidden_states'][exit_layer][:, -1, :]).to(final_logits.device)\n",
    "            for exit_layer in candidate_premature_layers\n",
    "        }\n",
    "\n",
    "\n",
    "        distance = distance_fn(\n",
    "            logits_dict,\n",
    "            candidate_premature_layers,\n",
    "            final_logits\n",
    "        )\n",
    "\n",
    "        \n",
    "        premature_layer = candidate_premature_layers[int(distance.argmax().cpu().item())]\n",
    "\n",
    "\n",
    "        base_logits = logits_dict[premature_layer]\n",
    "        \n",
    "        final_logits, base_logits = _relative_top_filter(final_logits, base_logits)\n",
    "\n",
    "        next_token_logits = final_logits - base_logits\n",
    "        \n",
    "    return next_token_logits, outputs.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁**: 50.76189422607422\n",
      "▁Samantha: 41.72283172607422\n",
      "▁Jennifer: 41.18376922607422\n",
      "▁Ashley: 39.66033172607422\n",
      "▁Emma: 36.87126922607422\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my name is\", return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "output = forward_pass(inputs, model, device, kl_div, candidate_premature_layers=[20])\n",
    "\n",
    "print_top_k_logits(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Michael and I'm\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text_simple(text, model, tokenizer, device, max_length=50):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    generated_tokens = []\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        next_token_id = outputs.logits[0, -1, :].argmax()\n",
    "        \n",
    "        inputs = {\n",
    "            # \"input_ids\": next_token_id.reshape((1, 1)),\n",
    "            \"input_ids\": torch.cat(\n",
    "                [inputs[\"input_ids\"], next_token_id.reshape((1, 1))], dim=1\n",
    "            ),\n",
    "            \"attention_mask\": torch.cat(\n",
    "                [inputs[\"attention_mask\"], torch.tensor([[1]]).to(device)], dim=1\n",
    "            ),\n",
    "            # \"past_key_values\": outputs.past_key_values,\n",
    "        }\n",
    "\n",
    "        if next_token_id.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "        generated_tokens.append(next_token_id.item())\n",
    "    \n",
    "    return  tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "generate_text_simple(\"Hello, my name is\", model, tokenizer, device, max_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' **Gemma**.\\n\\nI'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(text, model, tokenizer, device, distance_fn, candidate_premature_layers=None, max_length=50):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    generated_tokens = []\n",
    "    for _ in range(max_length):\n",
    "\n",
    "        logits, past_key_values = forward_pass(inputs, model, device, distance_fn, candidate_premature_layers)\n",
    "        \n",
    "        next_token_id = logits.argmax()\n",
    "\n",
    "        generated_tokens.append(next_token_id)\n",
    "\n",
    "        inputs = {\n",
    "            # \"input_ids\": next_token_id.unsqueeze(0),\n",
    "            \"input_ids\": torch.cat(\n",
    "                [inputs[\"input_ids\"], next_token_id.reshape((1, 1))], dim=1\n",
    "            ),\n",
    "            \"attention_mask\": torch.cat(\n",
    "                [inputs[\"attention_mask\"], torch.tensor([[1]]).to(device)], dim=1\n",
    "            ),           \n",
    "            # \"past_key_values\": past_key_values,\n",
    "        }\n",
    "\n",
    "        if next_token_id.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "    return  tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "relative_top = 0.1\n",
    "generate_text(\"Hello, my name is\", model, tokenizer, device, kl_div, candidate_premature_layers=[20], max_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁**: 50.76189422607422\n",
      "▁Samantha: 41.72283172607422\n",
      "▁Jennifer: 41.18376922607422\n",
      "▁Ashley: 39.66033172607422\n",
      "▁Emma: 36.87126922607422\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def wasserstein_distance_fn(logits_dict, candidate_premature_layers, final_logits):\n",
    "    stacked_premature_layers = torch.stack([logits_dict[layer] for layer in candidate_premature_layers])\n",
    "\n",
    "    softmax_mature_layer = final_logits.softmax(dim=-1)\n",
    "    softmax_premature_layers = stacked_premature_layers.softmax(dim=-1)\n",
    "\n",
    "    wasserstein_distances = torch.tensor([\n",
    "        wasserstein_distance(\n",
    "            softmax_mature_layer.cpu().numpy().flatten(),\n",
    "            softmax_premature_layers[i].cpu().numpy().flatten()\n",
    "        )\n",
    "        for i in range(len(candidate_premature_layers))\n",
    "    ])\n",
    "\n",
    "    return wasserstein_distances\n",
    "\n",
    "\n",
    "inputs = tokenizer(\"Hello, my name is\", return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "output = forward_pass(inputs, model, device, wasserstein_distance_fn, candidate_premature_layers=[20])\n",
    "\n",
    "print_top_k_logits(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁**: 50.76189422607422\n",
      "▁Samantha: 41.72283172607422\n",
      "▁Jennifer: 41.18376922607422\n",
      "▁Ashley: 39.66033172607422\n",
      "▁Emma: 36.87126922607422\n"
     ]
    }
   ],
   "source": [
    "# Bhattacharyya distance\n",
    "\n",
    "def bhattacharyya_distance_fn(logits_dict, candidate_premature_layers, final_logits):\n",
    "    stacked_premature_layers = torch.stack([logits_dict[layer] for layer in candidate_premature_layers])\n",
    "\n",
    "    softmax_mature_layer = final_logits.softmax(dim=-1)\n",
    "    softmax_premature_layers = stacked_premature_layers.softmax(dim=-1)\n",
    "\n",
    "    bhattacharyya_distances = torch.tensor([\n",
    "        -torch.log(torch.sum(torch.sqrt(softmax_mature_layer * softmax_premature_layers[i])))\n",
    "        for i in range(len(candidate_premature_layers))\n",
    "    ])\n",
    "\n",
    "    return bhattacharyya_distances\n",
    "\n",
    "inputs = tokenizer(\"Hello, my name is\", return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "output = forward_pass(inputs, model, device,bhattacharyya_distance_fn, candidate_premature_layers=[20])\n",
    "\n",
    "print_top_k_logits(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \n",
      "    `CONTEXT`: `Dokument [1]:` Wacław Stanisław Sitkowski (ur. 12 lutego 1924 w Warszawie, zm. 1 kwietnia 2010 tamże) – polski lekarz, kardiochirurg, profesor nauk medycznych, powstaniec warszawski. Jeden z pionierów polskiej kardiochirurgii, nauczyciel polskich kardiochirurgów, w tym Zbigniewa Religi. \n",
      "\n",
      "    `QUERY`: Jak miał na imię polski kardiochirurg, profesor Religa?\n",
      "\n",
      "    `ANSWER`:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [x for x in range(20, 40)]\n",
    "relative_top = 0.1\n",
    "\n",
    "prompt = \"Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \\n    `CONTEXT`: `Dokument [1]:` Wacław Stanisław Sitkowski (ur. 12 lutego 1924 w Warszawie, zm. 1 kwietnia 2010 tamże) – polski lekarz, kardiochirurg, profesor nauk medycznych, powstaniec warszawski. Jeden z pionierów polskiej kardiochirurgii, nauczyciel polskich kardiochirurgów, w tym Zbigniewa Religi. \\n\\n    `QUERY`: Jak miał na imię polski kardiochirurg, profesor Religa?\\n\\n    `ANSWER`:\\n\"\n",
    "\n",
    "prompt_len = len(prompt)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "distances_fns = {\n",
    "    \"KL Divergence\": kl_div,\n",
    "    \"Wasserstein Distance\": wasserstein_distance_fn,\n",
    "    \"Bhattacharyya Distance\": bhattacharyya_distance_fn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    Wacław Stanisław Sitkowski \\n\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = generate_text_simple(prompt, model, tokenizer, device, max_length=100)\n",
    "\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: ```\n",
      "Wacław Stanisław Sitkowski\n",
      "```\n",
      "Wasserstein Distance: ```\n",
      "Wacław Stanisław Sitkowski \n",
      "\n",
      "Bhattacharyya Distance: ```\n",
      "Wacław Stanisław Sitkowski\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "for name, fn in distances_fns.items():\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, fn, candidate_premature_layers=LAYERS, max_length=10)\n",
    "    print(f\"{name}: {all_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: ```\n",
      "Wacław\n",
      "``` \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Wasserstein Distance: ```\n",
      "Wacław\n",
      "``` \n",
      "\n",
      "\n",
      "Bhattacharyya Distance: ```\n",
      "Wacław\n",
      "``` \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [x for x in range(0, 20)]\n",
    "\n",
    "for name, fn in distances_fns.items():\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, fn, candidate_premature_layers=LAYERS, max_length=10)\n",
    "    print(f\"{name}: {all_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \n",
      "    `CONTEXT`: `Dokument [1]:` Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego. \n",
      "\n",
      "    `QUERY`: W którym wieku żył ludwik waryński?\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [x for x in range(20, 40)]\n",
    "\n",
    "prompt = \"Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \\n    `CONTEXT`: `Dokument [1]:` Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego. \\n\\n    `QUERY`: W którym wieku żył ludwik waryński?\"\n",
    "\n",
    "prompt_len = len(prompt)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "`ANSWER`: Ludwik Waryński żył w wieku od 24 do 32 lat. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_text = generate_text_simple(prompt, model, tokenizer, device, max_length=100)\n",
    "\n",
    "print(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \n",
      "    `CONTEXT`: `Dokument [1]:` Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego. \n",
      "\n",
      "    `QUERY`: W którym wieku żył ludwik waryński?\n",
      "\n",
      "\n",
      "\n",
      "```python\n",
      "ANSWER = str(max(int(CONTEXT.split('zm. ')[0].split('ur.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \\n    `CONTEXT`: `Dokument [1]:` Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego. \\n\\n    `QUERY`: W którym wieku żył ludwik waryński?\"\n",
    "prompt_len = len(prompt)\n",
    "output = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# generate text\n",
    "\n",
    "LAYERS = [x for x in range(20, 40)]\n",
    "\n",
    "response = model.generate(\n",
    "    **output,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=25,\n",
    "    dola_layers=LAYERS,\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "text_all = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "\n",
    "print(text_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "```python\n",
      "ANSWER = str(max(int(CONTEXT.split('zm. ')[0].split('ur.\n"
     ]
    }
   ],
   "source": [
    "all_text = generate_text(prompt, model, tokenizer, device, kl_div, candidate_premature_layers=LAYERS, max_length=25)\n",
    "\n",
    "print(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: \n",
      "\n",
      "\n",
      "\n",
      "Answer: Ludwik Waryński żył do wieku 32 lat.  \n",
      "\n",
      "Wasserstein Distance: \n",
      "\n",
      "\n",
      "\n",
      "Answer: Ludwik Waryński żył do wieku 32. \n",
      "\n",
      "Bhattacharyya Distance: \n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "ANSWER\n",
      "Ludwik Waryński żył w wieku 32 lat.  \n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, fn in distances_fns.items():\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, fn, candidate_premature_layers=LAYERS, max_length=100)\n",
    "    print(f\"{name}: {all_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: \n",
      "\n",
      "\n",
      "\n",
      "Answer: Ludwik Waryński żył do wieku 32 lat.  \n",
      "\n",
      "Wasserstein Distance: \n",
      "\n",
      "\n",
      "\n",
      "Answer: Ludwik Waryński żył do wieku 32. \n",
      "\n",
      "Bhattacharyya Distance: \n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "ANSWER\n",
      "Ludwik Waryński żył w wieku 32 lat.  \n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [x for x in range(0, 20)]\n",
    "\n",
    "for name, fn in distances_fns.items():\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, fn, candidate_premature_layers=LAYERS, max_length=100)\n",
    "    print(f\"{name}: {all_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check contrasting across all of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \\n    `CONTEXT`: `Dokument [1]:` Wacław Stanisław Sitkowski (ur. 12 lutego 1924 w Warszawie, zm. 1 kwietnia 2010 tamże) – polski lekarz, kardiochirurg, profesor nauk medycznych, powstaniec warszawski. Jeden z pionierów polskiej kardiochirurgii, nauczyciel polskich kardiochirurgów, w tym Zbigniewa Religi. \\n\\n    `QUERY`: Jak miał na imię polski kardiochirurg, profesor Religa?\\n\\n    `ANSWER`:\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [05:49<00:00,  8.73s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = {}\n",
    "\n",
    "for layer_id in tqdm(range(40)):\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, kl_div, candidate_premature_layers=[layer_id], max_length=100)\n",
    "    data[layer_id] = all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_len = len(prompt)\n",
    "\n",
    "# data_2 = {\n",
    "#     K: V\n",
    "#     for K, V in data.items()\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \n",
      "    `CONTEXT`: `Dokument [1]:` Wacław Stanisław Sitkowski (ur. 12 lutego 1924 w Warszawie, zm. 1 kwietnia 2010 tamże) – polski lekarz, kardiochirurg, profesor nauk medycznych, powstaniec warszawski. Jeden z pionierów polskiej kardiochirurgii, nauczyciel polskich kardiochirurgów, w tym Zbigniewa Religi. \n",
      "\n",
      "    `QUERY`: Jak miał na imię polski kardiochirurg, profesor Religa?\n",
      "\n",
      "    `ANSWER`:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '```\\nWacław\\n``` \\n\\n\\n\\n\\n',\n",
       " 1: '```\\nWacław\\n```\\n\\n\\n',\n",
       " 2: 'Wacław\\n',\n",
       " 3: '```\\nWacław\\n```\\n\\n\\n',\n",
       " 4: '```\\nWacław\\n```\\n\\n\\n',\n",
       " 5: '```\\nWacław\\n```\\n\\n',\n",
       " 6: '```\\nWacław\\n```\\n',\n",
       " 7: '```\\nWacław\\n```\\n',\n",
       " 8: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 9: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 10: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 11: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 12: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 13: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 14: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 15: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 16: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me break down why the answer is `Wacław Stanisław Sitkowski`:\\n\\n* **The Query:** Asks for the name of the Polish cardiothoracic surgeon who was a professor and Religa's teacher. \\n* **The Context:** Provides biographical information about Wacław Stanisław Sitkowski, stating he was:\\n    * A Polish cardiothoracic surgeon.\\n    * A professor.\\n    * One of\",\n",
       " 17: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me break down why this answer is correct:\\n\\n* **The Query:** Asks for the name of the Polish cardiothoracic surgeon who was a professor and Religa's teacher. \\n* **The Context:** Provides biographical information about Wacław Stanisław Sitkowski, stating he was:\\n    * A Polish cardiothoracic surgeon.\\n    * A professor.\\n    * One of the pioneers of Polish cardiothor\",\n",
       " 18: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me break down why this answer is correct:\\n\\n* **The Query:** Asks for the name of the Polish cardiothoracic surgeon who was a professor and Zbigniew Religia's teacher.\\n* **The Context:** Provides biographical information about Wacław Stanisław Sitkowski, stating he was:\\n    * A Polish cardiothoracic surgeon.\\n    * A professor.\\n    * One of the pioneers of Polish cardio\",\n",
       " 19: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me break down why this answer is incorrect:\\n\\n* **The Query:** Asks about the *first name* of the cardiologist who was Religa's teacher. \\n* **The Context:** Tells us Wacław Stanisław Sitkowski was one of the pioneers of Polish cardiochirurgy and taught Zbigniew Religia.\\n\\n\\nTherefore, the answer should be **Wacław Stanisław**.\",\n",
       " 20: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me clarify how I arrived at that answer:\\n\\n* **Understanding the Query:** The query asks for the name of the Polish cardiothoracic surgeon who was the teacher of Professor Religa.\\n* **Analyzing the Context:** The context tells us about Wacław Stanisław Sitkowski, a Polish cardiothoracic surgeon who was one of the pioneers in Poland. It also states he was a teacher to Zbigniew Religia (Professor Re',\n",
       " 21: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me clarify why this answer is incorrect:\\n\\nWhile the context mentions Wacław Stanisław Sitkowski as a pioneer in Polish cardiochirurgy who taught Zbigniew Religi, **the query asks for the name of Zbigniew Religi's teacher**, not Sitkowski himself.\\n\\n\\nTherefore, the correct answer would be **Wacław Stanisław Sitkowski**.\\n\",\n",
       " 22: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me break down why this answer is incorrect:\\n\\n* **The Query:** Asks about the *first name* of the cardiologist who was Religa's teacher.\\n* **The Context:** Provides biographical information about Wacław Stanisław Sitkowski, mentioning him as one of Zbigniew Religia's teachers.\\n\\n\\n**Therefore, the correct answer would be:** **Wacław Stanisław**.\\n\",\n",
       " 23: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me break down why this answer is incorrect:\\n\\n* **The Query:** Asks about the *first name* of the cardiologist who was Religa's teacher.\\n* **The Context:** Provides biographical information about Wacław Stanisław Sitkowski, mentioning him as one of Zbigniew Religia's teachers.\\n\\n\\n**Therefore, the correct answer would be:** **Wacław Stanisław**.\\n\",\n",
       " 24: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me clarify how I arrived at that answer:\\n\\n* **Understanding the Query:** The query asks for the first name of the Polish cardiothoracic surgeon who was Professor Religa's teacher.\\n\\n* **Analyzing the Context:**  The context tells us:\\n    * Wacław Stanisław Sitkowski was a Polish cardiothoracic surgeon.\\n    * He was a professor.\\n    * He was one of the pioneers of\",\n",
       " 25: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me clarify:  While the provided text mentions Professor Sitkowski as a teacher of Zbigniew Religia (another Polish cardiologist), **it doesn't state that Professor Sitkowski *himself* is Professor Religa.**\\n\\n\\n\\nTherefore, a more accurate answer based on the context would be: **We don't know the cardiochirurg's first name based on this text.** \\n\",\n",
       " 26: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me clarify:  While the context mentions Professor Sitkowski was a teacher to Professor Religia,  **it doesn't state that Professor Religia's full name was Wacław Stanisław Sitkowski.**\\n\\n\\n\\nIt seems like there might be confusion. Professor Religia had his own name.\\n\",\n",
       " 27: \"```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n\\nLet me clarify:  While the context provides information about Wacław Stanisław Sitkowski, a Polish cardiologist who was a teacher to Zbigniew Religia, **it doesn't state Zbigniew Religia's first name**.  \\n\\n\\n\\nTherefore, I cannot definitively answer your query based on the provided context.\\n\",\n",
       " 28: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 29: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 30: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 31: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 32: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 33: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 34: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 35: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 36: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 37: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 38: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 39: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n\\n\\n\\nAnswer: Ludwik Waryński żył do wieku 32 lat.  \\n',\n",
       " 1: '\\n\\n\\n\\nAnswer: Ludwik Waryński żył do wieku 32 lat.  \\n',\n",
       " 2: \"\\n\\n    `ANSWER`:  Ludwik Waryński żył do 32 roku życia. \\n\\n\\nLet me know if you'd like me to try another example.\\n\",\n",
       " 3: '\\n\\n    `ANSWER`:  Ludwik Waryński żył do wieku 32.\\n',\n",
       " 4: '\\n\\n    `ANSWER`:  Ludwik Waryński żył w wieku 32.\\n\\n\\n\\n',\n",
       " 5: '\\n\\n    `ANSWER`: Ludwik Waryński żył w wieku od 24 do 32 lat.\\n\\n\\n\\n\\n',\n",
       " 6: '\\n\\n\\n```\\nANSWER\\nLudwik Waryński żył do wieku 32.\\n```\\n',\n",
       " 7: '\\n\\n\\n```\\nANSWER\\nLudwik Waryński żył w wieku od 24 do 32 lat.\\n```\\n',\n",
       " 8: \"\\n\\n\\n\\nLet me break down why finding the answer requires understanding the context:\\n\\n* **Identifying Key Information:** We need to pinpoint Ludwik Tadeusz Waryński's birth and death dates from the provided text.\\n\\n* **Calculating Age:** Once we have those dates, we can subtract his birth year from his death year to determine his lifespan.\\n\\n\\n\\n\\nLet me know if you'd like me to calculate the answer based on the dates!\\n\",\n",
       " 9: \"\\n\\n\\n\\nLet me break down why finding the answer requires careful reading:\\n\\n* **Identifying Key Information:** We need to pinpoint Ludwik Tadeusz Waryński's birth and death dates from the text.\\n* **Calculation:** Once we have the dates, we can subtract his birth year from his death year to find his lifespan.\\n\\n\\nLet me know if you'd like me to calculate the answer based on the dates provided! \\n\",\n",
       " 10: \"\\n\\n\\n\\nLet me break down why finding the answer requires careful reading:\\n\\n* **Identifying Key Information:** We need to pinpoint Ludwik Tadeusz Waryński's birth and death dates from the text.\\n* **Calculating Age:** Once we have those dates, we can subtract his birth year from his death year to find his lifespan.\\n\\n\\nLet me know if you'd like me to calculate the answer based on the dates provided! \\n\",\n",
       " 11: \"\\n\\n\\n\\nLet me break down why finding the answer is simple:\\n\\n* **The Context:** Provides biographical information about Ludwik Tadeusz Waryński.\\n* **The Query:** Directly asks for Ludwik Waryński's lifespan.\\n\\n* **Key Information:** The context states his birth date (September 24, 1856) and death date (March 2, 1889).\\n\\n\\n\\nLet me calculate his age at death:\\n\\n* **Years:** \",\n",
       " 12: '`\\n\\n\\n```json\\n{\\n\"CONTEXT\": \"[Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego.\",\\n\"QUERY\": \"W którym wieku żył ludwik waryński?\"\\n',\n",
       " 13: '`\\n\\n\\n```python\\nANSWER = f\"{ludwik waryński żył w wieku od {ludwik waryński urodził się w wieku} do {ludwik waryński zmarł w wieku}}\" \\n```\\n\\n\\n\\n```python\\nANSWER = f\"{ludwik waryński żył w wieku od {ludwik waryński urodził się w wieku} do {ludwik waryński zmarł w wieku}}\" \\n```\\n',\n",
       " 14: '`\\n\\n\\n```json\\n{\\n\"CONTEXT\": \"[Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego.\",\\n\"QUERY\": \"W którym wieku żył ludwik waryński?\"\\n',\n",
       " 15: '\\n\\n\\n\\n```json\\n{\\n\"CONTEXT\": \"[Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego.\",\\n\"QUERY\": \"W którym wieku żył ludwik waryński?\"\\n}',\n",
       " 16: '\\n\\n\\n\\n```json\\n{\\n\"CONTEXT\": \"[Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego.\",\\n\"QUERY\": \"W którym wieku żył ludwik waryński?\"\\n}',\n",
       " 17: \"\\n\\n\\n\\n```python\\nANSWER = str(max(int(CONTEXT.split('zm. ')[0].split('ur. ')[1].split(' ')[0]), int(CONTEXT.split('zm. ')[1].split(' ')[0])))\\n```\\n\\n\\n\\n\",\n",
       " 18: \"\\n\\n\\n\\n```python\\nANSWER = str(max(int(CONTEXT.split('zm. ')[0].split('ur. ')[1].split(' ')[0]), int(CONTEXT.split('zm. ')[1].split(' ')[0])))\\n```\\n\\n\\n\\n\",\n",
       " 19: \"\\n\\n\\n\\n```python\\nANSWER = str(int(CONTEXT.split('zm. ')[0].split('ur. ')[1].split(' ')[0]) - int(CONTEXT.split('zm. ')[1].split(' ')[0])) \\n```\\n\\n\\n\\n```python\\nANSWER = str(int(CONTEXT.split('zm. ')[1].split(' ')[0]) - int(CONTEXT.split('ur. ')[1].split(' ')[0]))  \\n```\\n\\n\\n\\n```python\\nANSWER\",\n",
       " 20: '\\n\\n\\n\\n```json\\n{\\n \"CONTEXT\": \"[Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego.\",\\n \"QUERY\": \"W którym wieku żył ludwik waryński?\"\\n}',\n",
       " 21: '\\n\\n\\n\\n```json\\n{\\n \"CONTEXT\": \"[Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego.\",\\n \"QUERY\": \"W którym wieku żył ludwik waryński?\"\\n}',\n",
       " 22: '\\n\\n\\n\\n```json\\n{\\n \"CONTEXT\": \"[Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego.\",\\n \"QUERY\": \"W którym wieku żył ludwik waryński?\"\\n}',\n",
       " 23: \"\\n\\n\\n\\n```python\\nANSWER = str(max(int(CONTEXT.split('zm. ')[0].split('ur. ')[1].split(' ')[0]), int(CONTEXT.split('zm. ')[1].split(' ')[0])))\\n```\\n\\n\\n\\n\",\n",
       " 24: '\\n\\n\\n\\n```python\\nANSWER = str(max(int(CONTEXT.split(\"ur.\")[-1].split(\" \")[0]), int(CONTEXT.split(\"zm.\")[-1].split(\" \")[0]))) + \"-\" + str(min(int(CONTEXT.split(\"ur.\")[-1].split(\" \")[0]), int(CONTEXT.split(\"zm.\")[-1].split(\" \")[0])))\\n```\\n\\n\\n\\n',\n",
       " 25: '\\n\\n\\n\\n```python\\nANSWER = str(max(int(CONTEXT.split(\"ur.\")[-1].split(\" \")[0]), int(CONTEXT.split(\"zm.\")[-1].split(\" \")[0]))) + \"-\" + str(min(int(CONTEXT.split(\"ur.\")[-1].split(\" \")[0]), int(CONTEXT.split(\"zm.\")[-1].split(\" \")[0])))\\n```\\n\\n\\n\\n',\n",
       " 26: '\\n\\n\\n\\n```python\\nANSWER = str(max(int(CONTEXT.split(\"ur.\")[-1].split(\" \")[0]), int(CONTEXT.split(\"zm.\")[-1].split(\" \")[0]))) + \"-\" + str(min(int(CONTEXT.split(\"ur.\")[-1].split(\" \")[0]), int(CONTEXT.split(\"zm.\")[-1].split(\" \")[0])))\\n```\\n\\n\\n\\n',\n",
       " 27: '`\\n\\n\\n```python\\nANSWER = f\"{ludwik waryński żył w wieku od {ludwik waryński urodził się w wieku} do {ludwik waryński zmarł w wieku}}\" \\n```\\n\\n\\n\\n```python\\nANSWER = f\"{ludwik waryński żył w wieku od {ludwik waryński urodził się w wieku} do {ludwik waryński zmarł w wieku}}\" \\n```\\n',\n",
       " 28: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CONTEXT.split(\\'ur. \\')[1].split(\\' zm. \\')[0]} do {CONTEXT.split(\\' zm. \\')[1]}.\"} \\n```\\n\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0])} do {int(CONTEXT.split(\\' zm.',\n",
       " 29: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CALCULATED_AGE_START} do {CALCULATED_AGE_END}}\" \\n```\\n\\n\\n\\n```python\\nCALCULATED_AGE_START = int(2023) - int(1856)  \\nCALCULATED_AGE_END = int(2023) - int(1889)   \\n```\\n\\n\\n\\n\\n',\n",
       " 30: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CONTEXT.split(\\'ur. \\')[1].split(\\' zm. \\')[0]} do {CONTEXT.split(\\' zm. \\')[1]}.\"} \\n```\\n\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0])} do {int(CONTEXT.split(\\' zm.',\n",
       " 31: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CALCULATED_AGE_START} do {CALCULATED_AGE_END}}\" \\n```\\n\\n\\n\\n```python\\nCALCULATED_AGE_START = int(2023) - int(1856)  \\nCALCULATED_AGE_END = int(2023) - int(1889)   \\n```\\n\\n\\n\\n\\n\\n',\n",
       " 32: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CONTEXT.split(\\'ur. \\')[1].split(\\' zm. \\')[0]} do {CONTEXT.split(\\' zm. \\')[1]}.\"} \\n```\\n\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0])} do {int(CONTEXT.split(\\' zm.',\n",
       " 33: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CONTEXT.split(\\'ur. \\')[1].split(\\' zm. \\')[0]} do {CONTEXT.split(\\' zm. \\')[1]}.\"} \\n```\\n\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0])} do {int(CONTEXT.split(\\' zm.',\n",
       " 34: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CALCULATED_START_AGE} do {CALCULATED_END_AGE}}\" \\n```\\n\\n\\n\\n```python\\nCALCULATED_START_AGE = int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0]) \\nCALCULATED_END_AGE = int(CONTEXT.split(\\'zm. \\')[1].split(\\' \\')[0])  \\n```\\n\\n\\n\\n\\n',\n",
       " 35: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CALCULATED_START_AGE} do {CALCULATED_END_AGE}}\" \\n```\\n\\n\\n\\n```python\\nCALCULATED_START_AGE = int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0]) \\nCALCULATED_END_AGE = int(CONTEXT.split(\\'zm. \\')[1].split(\\' \\')[0])  \\n```\\n\\n\\n\\n\\n',\n",
       " 36: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CALCULATED_START_AGE} do {CALCULATED_END_AGE}}\" \\n```\\n\\n\\n\\n```python\\nCALCULATED_START_AGE = int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0]) \\nCALCULATED_END_AGE = int(CONTEXT.split(\\'zm. \\')[1].split(\\' \\')[0])  \\n```\\n\\n\\n\\n\\n',\n",
       " 37: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CALCULATED_START_AGE} do {CALCULATED_END_AGE}}\" \\n```\\n\\n\\n\\n```python\\nCALCULATED_START_AGE = int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0]) \\nCALCULATED_END_AGE = int(CONTEXT.split(\\'zm. \\')[1].split(\\' \\')[0])  \\n```\\n\\n\\n\\n\\n',\n",
       " 38: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CALCULATED_START_AGE} do {CALCULATED_END_AGE}}\" \\n```\\n\\n\\n\\n```python\\nCALCULATED_START_AGE = int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0]) \\nCALCULATED_END_AGE = int(CONTEXT.split(\\'zm. \\')[1].split(\\' \\')[0])  \\n```\\n\\n\\n\\n\\n',\n",
       " 39: '`\\n\\n\\n```python\\nANSWER = f\"{Ludwik Tadeusz Waryński żył w wieku od {CALCULATED_START_AGE} do {CALCULATED_END_AGE}}\" \\n```\\n\\n\\n\\n```python\\nCALCULATED_START_AGE = int(CONTEXT.split(\\'ur. \\')[1].split(\\' \\')[0]) \\nCALCULATED_END_AGE = int(CONTEXT.split(\\'zm. \\')[1].split(\\' \\')[0])  \\n```\\n\\n\\n\\n\\n'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "golem-ner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
