{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T07:36:13.808050Z",
     "iopub.status.busy": "2024-08-25T07:36:13.807429Z",
     "iopub.status.idle": "2024-08-25T07:36:17.927601Z",
     "shell.execute_reply": "2024-08-25T07:36:17.926713Z",
     "shell.execute_reply.started": "2024-08-25T07:36:13.808010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad-kielczynski/miniconda3/envs/golem-ner/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will load our standard `unsloth/gemma-2-9b-it-bnb-4bit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID = \"unsloth/gemma-2-9b-it-bnb-4bit\"\n",
    "DTYPE = torch.bfloat16\n",
    "LOAD_IN_4BIT = True\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T05:33:23.262495Z",
     "iopub.status.busy": "2024-08-24T05:33:23.259909Z",
     "iopub.status.idle": "2024-08-24T05:34:08.555677Z",
     "shell.execute_reply": "2024-08-24T05:34:08.553960Z",
     "shell.execute_reply.started": "2024-08-24T05:33:23.262444Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=os.environ[\"HF_TOKEN\"])\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map={\"\": device},\n",
    "    torch_dtype=DTYPE,\n",
    "    token=os.environ[\"HF_TOKEN\"],\n",
    "    use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_tokenizer = {v: k for k, v in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(text, model, tokenizer, device):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        outputs = model(\n",
    "            **inputs,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6719,  0.1553,  0.4805,  ..., -0.0378,  0.2598,  0.1982],\n",
       "          [ 1.3672,  1.5078,  0.4043,  ...,  1.3281, -2.4375, -1.9844],\n",
       "          [-0.7695,  1.8594, -0.4258,  ..., -0.3965, -0.9414, -0.8633],\n",
       "          [ 1.4609,  0.8125,  0.1025,  ...,  1.8984,  0.1040, -1.5156],\n",
       "          [-0.0481, -1.0469, -2.5156,  ...,  1.4297,  0.6250,  0.7695],\n",
       "          [-0.7109, -1.0859, -0.5898,  ...,  0.3984,  1.2344, -0.3379]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.2334, -1.9766, -0.0742,  ..., -0.1406,  0.0352,  0.2178],\n",
       "          [ 2.2188,  5.3125,  0.6055,  ...,  1.1094, -0.8672, -1.8359],\n",
       "          [-0.1699,  1.9375, -0.1748,  ..., -0.0898, -0.2402, -0.2129],\n",
       "          [ 1.0000,  3.1719, -0.4629,  ...,  1.0625,  0.8672, -1.0703],\n",
       "          [ 0.1572,  2.9062, -1.7812,  ...,  0.6445,  1.4062,  0.1406],\n",
       "          [-0.6641,  2.4688, -0.4727,  ..., -0.0352,  1.4062, -0.5156]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-1.0254e-01, -3.3750e+00, -7.8125e-02,  ..., -3.7842e-02,\n",
       "            3.9844e-01,  4.5312e-01],\n",
       "          [ 2.5312e+00,  4.0312e+00,  7.0312e-02,  ...,  1.1797e+00,\n",
       "           -9.1406e-01, -1.3672e+00],\n",
       "          [-1.1914e-01,  7.0703e-01, -1.5430e-01,  ...,  2.3438e-01,\n",
       "           -2.9688e-01,  1.7090e-01],\n",
       "          [ 6.7578e-01,  2.5469e+00, -2.3145e-01,  ...,  1.2031e+00,\n",
       "            6.1719e-01, -9.2188e-01],\n",
       "          [-1.9043e-01,  2.0000e+00, -1.5312e+00,  ...,  1.1094e+00,\n",
       "            8.9844e-01, -4.7266e-01],\n",
       "          [-5.7031e-01,  2.3750e+00, -4.8828e-01,  ..., -1.9531e-03,\n",
       "            9.0234e-01, -5.2734e-02]]], device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.0371, -1.9531, -0.4258,  ..., -0.3574,  0.5078,  0.0996],\n",
       "          [ 2.6250,  3.8438, -0.8125,  ...,  1.3203, -0.8555, -1.0156],\n",
       "          [ 0.1758,  0.0762, -0.0938,  ..., -0.5820, -0.3066,  0.8516],\n",
       "          [ 0.6523,  1.4531, -1.1875,  ...,  0.3320,  0.1914, -0.6641],\n",
       "          [-0.3613,  0.3867, -1.5156,  ...,  1.4453,  0.6914, -0.0156],\n",
       "          [-0.4609,  3.0469, -1.6094,  ..., -0.0488,  0.4492, -1.0938]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.1738, -0.6406, -0.2246,  ..., -0.7969,  0.5742, -0.1943],\n",
       "          [ 2.2969,  4.0000, -1.3750,  ...,  1.0156, -0.2344, -1.0391],\n",
       "          [ 1.7266,  0.8047, -1.7969,  ...,  0.1270, -0.8555,  0.4922],\n",
       "          [ 0.7734,  1.9844, -2.0312,  ...,  0.5977,  0.1797, -1.0703],\n",
       "          [-0.8125,  0.4492, -1.8906,  ...,  1.2500,  1.1016, -0.9805],\n",
       "          [ 0.8672,  1.8125, -1.2344,  ..., -0.0615,  1.3828, -0.8750]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 0.0708, -0.0518, -0.1924,  ..., -0.5000,  0.1494, -0.1348],\n",
       "          [ 1.9062,  2.4375, -1.7188,  ...,  0.3750,  0.0273, -1.1719],\n",
       "          [ 1.2188,  0.1348, -2.4062,  ..., -0.0820, -0.3340,  0.2910],\n",
       "          [ 0.6641,  1.8828, -3.1250,  ..., -0.3320,  0.1797, -0.3945],\n",
       "          [-1.7344,  0.3047, -2.8438,  ...,  1.4688,  1.9766, -1.1094],\n",
       "          [ 0.2500,  1.1406, -1.6484,  ...,  0.4844,  2.2500, -1.2656]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-9.8633e-02,  2.9688e-01, -2.5781e-01,  ..., -5.2734e-01,\n",
       "            6.7188e-01, -5.3906e-01],\n",
       "          [ 1.6953e+00,  3.2812e+00, -4.4375e+00,  ..., -1.9531e-03,\n",
       "           -9.3750e-02, -9.5312e-01],\n",
       "          [ 2.4375e+00,  5.4688e-02, -4.0625e+00,  ..., -9.5312e-01,\n",
       "           -4.0625e-01,  4.6387e-02],\n",
       "          [ 4.3750e-01,  4.3750e+00, -2.7969e+00,  ...,  3.3203e-01,\n",
       "            6.1523e-02, -5.1953e-01],\n",
       "          [-2.0312e+00,  7.1094e-01, -1.7422e+00,  ...,  1.5156e+00,\n",
       "            1.2812e+00, -1.0391e+00],\n",
       "          [ 2.4219e-01,  5.5859e-01, -3.6719e-01,  ...,  2.5195e-01,\n",
       "            2.1875e+00, -1.4844e+00]]], device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.4336, -0.4766, -0.4570,  ..., -0.5312,  0.8906, -0.9141],\n",
       "          [ 1.5312,  3.4531, -3.6719,  ..., -0.2070, -0.7422, -0.3984],\n",
       "          [ 2.5156, -1.0938, -3.2812,  ..., -1.3047, -1.3281,  0.4727],\n",
       "          [-0.9492,  2.9688, -1.8438,  ...,  0.3359,  0.9609,  0.1172],\n",
       "          [-1.2031, -1.7031, -0.0547,  ...,  3.1250,  2.1094, -2.0469],\n",
       "          [ 0.6875, -2.8750,  0.9141,  ...,  1.7500,  2.8281, -1.7344]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-1.1875, -0.6484, -1.5547,  ..., -0.3281,  0.8828, -1.5938],\n",
       "          [ 1.8906,  3.4375, -4.1562,  ..., -0.5586, -0.1875, -0.4609],\n",
       "          [ 3.3750,  0.5547, -4.5000,  ..., -0.9258, -1.1406, -0.4102],\n",
       "          [-0.7812,  3.9688, -2.4531,  ...,  1.2188,  0.7227, -1.0469],\n",
       "          [-1.8438, -1.4141, -0.5117,  ...,  2.7188,  2.4219, -2.7188],\n",
       "          [ 0.1641, -1.5703,  1.2500,  ...,  1.1094,  1.9219, -1.8672]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.7500, -0.6797, -2.2188,  ..., -0.5312,  0.5898, -1.6016],\n",
       "          [ 1.5078,  6.4062, -3.4062,  ..., -1.0547,  0.4922,  1.1484],\n",
       "          [ 3.5000,  1.1094, -3.8750,  ..., -0.2383, -1.8594, -0.4824],\n",
       "          [-0.9727,  3.3438, -1.8281,  ...,  0.6562,  1.2266, -2.9062],\n",
       "          [-3.2500, -1.3672, -1.9922,  ...,  3.3750,  2.2188, -3.0938],\n",
       "          [-0.0083, -1.5859,  1.3281,  ...,  1.4609,  0.8750, -2.4219]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.7539, -0.7578, -3.6562,  ..., -0.7812,  0.7734, -2.9688],\n",
       "          [ 1.5703,  5.7188, -2.9219,  ..., -0.8984,  0.5391,  1.2812],\n",
       "          [ 2.5938,  1.7969, -3.5469,  ...,  0.8594, -2.6875, -1.2500],\n",
       "          [-1.5859,  3.0938, -1.6484,  ...,  0.8906,  0.3047, -3.8125],\n",
       "          [-2.8125, -0.5508, -2.9688,  ...,  4.3438,  2.2344, -4.1250],\n",
       "          [-0.6328, -0.7500,  0.2930,  ...,  1.5156,  1.2734, -3.2188]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.5312, -0.2832, -3.9688,  ..., -0.4297,  0.9648, -2.7812],\n",
       "          [ 0.8555,  4.6250, -3.3438,  ..., -0.0117, -0.1113,  2.3438],\n",
       "          [ 1.9844,  2.2031, -4.7500,  ...,  1.9219, -2.4375,  0.6016],\n",
       "          [-3.0781,  2.5469, -2.6250,  ...,  0.6484,  1.6172, -2.0000],\n",
       "          [-2.2500, -0.0781, -3.4375,  ...,  3.8125,  1.4844, -3.1562],\n",
       "          [-0.4609, -0.2031,  0.3477,  ...,  1.6094,  1.4688, -1.9062]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.3320,  0.5938, -4.0938,  ...,  0.6328,  0.9258, -3.0312],\n",
       "          [ 1.4219,  3.9688, -2.3750,  ..., -0.4980,  1.7266,  1.8281],\n",
       "          [ 2.6562,  1.0469, -4.9062,  ...,  0.7656, -2.6250,  1.8359],\n",
       "          [-2.0000,  0.7109, -2.5781,  ...,  0.1836,  0.3672, -0.4141],\n",
       "          [-1.2812, -0.6016, -3.7031,  ...,  3.8281,  0.2109, -1.9062],\n",
       "          [ 0.1719, -0.4062,  0.2852,  ...,  0.8984,  0.7578, -0.5781]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.2676, -1.3281, -3.9219,  ...,  0.3965,  0.5391, -3.0625],\n",
       "          [ 0.5781,  2.1250, -2.5781,  ..., -1.2031,  2.5938,  2.2188],\n",
       "          [ 2.1250,  0.2031, -5.1562,  ...,  0.8828, -2.2031,  2.5312],\n",
       "          [-3.7344, -0.6758, -2.6719,  ...,  0.6094,  0.9219, -0.4316],\n",
       "          [-3.0469, -1.1016, -3.4688,  ...,  5.4688,  1.2031, -0.8828],\n",
       "          [-1.5938, -1.3594,  0.8281,  ...,  2.0000,  1.8125,  0.7266]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 0.2227, -0.9102, -3.7500,  ...,  1.5391,  0.3164, -3.3438],\n",
       "          [ 1.7812,  2.9219, -1.5312,  ..., -2.0781,  3.5312,  1.3438],\n",
       "          [ 1.6875, -0.2656, -5.8438,  ...,  0.0859, -0.5938,  2.5625],\n",
       "          [-3.8594, -0.6641, -2.8125,  ..., -0.4238,  1.8047,  0.9180],\n",
       "          [-4.8125,  1.0234, -4.8438,  ...,  4.5938,  1.0469, -0.0820],\n",
       "          [-2.1406, -0.2383,  0.1602,  ...,  1.7266,  2.8438,  1.0469]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 0.8984, -1.6406, -3.9531,  ...,  0.1875,  0.8594, -4.5938],\n",
       "          [ 1.9531,  1.3594, -0.8750,  ..., -2.6406,  4.5938,  2.0000],\n",
       "          [ 1.8125, -0.2539, -6.9375,  ..., -1.6875,  0.0703,  2.5312],\n",
       "          [-4.1250, -1.6406, -3.8438,  ..., -0.7891,  2.0000,  0.5039],\n",
       "          [-4.1875,  0.2520, -5.0312,  ...,  3.5156,  3.5469,  0.1426],\n",
       "          [-1.7109, -0.4395,  0.8984,  ...,  0.2148,  5.0000,  0.3086]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 0.6836, -0.3320, -3.2500,  ...,  0.0820,  0.7188, -3.5312],\n",
       "          [ 1.2422,  1.1328,  0.3301,  ..., -0.2109,  6.4375,  3.6406],\n",
       "          [ 2.0312, -0.0078, -7.3750,  ..., -1.7969,  0.5469,  2.4688],\n",
       "          [-4.9062, -2.5469, -3.9688,  ..., -1.1172,  1.6406,  0.9219],\n",
       "          [-4.7812,  0.8555, -5.9375,  ...,  4.1250,  2.7188, -0.2188],\n",
       "          [-2.8750, -0.0410,  0.7773,  ...,  1.1953,  4.3750, -0.3535]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 0.7852,  0.6641, -2.3750,  ...,  0.6602,  1.0547, -3.8750],\n",
       "          [ 0.2812,  0.5703,  2.5938,  ..., -1.0156,  7.2812,  4.9688],\n",
       "          [ 2.2969, -1.2266, -8.3750,  ..., -0.7109,  0.3789,  2.8906],\n",
       "          [-3.7812, -1.6406, -4.8438,  ..., -3.3438,  1.6016,  1.5000],\n",
       "          [-1.4844,  1.0391, -6.0312,  ...,  1.4062,  1.9375, -0.0752],\n",
       "          [-0.5781, -1.3672,  0.8828,  ...,  0.5938,  3.6250,  0.3379]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 5.6250e-01,  3.6328e-01, -1.5703e+00,  ...,  2.7734e-01,\n",
       "            3.8281e-01, -3.8750e+00],\n",
       "          [ 2.6250e+00,  1.3672e-01,  4.3438e+00,  ..., -1.0547e+00,\n",
       "            8.4375e+00,  4.8750e+00],\n",
       "          [ 2.2500e+00, -1.3594e+00, -9.0625e+00,  ...,  6.6406e-01,\n",
       "            4.2188e-01,  3.4062e+00],\n",
       "          [-2.8125e+00, -3.4688e+00, -4.7188e+00,  ..., -2.0781e+00,\n",
       "            1.4453e+00,  1.2031e+00],\n",
       "          [-1.6094e+00, -7.8125e-03, -5.8125e+00,  ...,  1.6562e+00,\n",
       "            3.1250e-01, -1.3281e+00],\n",
       "          [ 5.3125e-01, -1.1562e+00,  1.4688e+00,  ..., -5.8203e-01,\n",
       "            2.2812e+00, -5.6250e-01]]], device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 1.2109, -0.8438, -1.2344,  ...,  0.4941,  0.4336, -3.4062],\n",
       "          [ 3.0469, -0.6484,  4.4062,  ..., -1.4766,  8.2500,  5.1250],\n",
       "          [ 2.2500, -1.6641, -9.0000,  ...,  0.4258,  0.9609,  4.0625],\n",
       "          [-2.3438, -2.8594, -4.6250,  ..., -1.3203,  1.0625,  2.0312],\n",
       "          [ 1.0938, -0.0171, -5.9688,  ...,  1.0000,  1.1641, -1.6484],\n",
       "          [ 2.2969, -1.2344,  0.7148,  ..., -1.5938,  3.3594, -0.8516]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 1.0547, -1.1562, -1.1484,  ..., -0.2373,  0.9648, -3.4375],\n",
       "          [ 2.5938, -0.4844,  4.7188,  ..., -1.7656,  9.0625,  4.8438],\n",
       "          [ 3.1719, -1.2188, -8.4375,  ...,  0.0469,  1.6719,  4.3125],\n",
       "          [-0.5859, -0.4609, -4.7188,  ..., -2.2344,  0.9336,  1.8281],\n",
       "          [ 1.1641,  3.6562, -6.2188,  ...,  1.4219,  0.9375, -0.6641],\n",
       "          [ 1.9922,  0.1719,  0.1328,  ..., -3.4688,  2.2812, -0.2969]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 2.0938, -1.5156, -0.2324,  ..., -1.4141,  2.2656, -3.5312],\n",
       "          [ 2.3125, -0.1562,  5.1250,  ..., -1.3750,  8.9375,  4.8438],\n",
       "          [ 4.6562, -0.3984, -7.9062,  ..., -0.4805,  2.7031,  4.7500],\n",
       "          [ 1.5312,  0.0273, -3.5312,  ..., -2.2188,  2.5000,  2.7031],\n",
       "          [ 0.9688,  4.0312, -5.4062,  ...,  2.4219,  2.6094, -1.1406],\n",
       "          [ 2.7656,  1.0469,  1.0000,  ..., -2.6250,  4.0000,  0.4902]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 1.6406, -2.3125, -0.0952,  ..., -1.8281,  1.9297, -1.8125],\n",
       "          [ 2.1094, -0.0352,  5.3125,  ..., -2.4062,  8.6250,  5.7500],\n",
       "          [ 4.0625, -1.6875, -7.4375,  ..., -0.6953,  2.7812,  5.8750],\n",
       "          [ 2.8594,  0.1084, -3.5938,  ..., -2.2812,  3.3281,  2.7188],\n",
       "          [ 2.0938,  2.7031, -5.1562,  ...,  2.4375,  2.3125, -1.5469],\n",
       "          [ 3.0000,  1.8750,  1.1719,  ..., -2.1719,  4.5312,  0.1406]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 1.4453, -2.7344, -0.3281,  ..., -3.1250,  2.4688, -0.6602],\n",
       "          [ 1.7891, -1.1484,  4.4375,  ..., -2.6875,  7.7500,  6.0625],\n",
       "          [ 4.0625, -0.5312, -8.5625,  ..., -1.3047,  1.8750,  5.0000],\n",
       "          [ 1.7344, -1.5703, -4.0625,  ...,  0.4844,  1.6641,  0.8672],\n",
       "          [ 1.3750,  1.4062, -5.4062,  ...,  2.1250, -1.1875, -2.5938],\n",
       "          [ 3.1875, -0.4531,  1.4141,  ..., -1.9062,  1.8281, -0.8359]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 0.7500, -1.9922, -0.0547,  ..., -1.9062,  2.6719, -1.3125],\n",
       "          [ 1.1016, -2.2344,  4.0000,  ..., -1.3203,  6.6875,  6.3438],\n",
       "          [ 8.1250, -0.8047, -8.7500,  ..., -0.5586,  2.3750,  4.6250],\n",
       "          [ 1.6172, -0.8281, -4.1875,  ...,  1.1250,  2.0625,  1.1562],\n",
       "          [ 1.9219, -0.5156, -5.4062,  ...,  0.7188, -1.1484, -3.0000],\n",
       "          [ 4.5625, -1.7500,  1.3438,  ..., -1.2266,  1.3672, -1.2188]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 2.6094,  0.8594, -1.4766,  ...,  0.6797,  2.0156, -2.8125],\n",
       "          [ 0.1172, -3.2031,  4.1250,  ...,  0.1260,  5.4375,  4.8750],\n",
       "          [ 6.1875, -2.7969, -8.4375,  ..., -2.9531, -0.9844,  5.4375],\n",
       "          [-0.4922, -2.5312, -3.1875,  ..., -0.3047,  2.9375,  0.4395],\n",
       "          [ 0.0938, -1.2969, -5.0000,  ..., -1.8516, -0.8359, -4.9375],\n",
       "          [ 3.0156, -2.5156,  1.5156,  ..., -1.7734,  0.7812, -1.8906]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 2.4531,  2.3125, -2.5938,  ...,  3.4219,  1.2734, -4.2812],\n",
       "          [-0.1592, -2.5625,  3.5000,  ..., -0.9141,  5.2500,  4.5625],\n",
       "          [ 8.5625, -2.4688, -8.5000,  ..., -3.5000, -3.4219,  5.8750],\n",
       "          [ 2.1562, -4.3125, -2.2812,  ..., -0.7109,  3.5000,  3.5781],\n",
       "          [ 2.3750, -3.0938, -4.6250,  ..., -3.4062, -0.4570, -4.5000],\n",
       "          [ 4.0625, -2.2344,  2.4062,  ..., -3.4062,  2.0312, -2.3281]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 2.5156, -0.0703, -2.6875,  ...,  3.3438,  2.2969, -2.8750],\n",
       "          [-0.5859, -0.1094,  0.8281,  ..., -0.1484,  3.3125,  2.3750],\n",
       "          [ 9.0000, -4.3750, -9.3125,  ..., -3.7031, -1.5703,  7.8125],\n",
       "          [ 9.3750, -3.1875, -3.8281,  ..., -2.5000,  5.3750,  2.0156],\n",
       "          [ 4.0938, -3.5000, -5.3438,  ..., -4.4062,  0.5312, -4.4688],\n",
       "          [ 4.3750, -4.6875,  1.8281,  ..., -3.9531,  0.7344, -0.4922]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 2.3281, -1.0703,  0.6172,  ...,  2.3750,  2.4062, -2.2188],\n",
       "          [ 0.1406, -0.3320,  1.0781,  ..., -1.4219,  1.2031,  0.5469],\n",
       "          [ 6.2500, -5.1562, -8.6250,  ..., -2.6406, -0.0781,  3.4375],\n",
       "          [ 7.5312, -4.0625, -3.3125,  ..., -2.8906,  6.6875, -1.2969],\n",
       "          [ 6.2812, -2.2500, -3.4375,  ..., -0.7031,  3.8750, -6.0000],\n",
       "          [ 3.0625, -5.9375,  0.5938,  ..., -5.1250, -0.8047, -0.1562]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 3.1562, -1.7969,  1.1094,  ...,  1.5938,  0.8594, -2.0625],\n",
       "          [-0.2256, -1.3281, -0.4531,  ..., -0.8906, -0.3203, -0.0254],\n",
       "          [12.5625, -2.6094, -9.3750,  ..., -4.1875,  2.3438,  2.8750],\n",
       "          [ 9.7500, -1.9531, -2.2812,  ..., -1.8594,  7.9375, -2.1094],\n",
       "          [ 8.8750, -0.7148, -2.6406,  ..., -4.0625,  3.9531, -3.6719],\n",
       "          [ 2.3750, -5.9062,  0.0625,  ..., -5.9062,  1.1406, -1.5234]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[  0.7422,  -2.0156,   1.0547,  ...,   1.1719,   1.1484,  -3.7812],\n",
       "          [ -0.4316,  -0.3906,  -0.8672,  ...,  -0.4688,  -0.6523,   0.4609],\n",
       "          [ 14.2500,  -0.7734, -14.1875,  ...,  -5.8750,   2.3594,   1.6562],\n",
       "          [  9.5000,  -1.0312,  -5.8438,  ...,  -3.6250,   6.7500,  -1.6172],\n",
       "          [ 10.9375,   2.3438,  -5.7812,  ...,  -3.0156,   4.5000,  -1.6406],\n",
       "          [  5.2812,  -2.8438,  -2.2031,  ...,  -4.5938,  -0.1055,  -2.0938]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[  0.9531,  -0.8242,   0.7266,  ...,   1.0469,   1.1250,  -1.9219],\n",
       "          [  0.0820,  -1.1250,  -1.4922,  ...,  -1.0703,   0.5000,  -0.0488],\n",
       "          [ 13.1250,  -0.1641, -14.0000,  ...,  -3.0781,   4.3125,  -1.1875],\n",
       "          [  6.7500,  -1.4609,  -5.7812,  ...,  -0.8906,   6.2500,  -2.4062],\n",
       "          [  9.2500,   2.7500,  -5.8125,  ...,  -0.9922,   2.6875,  -0.8594],\n",
       "          [  6.1562,  -1.2031,  -3.8438,  ...,  -6.1250,  -0.2773,  -0.4414]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 1.0312e+00, -1.6937e-03,  9.5312e-01,  ...,  6.2109e-01,\n",
       "            1.0234e+00, -1.7031e+00],\n",
       "          [ 3.5938e-01, -1.2344e+00, -7.1875e-01,  ..., -1.5312e+00,\n",
       "            1.5547e+00,  6.8359e-01],\n",
       "          [ 1.5375e+01,  8.3594e-01, -1.2938e+01,  ..., -4.2500e+00,\n",
       "            6.1875e+00, -1.9219e+00],\n",
       "          [ 5.2812e+00, -4.7188e+00, -2.8906e+00,  ..., -2.2656e-01,\n",
       "            9.0000e+00, -5.5000e+00],\n",
       "          [ 6.8125e+00,  1.1250e+00, -2.9688e+00,  ..., -2.5312e+00,\n",
       "            4.4062e+00, -1.5000e+00],\n",
       "          [ 7.1562e+00, -1.7031e+00, -4.1875e+00,  ..., -2.7812e+00,\n",
       "            7.8516e-01, -1.5391e+00]]], device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[  1.0078,  -1.2500,   1.4688,  ...,   0.8516,   1.7812,  -0.5078],\n",
       "          [  0.7109,  -1.0469,  -1.2109,  ...,  -2.3438,   2.2500,   1.2891],\n",
       "          [ 13.6875,  -1.4375, -14.4375,  ...,  -6.1875,   6.8125,  -3.5469],\n",
       "          [  4.9688,  -8.2500,  -4.8750,  ...,  -2.3906,   8.6875,  -4.8438],\n",
       "          [  6.4688,   2.0625,  -4.0938,  ...,  -1.2031,   5.2500,  -3.2500],\n",
       "          [  7.3750,  -4.6250,  -4.5938,  ...,  -3.9375,   1.9062,  -1.4375]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[  0.9805,  -1.5938,   0.5664,  ...,   1.4375,   1.4688,  -0.9766],\n",
       "          [  0.4141,  -0.7461,  -1.7734,  ...,  -2.2344,   1.6172,   0.7148],\n",
       "          [ 12.4375,  -0.1914, -12.6875,  ...,  -2.9844,   5.5625,  -4.3125],\n",
       "          [  3.8125,  -6.9375,  -3.9062,  ...,   2.5781,   9.5000,  -8.2500],\n",
       "          [  3.5781,   4.1250,  -4.2812,  ...,   1.7891,   5.4688,  -3.3281],\n",
       "          [  5.3750,  -5.4375,  -3.5781,  ...,  -2.1250,   1.8594,  -0.1484]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[  0.5742,  -1.5781,  -0.3223,  ...,   0.1641,   1.2812,  -1.3906],\n",
       "          [  0.2227,  -0.5156,  -1.7578,  ...,  -1.5859,   1.8828,   0.9219],\n",
       "          [ 11.9375,   1.8672, -12.9375,  ...,   0.5000,   9.7500,  -4.8438],\n",
       "          [  1.8516,  -4.6250,  -1.9688,  ...,   2.3750,  11.2500,  -8.6875],\n",
       "          [  2.0938,   2.4219,  -2.4688,  ...,   2.6719,   7.3438,  -2.9375],\n",
       "          [  4.1250,  -7.2188,  -2.6562,  ...,  -1.0938,   3.7188,  -1.0234]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[  1.1250,  -0.1211,  -1.9141,  ...,  -0.8125,   1.8906,  -1.0703],\n",
       "          [  1.6641,  -1.3750,  -1.5859,  ...,  -1.2891,   1.2500,   0.4395],\n",
       "          [ 11.3750,   0.2734, -10.8750,  ...,  -0.1094,   9.5000,  -3.8281],\n",
       "          [  2.8750,  -2.4375,  -2.0781,  ...,   5.7500,  11.8125, -10.0000],\n",
       "          [  4.6250,   1.6016,  -0.8750,  ...,   1.4688,   6.5938,  -7.8750],\n",
       "          [  6.9688, -10.3125,  -0.7070,  ...,  -0.3770,   4.3125,   0.3984]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 0.1016, -1.2500, -3.0156,  ..., -1.3281, -0.1250, -1.0469],\n",
       "          [ 1.8906, -0.7109, -1.9688,  ...,  0.1406,  1.0469,  0.0630],\n",
       "          [10.3750, -1.4062, -9.3750,  ...,  0.7305,  8.3125, -2.2812],\n",
       "          [ 1.2344, -2.4219, -0.8984,  ...,  6.0312,  9.5000, -9.5000],\n",
       "          [ 6.9688,  2.1094, -2.5312,  ...,  1.0859,  7.1250, -6.7812],\n",
       "          [ 8.8750, -8.8750, -0.8672,  ...,  1.7578,  7.1562,  0.0947]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[ 0.0859, -1.2812, -3.1250,  ..., -1.1016,  0.6367, -1.4141],\n",
       "          [ 0.3125, -0.0557, -2.5156,  ...,  0.3047,  0.2031,  0.3340],\n",
       "          [12.1875, -6.5625, -7.0938,  ...,  2.3125, 14.0000, -2.4219],\n",
       "          [-1.9219, -6.0625,  4.1562,  ...,  7.6250,  8.6250, -8.8125],\n",
       "          [ 8.3750,  3.3906, -1.8125,  ...,  5.5625,  5.6875, -6.1250],\n",
       "          [13.2500, -6.0625, -3.2812,  ...,  6.2500,  5.5938,  5.4062]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.9023,  0.3750, -1.1953,  ..., -0.4863, -3.0781,  0.9375],\n",
       "          [ 1.4219, -0.4688, -3.1875,  ..., -0.8516,  1.0625, -0.4961],\n",
       "          [15.6250, -4.0938, -7.8438,  ..., -0.4219, 13.3750, -1.7500],\n",
       "          [-1.4688, -3.5938,  2.2500,  ...,  5.3125,  7.9062, -2.9375],\n",
       "          [ 2.5938,  1.1875, -1.1875,  ...,  1.8594, 10.4375, -7.5625],\n",
       "          [12.1875, -7.8750, -1.7031,  ...,  4.3125,  7.2500,  7.3750]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.9258,  1.1641, -2.3594,  ..., -1.4375, -0.6797,  1.4531],\n",
       "          [ 2.3594, -0.5820, -3.8281,  ..., -0.1719,  1.1875, -0.5312],\n",
       "          [15.4375, -7.6562, -6.9062,  ...,  1.7812, 12.0000, -3.7500],\n",
       "          [-1.9531, -4.9375,  3.3906,  ...,  7.4062, 11.8750, -6.2500],\n",
       "          [ 3.6250,  2.7812, -6.1875,  ...,  5.3438, 13.0000, -5.5312],\n",
       "          [12.6250, -6.4375, -4.1562,  ..., -0.5312,  9.7500,  5.8125]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-3.8906,  0.6602,  1.7812,  ..., -0.8906, -1.6484, -0.1475],\n",
       "          [ 6.0938, -1.1016, -5.0000,  ...,  0.2178,  0.7695, -1.3594],\n",
       "          [12.7500, -9.6875,  3.3125,  ...,  2.0938,  4.0625, -8.6250],\n",
       "          [-3.7500, -2.7500, 10.7500,  ...,  4.7812, 11.8125, -9.0625],\n",
       "          [ 6.0000,  6.7188, -5.6875,  ..., -0.3594, 10.0000, -2.0781],\n",
       "          [15.0000, -9.7500, -4.8750,  ...,  0.6094,  4.6875,  4.1875]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-0.2520, -0.0267, -0.0084,  ..., -0.0223, -0.1787,  0.0238],\n",
       "          [ 1.2891, -3.6094, -0.8320,  ...,  1.0938,  0.7422, -0.6953],\n",
       "          [ 0.4844, -2.4688,  1.2812,  ...,  0.3457,  0.5664, -0.6250],\n",
       "          [-0.5781, -0.7656,  1.4531,  ...,  0.0815,  0.6719, -0.3145],\n",
       "          [ 0.7539,  0.9570, -0.7656,  ..., -0.2969,  1.4922,  0.3965],\n",
       "          [ 1.3125, -2.5469, -0.8477,  ..., -0.7539,  0.2754,  1.1328]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = forward_pass(\"Hello, my name is\", model, tokenizer, device)\n",
    "\n",
    "output['hidden_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output['hidden_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_dict = {}\n",
    "\n",
    "for i, hidden_state in enumerate(output['hidden_states']):\n",
    "    logits = model.lm_head(hidden_state)\n",
    "    logits_dict[i] = logits\n",
    "\n",
    "logits_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 256000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premature_layer = 20\n",
    "\n",
    "logits_dict[premature_layer].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_logits = logits_dict[premature_layer][:, -1, :]\n",
    "\n",
    "base_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _relative_top_filter(\n",
    "    scores: torch.FloatTensor,\n",
    "    baseline_scores: torch.FloatTensor,\n",
    "    relative_top: float = 0.1,\n",
    "    filter_value: float = -float(\"Inf\"),\n",
    "    base_filter_value=-1e-3,\n",
    "    min_tokens_to_keep: int = 1,\n",
    ") -> torch.FloatTensor:\n",
    "    \"\"\"\n",
    "    Reference: https://github.com/XiangLi1999/ContrastiveDecoding/blob/170e9142e92159c1237d731e240f5eb14aabf428/transformers/src/transformers/generation_logits_process.py#L235\n",
    "    Apply filtering to only keep tokens with a probability above a certain threshold. The threshold is defined as `relative_top` * max probability in the distribution.\n",
    "    \"\"\"\n",
    "    scores_normalized = scores.log_softmax(dim=-1)\n",
    "    baseline_scores_normalized = baseline_scores.log_softmax(dim=-1)\n",
    "    sorted_logits, sorted_indices = torch.sort(scores_normalized, descending=True)\n",
    "    min_thresh = sorted_logits[..., min_tokens_to_keep - 1]\n",
    "    probs_max = torch.max(scores_normalized, dim=-1).values\n",
    "    probs_thresh = probs_max + np.log(relative_top)\n",
    "    probs_thresh = torch.min(min_thresh, probs_thresh)\n",
    "    probs_thresh = probs_thresh.unsqueeze(-1)\n",
    "    baseline_scores_normalized[scores_normalized < probs_thresh] = base_filter_value\n",
    "    scores_normalized[scores_normalized < probs_thresh] = filter_value\n",
    "    return scores_normalized, baseline_scores_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits_dict) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logits = logits_dict[len(logits_dict) - 1][:, -1, :]\n",
    "final_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_top = 0.1\n",
    "\n",
    "final_logits, base_logits = _relative_top_filter(final_logits, base_logits, relative_top=relative_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0',\n",
       "       dtype=torch.bfloat16, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits = final_logits - base_logits\n",
    "next_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁**: 51.0\n",
      "▁Samantha: 41.75\n",
      "▁Ashley: 40.0\n",
      "▁Sarah: 36.75\n",
      "▁Emily: 35.25\n"
     ]
    }
   ],
   "source": [
    "# Detach, move to CPU, and convert to numpy array\n",
    "logits = next_token_logits.detach().to(torch.float32).cpu().numpy()\n",
    "\n",
    "# Get the top 5 tokens\n",
    "top_5_tokens = logits.argsort()[0][::-1][:5]\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(f\"{reversed_tokenizer[token]}: {logits[0][token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_k_logits(logits, top_k=5):\n",
    "    logits = logits[0].detach().to(torch.float32).cpu().numpy()\n",
    "    top_k_tokens = logits.argsort()[0][::-1][:top_k]\n",
    "    for token in top_k_tokens:\n",
    "        print(f\"{reversed_tokenizer[token]}: {logits[0][token]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def kl_div(logits_dict, candidate_premature_layers, final_logits):\n",
    "    stacked_premature_layers = torch.stack([logits_dict[layer] for layer in candidate_premature_layers], dim=0)\n",
    "\n",
    "    softmax_mature_layer = F.softmax(final_logits, dim=-1)\n",
    "    softmax_premature_layers = F.softmax(stacked_premature_layers, dim=-1)\n",
    "    \n",
    "    # 3. Calculate M, the average distribution\n",
    "    M = 0.5 * (softmax_mature_layer[None, :, :] + softmax_premature_layers)  # shape: (num_premature_layers, batch_size, num_features)\n",
    "\n",
    "    # 4. Calculate log-softmax for the KL divergence\n",
    "    log_softmax_mature_layer = F.log_softmax(final_logits, dim=-1)\n",
    "    log_softmax_premature_layers = F.log_softmax(stacked_premature_layers, dim=-1)  # shape: (num_premature_layers, batch_size, num_features)\n",
    "\n",
    "    # 5. Calculate the KL divergences and then the JS divergences\n",
    "    kl1 = F.kl_div(log_softmax_mature_layer[None, :, :], M, reduction='none').mean(-1)  # shape: (num_premature_layers, batch_size)\n",
    "    kl2 = F.kl_div(log_softmax_premature_layers, M, reduction='none').mean(-1)  # shape: (num_premature_layers, batch_size)\n",
    "    js_divs = 0.5 * (kl1 + kl2)  # shape: (num_premature_layers, batch_size)\n",
    "\n",
    "    # 6. Reduce the batchmean\n",
    "    js_divs = js_divs.mean(-1)  # shape: (num_premature_layers,)\n",
    "    return js_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from transformers import HybridCache\n",
    "\n",
    "def forward_pass(inputs, model, device, distance_fn, candidate_premature_layers=None):\n",
    "    with torch.no_grad():\n",
    "        model_inputs = model.prepare_inputs_for_generation(**inputs)\n",
    "\n",
    "        final_layer = model.config.get_text_config().num_hidden_layers\n",
    "\n",
    "        if not model.config.tie_word_embeddings:\n",
    "            start_layer = 0\n",
    "        elif final_layer > 2:\n",
    "            start_layer = 2\n",
    "        elif final_layer == 2:\n",
    "            start_layer = 1\n",
    "        else:\n",
    "            start_layer = 0\n",
    "\n",
    "        dola_layers = candidate_premature_layers\n",
    "\n",
    "        if isinstance(dola_layers, str) and dola_layers == \"low\":\n",
    "            if start_layer == final_layer // 2:\n",
    "                candidate_premature_layers = [start_layer]\n",
    "            else:\n",
    "                candidate_premature_layers = (\n",
    "                    list(range(start_layer, final_layer // 2, 2))\n",
    "                    if final_layer <= 40\n",
    "                    else list(range(start_layer, 20, 2))\n",
    "                )\n",
    "        elif isinstance(dola_layers, str) and dola_layers == \"high\":\n",
    "            candidate_premature_layers = (\n",
    "                list(range(final_layer // 2, final_layer, 2))\n",
    "                if final_layer <= 40\n",
    "                else list(range(final_layer - 20, final_layer, 2))\n",
    "            )\n",
    "        # Set the `dola_layers` to a list of integers for layer indices to contrast manually specified layers.\n",
    "        elif isinstance(dola_layers, list):\n",
    "            candidate_premature_layers = [i for i in dola_layers if i < final_layer]\n",
    "        else:\n",
    "            raise ValueError(\"dola_layers must be either 'low', 'high' or a list of integers.\")\n",
    "\n",
    "\n",
    "        outputs = model(\n",
    "            **model_inputs,\n",
    "            return_dict=True,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "\n",
    "        final_logits = outputs.logits[:, -1, :].float()\n",
    "\n",
    "\n",
    "        logits_dict = {\n",
    "            exit_layer: model.lm_head(outputs['hidden_states'][exit_layer][:, -1, :]).to(final_logits.device)\n",
    "            for exit_layer in candidate_premature_layers\n",
    "        }\n",
    "\n",
    "\n",
    "        distance = distance_fn(\n",
    "            logits_dict,\n",
    "            candidate_premature_layers,\n",
    "            final_logits\n",
    "        )\n",
    "\n",
    "        \n",
    "        premature_layer = candidate_premature_layers[int(distance.argmax().cpu().item())]\n",
    "\n",
    "\n",
    "        base_logits = logits_dict[premature_layer]\n",
    "        \n",
    "        final_logits, base_logits = _relative_top_filter(final_logits, base_logits)\n",
    "\n",
    "        next_token_logits = final_logits - base_logits\n",
    "        \n",
    "    return next_token_logits, outputs.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁**: 50.836509704589844\n",
      "▁Samantha: 41.711509704589844\n",
      "▁Ashley: 39.711509704589844\n",
      "▁Emma: 36.961509704589844\n",
      "▁Laura: 36.899009704589844\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my name is\", return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "output = forward_pass(inputs, model, device, kl_div, candidate_premature_layers=[20])\n",
    "\n",
    "print_top_k_logits(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Michael and I'm\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text_simple(text, model, tokenizer, device, max_length=50, repetition_penalty=1.2):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    generated_tokens = []\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        logits = outputs.logits[0, -1, :]\n",
    "\n",
    "        # Apply repetition penalty\n",
    "        if generated_tokens:\n",
    "            for token_id in set(generated_tokens):\n",
    "                logits[token_id] /= repetition_penalty\n",
    "\n",
    "        next_token_id = logits.argmax()\n",
    "        \n",
    "        inputs = {\n",
    "            # \"input_ids\": next_token_id.reshape((1, 1)),\n",
    "            \"input_ids\": torch.cat(\n",
    "                [inputs[\"input_ids\"], next_token_id.reshape((1, 1))], dim=1\n",
    "            ),\n",
    "            \"attention_mask\": torch.cat(\n",
    "                [inputs[\"attention_mask\"], torch.tensor([[1]]).to(device)], dim=1\n",
    "            ),\n",
    "            # \"past_key_values\": outputs.past_key_values,\n",
    "        }\n",
    "\n",
    "        if next_token_id.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "        generated_tokens.append(next_token_id.item())\n",
    "    \n",
    "    return  tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "generate_text_simple(\"Hello, my name is\", model, tokenizer, device, max_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' **Gemma**.\\n\\nI'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(text, model, tokenizer, device, distance_fn, candidate_premature_layers=None, max_length=50, repetition_penalty=1.2):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    generated_tokens = []\n",
    "    for _ in range(max_length):\n",
    "\n",
    "        logits, past_key_values = forward_pass(inputs, model, device, distance_fn, candidate_premature_layers)\n",
    "        \n",
    "        if generated_tokens:\n",
    "            for token_id in set(generated_tokens):\n",
    "                logits[0][token_id] /= repetition_penalty\n",
    "\n",
    "        next_token_id = logits.argmax()\n",
    "\n",
    "        generated_tokens.append(next_token_id)\n",
    "\n",
    "        inputs = {\n",
    "            # \"input_ids\": next_token_id.unsqueeze(0),\n",
    "            \"input_ids\": torch.cat(\n",
    "                [inputs[\"input_ids\"], next_token_id.reshape((1, 1))], dim=1\n",
    "            ),\n",
    "            \"attention_mask\": torch.cat(\n",
    "                [inputs[\"attention_mask\"], torch.tensor([[1]]).to(device)], dim=1\n",
    "            ),           \n",
    "            # \"past_key_values\": past_key_values,\n",
    "        }\n",
    "\n",
    "        if next_token_id.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "    return  tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "relative_top = 0.1\n",
    "generate_text(\"Hello, my name is\", model, tokenizer, device, kl_div, candidate_premature_layers=[20], max_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁**: 50.836509704589844\n",
      "▁Samantha: 41.711509704589844\n",
      "▁Ashley: 39.711509704589844\n",
      "▁Emma: 36.961509704589844\n",
      "▁Laura: 36.899009704589844\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def wasserstein_distance_fn(logits_dict, candidate_premature_layers, final_logits):\n",
    "    stacked_premature_layers = torch.stack([logits_dict[layer] for layer in candidate_premature_layers])\n",
    "\n",
    "    softmax_mature_layer = final_logits.softmax(dim=-1).float()\n",
    "    softmax_premature_layers = stacked_premature_layers.softmax(dim=-1).float()\n",
    "\n",
    "    wasserstein_distances = torch.tensor([\n",
    "        wasserstein_distance(\n",
    "            softmax_mature_layer.cpu().numpy().flatten(),\n",
    "            softmax_premature_layers[i].cpu().numpy().flatten()\n",
    "        )\n",
    "        for i in range(len(candidate_premature_layers))\n",
    "    ])\n",
    "\n",
    "    return wasserstein_distances\n",
    "\n",
    "\n",
    "inputs = tokenizer(\"Hello, my name is\", return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "output = forward_pass(inputs, model, device, wasserstein_distance_fn, candidate_premature_layers=[20])\n",
    "\n",
    "print_top_k_logits(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁**: 50.836509704589844\n",
      "▁Samantha: 41.711509704589844\n",
      "▁Ashley: 39.711509704589844\n",
      "▁Emma: 36.961509704589844\n",
      "▁Laura: 36.899009704589844\n"
     ]
    }
   ],
   "source": [
    "# Bhattacharyya distance\n",
    "\n",
    "def bhattacharyya_distance_fn(logits_dict, candidate_premature_layers, final_logits):\n",
    "    stacked_premature_layers = torch.stack([logits_dict[layer] for layer in candidate_premature_layers])\n",
    "\n",
    "    softmax_mature_layer = final_logits.softmax(dim=-1)\n",
    "    softmax_premature_layers = stacked_premature_layers.softmax(dim=-1)\n",
    "\n",
    "    bhattacharyya_distances = torch.tensor([\n",
    "        -torch.log(torch.sum(torch.sqrt(softmax_mature_layer * softmax_premature_layers[i])))\n",
    "        for i in range(len(candidate_premature_layers))\n",
    "    ])\n",
    "\n",
    "    return bhattacharyya_distances\n",
    "\n",
    "inputs = tokenizer(\"Hello, my name is\", return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "output = forward_pass(inputs, model, device,bhattacharyya_distance_fn, candidate_premature_layers=[20])\n",
    "\n",
    "print_top_k_logits(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \n",
      "    `CONTEXT`: `Dokument [1]:` Wacław Stanisław Sitkowski (ur. 12 lutego 1924 w Warszawie, zm. 1 kwietnia 2010 tamże) – polski lekarz, kardiochirurg, profesor nauk medycznych, powstaniec warszawski. Jeden z pionierów polskiej kardiochirurgii, nauczyciel polskich kardiochirurgów, w tym Zbigniewa Religi. \n",
      "\n",
      "    `QUERY`: Jak miał na imię polski kardiochirurg, profesor Religa?\n",
      "\n",
      "    `ANSWER`:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [x for x in range(20, 40)]\n",
    "relative_top = 0.1\n",
    "\n",
    "prompt = \"Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \\n    `CONTEXT`: `Dokument [1]:` Wacław Stanisław Sitkowski (ur. 12 lutego 1924 w Warszawie, zm. 1 kwietnia 2010 tamże) – polski lekarz, kardiochirurg, profesor nauk medycznych, powstaniec warszawski. Jeden z pionierów polskiej kardiochirurgii, nauczyciel polskich kardiochirurgów, w tym Zbigniewa Religi. \\n\\n    `QUERY`: Jak miał na imię polski kardiochirurg, profesor Religa?\\n\\n    `ANSWER`:\\n\"\n",
    "\n",
    "prompt_len = len(prompt)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "distances_fns = {\n",
    "    \"KL Divergence\": kl_div,\n",
    "    \"Wasserstein Distance\": wasserstein_distance_fn,\n",
    "    \"Bhattacharyya Distance\": bhattacharyya_distance_fn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    Wacław \\n\\n\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = generate_text_simple(prompt, model, tokenizer, device, max_length=100)\n",
    "\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: ```\n",
      "Wacław Stanisław Sitkowski\n",
      "```\n",
      "Wasserstein Distance: ```\n",
      "Wacław Stanisław Sitkowski \n",
      "\n",
      "Bhattacharyya Distance: ```\n",
      "Wacław Stanisław Sitkowski\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "for name, fn in distances_fns.items():\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, fn, candidate_premature_layers='high', max_length=10)\n",
    "    print(f\"{name}: {all_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: ```\n",
      "Wacław \n",
      "```\n",
      "\n",
      "\n",
      "Wasserstein Distance: ```\n",
      "Wacław \n",
      "```\n",
      "\n",
      "\n",
      "Bhattacharyya Distance: Wacław\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [x for x in range(0, 20)]\n",
    "\n",
    "for name, fn in distances_fns.items():\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, fn, candidate_premature_layers='low', max_length=10)\n",
    "    print(f\"{name}: {all_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \n",
      "    `CONTEXT`: `Dokument [1]:` Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego. \n",
      "\n",
      "    `QUERY`: W którym wieku żył ludwik waryński?\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [x for x in range(20, 40)]\n",
    "\n",
    "prompt = \"Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \\n    `CONTEXT`: `Dokument [1]:` Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego. \\n\\n    `QUERY`: W którym wieku żył ludwik waryński?\"\n",
    "\n",
    "prompt_len = len(prompt)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "`ANSWER`: Ludwik Waryński żył w wieku od 24 do 32 lat.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_text = generate_text_simple(prompt, model, tokenizer, device, max_length=100)\n",
    "\n",
    "print(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \n",
      "    `CONTEXT`: `Dokument [1]:` Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego. \n",
      "\n",
      "    `QUERY`: W którym wieku żył ludwik waryński?\n",
      "\n",
      "\n",
      "\n",
      "```python\n",
      "CONTEXT = \"\"\"Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września \n"
     ]
    }
   ],
   "source": [
    "prompt = \"Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \\n    `CONTEXT`: `Dokument [1]:` Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego. \\n\\n    `QUERY`: W którym wieku żył ludwik waryński?\"\n",
    "prompt_len = len(prompt)\n",
    "output = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# generate text\n",
    "\n",
    "LAYERS = 'high'\n",
    "\n",
    "response = model.generate(\n",
    "    **output,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=25,\n",
    "    dola_layers=LAYERS,\n",
    "    use_cache=True,\n",
    "    repetition_penalty=1.2,\n",
    ")\n",
    "\n",
    "text_all = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "\n",
    "print(text_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "```python\n",
      "CONTEXT = \"\"\"Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września \n"
     ]
    }
   ],
   "source": [
    "all_text = generate_text(prompt, model, tokenizer, device, kl_div, candidate_premature_layers=LAYERS, max_length=25)\n",
    "\n",
    "print(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: \n",
      "\n",
      "\n",
      "\n",
      "```python\n",
      "CONTEXT = \"\"\"Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego.\"\"\"\n",
      "QUERY = \"W którym wieku żył ludwik waryński?\"\n",
      "\n",
      "ANSWER = f\"{1\n",
      "Wasserstein Distance: \n",
      "\n",
      "\n",
      "\n",
      "```python\n",
      "ANSWER = \"\"  # Replace with your answer \n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Bhattacharyya Distance: \n",
      "\n",
      "\n",
      "\n",
      "```json\n",
      "{\n",
      " \"CONTEXT\": \"[Dokument [1]: Ludwik Tadeusz Waryński (ur. 24 września 1856 w Martynówce koło Kaniowa, zm. 2 marca 1889 w Szlisselburgu) – polski działacz i ideolog polskiego ruchu socjalistycznego. Brat Stanisława, ojciec Tadeusza Waryńskiego.\",\n",
      " \"QUERY\": \"W którym wieku żył ludwik waryński?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for name, fn in distances_fns.items():\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, fn, candidate_premature_layers='high', max_length=100)\n",
    "    print(f\"{name}: {all_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: \n",
      "\n",
      "`ANSWER`:  Ludwik Waryński żył do 32 lat.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Wasserstein Distance: \n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "ANSWER`:  Ludwik Waryński żył do 32. roku życia.\n",
      "```\n",
      "\n",
      "\n",
      "Bhattacharyya Distance: \n",
      "\n",
      "`ANSWER`:  Ludwik Waryński żył w wieku 32 lat.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, fn in distances_fns.items():\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, fn, candidate_premature_layers='low', max_length=100)\n",
    "    print(f\"{name}: {all_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check contrasting across all of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \\n    `CONTEXT`: `Dokument [1]:` Wacław Stanisław Sitkowski (ur. 12 lutego 1924 w Warszawie, zm. 1 kwietnia 2010 tamże) – polski lekarz, kardiochirurg, profesor nauk medycznych, powstaniec warszawski. Jeden z pionierów polskiej kardiochirurgii, nauczyciel polskich kardiochirurgów, w tym Zbigniewa Religi. \\n\\n    `QUERY`: Jak miał na imię polski kardiochirurg, profesor Religa?\\n\\n    `ANSWER`:\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:58<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = {}\n",
    "\n",
    "for layer_id in tqdm(range(40)):\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, kl_div, candidate_premature_layers=[layer_id], max_length=100)\n",
    "    data[layer_id] = all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_len = len(prompt)\n",
    "\n",
    "# data_2 = {\n",
    "#     K: V\n",
    "#     for K, V in data.items()\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question. \n",
      "    `CONTEXT`: `Dokument [1]:` Wacław Stanisław Sitkowski (ur. 12 lutego 1924 w Warszawie, zm. 1 kwietnia 2010 tamże) – polski lekarz, kardiochirurg, profesor nauk medycznych, powstaniec warszawski. Jeden z pionierów polskiej kardiochirurgii, nauczyciel polskich kardiochirurgów, w tym Zbigniewa Religi. \n",
      "\n",
      "    `QUERY`: Jak miał na imię polski kardiochirurg, profesor Religa?\n",
      "\n",
      "    `ANSWER`:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '```\\nWacław \\n```\\n\\n',\n",
       " 1: '```\\nWacław \\n```\\n\\n',\n",
       " 2: 'Wacław\\n',\n",
       " 3: '```\\nWacław \\n```\\n\\n',\n",
       " 4: '```\\nWacław \\n```\\n\\n',\n",
       " 5: '```\\nWacław \\n```\\n\\n',\n",
       " 6: '```\\nWacław \\n```\\n\\n',\n",
       " 7: '```\\nWacław \\n```\\n\\n',\n",
       " 8: '```\\nWacław Stanisław Sitkowski \\n```',\n",
       " 9: '```\\nWacław Stanisław Sitkowski \\n```',\n",
       " 10: '```\\nWacław Stanisław Sitkowski \\n```',\n",
       " 11: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 12: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 13: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 14: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 15: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 16: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 17: '```\\nWacław Stanisław Sitkowski\\n```',\n",
       " 18: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n',\n",
       " 19: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n',\n",
       " 20: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n',\n",
       " 21: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n',\n",
       " 22: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n',\n",
       " 23: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n',\n",
       " 24: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n',\n",
       " 25: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n',\n",
       " 26: '```\\nWacław Stanisław Sitkowski\\n```\\n\\n\\n',\n",
       " 27: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 28: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 29: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 30: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 31: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 32: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 33: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 34: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 35: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 36: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 37: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 38: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n',\n",
       " 39: '```\\nWacław Stanisław Sitkowski \\n```\\n\\n\\n'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question.  \n",
    "`CONTEXT`: `Document [1]:` Wacław Stanisław Sitkowski (born February 12, 1924, in Warsaw, died April 1, 2010, in the same city) – a Polish doctor, cardiac surgeon, professor of medical sciences, and Warsaw Uprising insurgent. One of the pioneers of Polish cardiac surgery, a mentor to Polish cardiac surgeons, including Zbigniew Religa.  \n",
    "\n",
    "`QUERY`: What was the first name of the Polish cardiac surgeon, Professor Religa?  \n",
    "\n",
    "`ANSWER`:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for layer_id in tqdm(range(40)):\n",
    "    all_text = generate_text(prompt, model, tokenizer, device, kl_div, candidate_premature_layers=[layer_id], max_length=100)\n",
    "    data[layer_id] = all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context `CONTEXT` and the query `QUERY` below, please provide an answer `ANSWER` to the question.  \n",
      "`CONTEXT`: `Document [1]:` Wacław Stanisław Sitkowski (born February 12, 1924, in Warsaw, died April 1, 2010, in the same city) – a Polish doctor, cardiac surgeon, professor of medical sciences, and Warsaw Uprising insurgent. One of the pioneers of Polish cardiac surgery, a mentor to Polish cardiac surgeons, including Zbigniew Religa.  \n",
      "\n",
      "`QUERY`: What was the first name of the Polish cardiac surgeon, Professor Religa?  \n",
      "\n",
      "`ANSWER`:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Zbigniew \\n\\n\\n',\n",
       " 1: 'Zbigniew \\n\\n\\n',\n",
       " 2: 'Zbigniew \\n\\n\\n',\n",
       " 3: 'Zbigniew \\n',\n",
       " 4: 'Zbigniew \\n',\n",
       " 5: 'Zbigniew \\n\\n\\n',\n",
       " 6: 'Zbigniew \\n\\n\\n',\n",
       " 7: 'Zbigniew \\n\\n\\n',\n",
       " 8: 'Zbigniew',\n",
       " 9: 'Zbigniew',\n",
       " 10: 'Zbigniew',\n",
       " 11: 'Zbigniew',\n",
       " 12: 'Zbigniew',\n",
       " 13: 'Zbigniew',\n",
       " 14: 'Zbigniew',\n",
       " 15: 'Zbigniew',\n",
       " 16: 'Zbigniew',\n",
       " 17: 'Zbigniew',\n",
       " 18: 'Zbigniew',\n",
       " 19: 'Zbigniew',\n",
       " 20: 'Zbigniew',\n",
       " 21: 'Zbigniew',\n",
       " 22: 'Zbigniew',\n",
       " 23: 'Zbigniew',\n",
       " 24: 'Zbigniew',\n",
       " 25: 'Zbigniew\\n',\n",
       " 26: 'Zbigniew\\n',\n",
       " 27: 'Zbigniew\\n',\n",
       " 28: 'Zbigniew\\n',\n",
       " 29: 'Zbigniew\\n',\n",
       " 30: 'Zbigniew\\n',\n",
       " 31: 'Zbigniew\\n',\n",
       " 32: 'Zbigniew\\n',\n",
       " 33: 'Zbigniew\\n',\n",
       " 34: 'Zbigniew\\n',\n",
       " 35: 'Zbigniew\\n',\n",
       " 36: 'Zbigniew\\n',\n",
       " 37: 'Zbigniew\\n',\n",
       " 38: 'Zbigniew\\n',\n",
       " 39: 'Zbigniew\\n'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "golem-ner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
