{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import io\n",
    "from google.cloud import storage\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This package will be included in our repo, but it is only a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from golemai.nlp.prompts import QUERY_INTRO_NO_ANS, SYSTEM_MSG_RAG, SYSTEM_MSG_RAG_SHORT\n",
    "from golemai.nlp.llm_module import prepare_prompt\n",
    "from golemai.nlp.llm_resp_gen import LLMRespGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(), torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "DATASET_FILE = 'new_version_merged_df.parquet'\n",
    "QUESTION_COL = 'question'\n",
    "CONTEXT_COL = 'context'\n",
    "ANSWER_COL = 'answer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPTS_DIR = 'scripts'\n",
    "GEMMA_DIR = 'gemma2_new_dataset'\n",
    "ATT_DIR = 'attentions'\n",
    "\n",
    "ATT_PATH = os.path.join('..', SCRIPTS_DIR, GEMMA_DIR, ATT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset_path = os.path.join(\"..\", DATA_DIR, DATASET_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will load our standard `unsloth/gemma-2-9b-it-bnb-4bit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"unsloth/gemma-2-9b-it-bnb-4bit\"\n",
    "DTYPE = torch.bfloat16\n",
    "LOAD_IN_4BIT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map='auto',\n",
    "    torch_dtype=DTYPE,\n",
    "    token=os.environ[\"HF_TOKEN\"],\n",
    "    # sliding_window=8192\n",
    "    # max_memory={0: \"4GB\", 1: \"3GB\"}\n",
    "    #attn_implementation=\"sdpa\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverted_tokenizer = {\n",
    "    v: k\n",
    "    for k, v in tokenizer.get_vocab().items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input_str = \"Stolicą Polski jest Waszyngton DC bardzo lubię ten kraj.\"\n",
    "problematic_span = [' Waszyngton DC']\n",
    "toknized_input = tokenizer(sample_input_str, return_tensors=\"pt\")\n",
    "\n",
    "toknized_input.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_span = tokenizer(problematic_span, return_tensors=\"pt\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: <bos>\n",
      "5537: Sto\n",
      "720: lic\n",
      "235524: ą\n",
      "70456: ▁Polski\n",
      "9497: ▁jest\n",
      "9626: ▁Was\n",
      "1930: zy\n",
      "512: ng\n",
      "1166: ton\n",
      "11399: ▁DC\n",
      "38222: ▁bardzo\n",
      "15747: ▁lub\n",
      "44602: ię\n",
      "2797: ▁ten\n",
      "65170: ▁kraj\n",
      "235265: .\n"
     ]
    }
   ],
   "source": [
    "for k in toknized_input['input_ids'][0]:\n",
    "    print(f\"{k}: {reverted_tokenizer[k.item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9626: ▁Was\n",
      "1930: zy\n",
      "512: ng\n",
      "1166: ton\n",
      "11399: ▁DC\n"
     ]
    }
   ],
   "source": [
    "for k in tokenized_span['input_ids'][0]:\n",
    "    print(f\"{k}: {reverted_tokenizer[k.item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str_ids = toknized_input['input_ids'][0]\n",
    "span_ids = tokenized_span['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([     2,   5537,    720, 235524,  70456,   9497,   9626,   1930,    512,\n",
       "           1166,  11399,  38222,  15747,  44602,   2797,  65170, 235265]),\n",
       " tensor([ 9626,  1930,   512,  1166, 11399]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str_ids, span_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_span_positions(input_ids, span_ids):\n",
    "    \n",
    "    input_len = len(input_ids)\n",
    "    span_len = len(span_ids)\n",
    "    \n",
    "    for i in range(input_len - span_len + 1):\n",
    "\n",
    "        if torch.equal(input_ids[i:i+span_len], span_ids):\n",
    "            return i, i + span_len - 1\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "start_pos, end_pos = find_span_positions(input_str_ids, span_ids)\n",
    "start_pos, end_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_input = torch.zeros_like(input_str_ids)\n",
    "labels_input[start_pos:end_pos + 1] = 1\n",
    "labels_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 5537, 720, 235524, 70456, 9497, 9626, 1930, 512, 1166, 11399, 38222, 15747, 44602, 2797, 65170, 235265], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 3), (3, 6), (6, 7), (7, 14), (14, 19), (19, 23), (23, 25), (25, 27), (27, 30), (30, 33), (33, 40), (40, 44), (44, 46), (46, 50), (50, 55), (55, 56)]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizer(sample_input_str, return_offsets_mapping=True)\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does labels look like - small sample check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_files = [\n",
    "    'gemma-2-9b-it-bnb-4bit_2024-11-17_13-44.json',\n",
    "    'gemma-2-9b-it-bnb-4bit_2024-11-29_00-56.json',\n",
    "    'gemma-2-9b-it-bnb-4bit_2024-11-29_01-31.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_json(os.path.join('..', 'scripts', eval_files[0]), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = None\n",
    "\n",
    "for f in eval_files:\n",
    "\n",
    "    eval_df = pd.read_json(os.path.join('..', 'scripts', f), lines=True)\n",
    "    if 'index' in eval_df.columns:\n",
    "        eval_df = eval_df.rename(columns={'index': 'id'})\n",
    "\n",
    "    if merged_df is None:\n",
    "        merged_df = eval_df\n",
    "    else:\n",
    "\n",
    "        merged_df = pd.concat([merged_df, eval_df], ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>response</th>\n",
       "      <th>decision</th>\n",
       "      <th>gpt4_explanation</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>cost</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#Document#: `Dokument [1]:` 18 sierpnia królow...</td>\n",
       "      <td>130</td>\n",
       "      <td>Wielka Armada liczyła 125 statków.</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that \"Wielka Armada...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#Document#: `Dokument [ \"Post Malone\" ]:` 20 l...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states, \"Nie mogę udzielić...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>#Document#: `Dokument [ \"Ouija (2015 film)\" ]:...</td>\n",
       "      <td>Ishita Dutta</td>\n",
       "      <td>Ishita Dutta</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that \"Ishita Dutta\"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.009995</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>#Document#: `Dokument [ \"Gotham Independent Fi...</td>\n",
       "      <td>scenarzystka</td>\n",
       "      <td>Obydwóch reżyserzy filmowi.</td>\n",
       "      <td>False</td>\n",
       "      <td>The proposed answer states that both Sidney Lu...</td>\n",
       "      <td>[\"Obydwóch reżyserzy filmowi\"]</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>#Document#: `Dokument [ \"Joanna Jędrzejczyk\" ]...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>W programie TVN Turbo MMAster.</td>\n",
       "      <td>False</td>\n",
       "      <td>The proposed answer states that Joanna Jędrzej...</td>\n",
       "      <td>[\"W programie TVN Turbo MMAster\"]</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>poquad_v2_27489</td>\n",
       "      <td>#Document#: `Dokument [ \"The Falling Man\" ]:` ...</td>\n",
       "      <td>106 i 107</td>\n",
       "      <td>Na 106 i 107 piętrze.</td>\n",
       "      <td>True</td>\n",
       "      <td>The document states that the restaurant Window...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>poquad_v2_11468</td>\n",
       "      <td>#Document#: `Dokument [ \"Red Hot Chili Peppers...</td>\n",
       "      <td>Give It Away</td>\n",
       "      <td>Give It Away</td>\n",
       "      <td>True</td>\n",
       "      <td>The document states that the song \"Give It Awa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>poquad_v2_9258</td>\n",
       "      <td>#Document#: `Dokument [ \"USS Wahoo (SS-238)\" ]...</td>\n",
       "      <td>tak</td>\n",
       "      <td>Tak, w tekście wspomniano, że Komandor Kennedy...</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that \"Komandor Kenn...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>poquad_v2_8449</td>\n",
       "      <td>#Document#: `Dokument [ \"Kalifornia\" ]:` Hiszp...</td>\n",
       "      <td>w wyniku powstania przeciwko władzy Hiszpanii</td>\n",
       "      <td>W wyniku powstania przeciwko władzy Hiszpanii ...</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states: \"W wyniku powstani...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>poquad_v2_52136</td>\n",
       "      <td>#Document#: `Dokument [ \"Sroka zwyczajna\" ]:` ...</td>\n",
       "      <td>Claude Monet</td>\n",
       "      <td>Claude Monet</td>\n",
       "      <td>True</td>\n",
       "      <td>The document states that \"Claude Monet na obra...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5997 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           document  \\\n",
       "0                   0  #Document#: `Dokument [1]:` 18 sierpnia królow...   \n",
       "1                   1  #Document#: `Dokument [ \"Post Malone\" ]:` 20 l...   \n",
       "2                   2  #Document#: `Dokument [ \"Ouija (2015 film)\" ]:...   \n",
       "3                   3  #Document#: `Dokument [ \"Gotham Independent Fi...   \n",
       "4                   4  #Document#: `Dokument [ \"Joanna Jędrzejczyk\" ]...   \n",
       "...               ...                                                ...   \n",
       "5992  poquad_v2_27489  #Document#: `Dokument [ \"The Falling Man\" ]:` ...   \n",
       "5993  poquad_v2_11468  #Document#: `Dokument [ \"Red Hot Chili Peppers...   \n",
       "5994   poquad_v2_9258  #Document#: `Dokument [ \"USS Wahoo (SS-238)\" ]...   \n",
       "5995   poquad_v2_8449  #Document#: `Dokument [ \"Kalifornia\" ]:` Hiszp...   \n",
       "5996  poquad_v2_52136  #Document#: `Dokument [ \"Sroka zwyczajna\" ]:` ...   \n",
       "\n",
       "                                           ground_truth  \\\n",
       "0                                                   130   \n",
       "1     Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "2                                          Ishita Dutta   \n",
       "3                                          scenarzystka   \n",
       "4     Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "...                                                 ...   \n",
       "5992                                          106 i 107   \n",
       "5993                                       Give It Away   \n",
       "5994                                                tak   \n",
       "5995      w wyniku powstania przeciwko władzy Hiszpanii   \n",
       "5996                                       Claude Monet   \n",
       "\n",
       "                                               response  decision  \\\n",
       "0                    Wielka Armada liczyła 125 statków.      True   \n",
       "1     Nie mogę udzielić odpowiedzi na to pytanie na ...      True   \n",
       "2                                          Ishita Dutta      True   \n",
       "3                           Obydwóch reżyserzy filmowi.     False   \n",
       "4                        W programie TVN Turbo MMAster.     False   \n",
       "...                                                 ...       ...   \n",
       "5992                              Na 106 i 107 piętrze.      True   \n",
       "5993                                       Give It Away      True   \n",
       "5994  Tak, w tekście wspomniano, że Komandor Kennedy...      True   \n",
       "5995  W wyniku powstania przeciwko władzy Hiszpanii ...      True   \n",
       "5996                                       Claude Monet      True   \n",
       "\n",
       "                                       gpt4_explanation  \\\n",
       "0     The proposed answer states that \"Wielka Armada...   \n",
       "1     The proposed answer states, \"Nie mogę udzielić...   \n",
       "2     The proposed answer states that \"Ishita Dutta\"...   \n",
       "3     The proposed answer states that both Sidney Lu...   \n",
       "4     The proposed answer states that Joanna Jędrzej...   \n",
       "...                                                 ...   \n",
       "5992  The document states that the restaurant Window...   \n",
       "5993  The document states that the song \"Give It Awa...   \n",
       "5994  The proposed answer states that \"Komandor Kenn...   \n",
       "5995  The proposed answer states: \"W wyniku powstani...   \n",
       "5996  The document states that \"Claude Monet na obra...   \n",
       "\n",
       "                      problematic_spans      cost  \\\n",
       "0                                    []  0.008440   \n",
       "1                                    []  0.005290   \n",
       "2                                    []  0.009995   \n",
       "3        [\"Obydwóch reżyserzy filmowi\"]  0.006190   \n",
       "4     [\"W programie TVN Turbo MMAster\"]  0.004450   \n",
       "...                                 ...       ...   \n",
       "5992                                 []  0.003505   \n",
       "5993                                 []  0.003855   \n",
       "5994                                 []  0.007040   \n",
       "5995                                 []  0.004270   \n",
       "5996                                 []  0.003550   \n",
       "\n",
       "                                                 prompt  \n",
       "0     You will be provided with a document and a pro...  \n",
       "1     You will be provided with a document and a pro...  \n",
       "2     You will be provided with a document and a pro...  \n",
       "3     You will be provided with a document and a pro...  \n",
       "4     You will be provided with a document and a pro...  \n",
       "...                                                 ...  \n",
       "5992  You will be provided with a document and a pro...  \n",
       "5993  You will be provided with a document and a pro...  \n",
       "5994  You will be provided with a document and a pro...  \n",
       "5995  You will be provided with a document and a pro...  \n",
       "5996  You will be provided with a document and a pro...  \n",
       "\n",
       "[5997 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function to Find Indices\n",
    "Define a function that takes a row of the DataFrame and finds the starting and ending indices of each substring in 'problematic_spans' within 'model_response'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(response, spans) -> list:\n",
    "    \"\"\"\n",
    "    Function to find the starting and ending indices of each substring in 'problematic_spans' within 'model_response'.\n",
    "    Returns a list of tuples (start, end) for each problematic span.\n",
    "    If a span cannot be found, it returns (None, None).\n",
    "    \"\"\"\n",
    "\n",
    "    indices = []\n",
    "    if isinstance(spans, str):\n",
    "        spans = [spans]\n",
    "\n",
    "    if spans is None:\n",
    "        return None\n",
    "    \n",
    "    for span in spans:\n",
    "        start = response.rfind(span)\n",
    "        if start != -1:\n",
    "            end = start + len(span)\n",
    "            indices.append((start, end))\n",
    "        else:\n",
    "            indices.append((None, None))\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_parquet(os.path.join('..', 'data', 'research_sample_with_indices.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>formatted_context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>answer_length</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>model_response</th>\n",
       "      <th>gpt_index</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>hallu_indicies</th>\n",
       "      <th>hallu_tokens</th>\n",
       "      <th>contain_hallu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4172</td>\n",
       "      <td>polqa_2503</td>\n",
       "      <td>polqa</td>\n",
       "      <td>Ile okrętów w 1588 r. liczyła Wielka Armada: 1...</td>\n",
       "      <td>130</td>\n",
       "      <td>`Dokument [1]:` 18 sierpnia królowa dokonała p...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>1366</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>Wielka Armada liczyła 125 statków.</td>\n",
       "      <td>0</td>\n",
       "      <td>1123</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1895</td>\n",
       "      <td>poquad_v2_4138</td>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Po ilu dniach od premiery jego utwór \"Psycho\" ...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>`Dokument [ \"Post Malone\" ]:` 20 lutego 2018 r...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>607</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              id    dataset  \\\n",
       "0   4172      polqa_2503      polqa   \n",
       "1   1895  poquad_v2_4138  poquad_v2   \n",
       "\n",
       "                                               query  \\\n",
       "0  Ile okrętów w 1588 r. liczyła Wielka Armada: 1...   \n",
       "1  Po ilu dniach od premiery jego utwór \"Psycho\" ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                                130   \n",
       "1  Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  `Dokument [1]:` 18 sierpnia królowa dokonała p...   \n",
       "1  `Dokument [ \"Post Malone\" ]:` 20 lutego 2018 r...   \n",
       "\n",
       "                                   formatted_context  context_length  \\\n",
       "0  <bos><start_of_turn>user\\nYou are a helpful as...            1366   \n",
       "1  <bos><start_of_turn>user\\nYou are a helpful as...             607   \n",
       "\n",
       "   answer_length problematic_spans  \\\n",
       "0              4                []   \n",
       "1             17                []   \n",
       "\n",
       "                                      model_response  gpt_index  \\\n",
       "0                 Wielka Armada liczyła 125 statków.          0   \n",
       "1  Nie mogę udzielić odpowiedzi na to pytanie na ...          1   \n",
       "\n",
       "   prompt_length hallu_indicies  \\\n",
       "0           1123             []   \n",
       "1            364             []   \n",
       "\n",
       "                                        hallu_tokens  contain_hallu  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          False  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          False  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>response</th>\n",
       "      <th>decision</th>\n",
       "      <th>gpt4_explanation</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>cost</th>\n",
       "      <th>prompt</th>\n",
       "      <th>gpt_index</th>\n",
       "      <th>id_df_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#Document#: `Dokument [1]:` 18 sierpnia królow...</td>\n",
       "      <td>130</td>\n",
       "      <td>Wielka Armada liczyła 125 statków.</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that \"Wielka Armada...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>polqa_2503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#Document#: `Dokument [ \"Post Malone\" ]:` 20 l...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states, \"Nie mogę udzielić...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>poquad_v2_4138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                           document  \\\n",
       "0  0  #Document#: `Dokument [1]:` 18 sierpnia królow...   \n",
       "1  1  #Document#: `Dokument [ \"Post Malone\" ]:` 20 l...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0                                                130   \n",
       "1  Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "\n",
       "                                            response  decision  \\\n",
       "0                 Wielka Armada liczyła 125 statków.      True   \n",
       "1  Nie mogę udzielić odpowiedzi na to pytanie na ...      True   \n",
       "\n",
       "                                    gpt4_explanation problematic_spans  \\\n",
       "0  The proposed answer states that \"Wielka Armada...                []   \n",
       "1  The proposed answer states, \"Nie mogę udzielić...                []   \n",
       "\n",
       "      cost                                             prompt  gpt_index  \\\n",
       "0  0.00844  You will be provided with a document and a pro...        0.0   \n",
       "1  0.00529  You will be provided with a document and a pro...        1.0   \n",
       "\n",
       "        id_df_res  \n",
       "0      polqa_2503  \n",
       "1  poquad_v2_4138  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(df_res[['gpt_index', 'id']], left_on='id', right_on='gpt_index', how='left', suffixes=('', '_df_res'))\n",
    "merged_df['id'] = merged_df['id_df_res'].combine_first(merged_df['id'])\n",
    "merged_df.drop(columns=['id_df_res', 'gpt_index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df['id']\n",
    "merged_df.index = merged_df['id']\n",
    "\n",
    "df = df.join(merged_df[['response', 'decision', 'problematic_spans']], how='inner')\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.rename(columns={'response': 'model_response'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['problematic_spans'] = df['problematic_spans'].apply(lambda x: [span.removeprefix('\"').removesuffix('\"') for span in x] if x is not None else None)\n",
    "df = df.loc[df['model_response'] != '<CUDA_ERROR>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>model_response</th>\n",
       "      <th>decision</th>\n",
       "      <th>problematic_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bioask_1000</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Czy możliwe jest oczyszczenie pseudopodiów do ...</td>\n",
       "      <td>Pseudopodia mogą być oczyszczane przy użyciu r...</td>\n",
       "      <td>`Dokument [1]:` Migracja komórek wymaga wypukł...</td>\n",
       "      <td>1547</td>\n",
       "      <td>Tak, tekst mówi o metodzie oczyszczania pseudo...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_1001</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Jaki jest mechanizm działania deaminazy cytydy...</td>\n",
       "      <td>Podczas odwrotnej transkrypcji APOBEC3G deamin...</td>\n",
       "      <td>`Dokument [1]:` Rodzina deaminaz deoksycytydyn...</td>\n",
       "      <td>2445</td>\n",
       "      <td>APOBEC3G hamuje replikację wirusa HIV-1 poprze...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset                                              query  \\\n",
       "bioask_1000  bioask  Czy możliwe jest oczyszczenie pseudopodiów do ...   \n",
       "bioask_1001  bioask  Jaki jest mechanizm działania deaminazy cytydy...   \n",
       "\n",
       "                                                        answer  \\\n",
       "bioask_1000  Pseudopodia mogą być oczyszczane przy użyciu r...   \n",
       "bioask_1001  Podczas odwrotnej transkrypcji APOBEC3G deamin...   \n",
       "\n",
       "                                                       context  \\\n",
       "bioask_1000  `Dokument [1]:` Migracja komórek wymaga wypukł...   \n",
       "bioask_1001  `Dokument [1]:` Rodzina deaminaz deoksycytydyn...   \n",
       "\n",
       "             context_length  \\\n",
       "bioask_1000            1547   \n",
       "bioask_1001            2445   \n",
       "\n",
       "                                                model_response  decision  \\\n",
       "bioask_1000  Tak, tekst mówi o metodzie oczyszczania pseudo...      True   \n",
       "bioask_1001  APOBEC3G hamuje replikację wirusa HIV-1 poprze...      True   \n",
       "\n",
       "            problematic_spans  \n",
       "bioask_1000                []  \n",
       "bioask_1001                []  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda, device_num = 1\n"
     ]
    }
   ],
   "source": [
    "llm_rg = LLMRespGen(\n",
    "    df=df,\n",
    "    id_col='id',\n",
    "    model_type='local',\n",
    "    system_msg=SYSTEM_MSG_RAG_SHORT,\n",
    "    prompt_template=QUERY_INTRO_NO_ANS,\n",
    "    batch_size=1,\n",
    "    device_num=1\n",
    ")\n",
    "\n",
    "llm_rg.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['indices'] = df.apply(lambda row: find_indices(row['model_response'], row['problematic_spans']), axis=1)\n",
    "df = df.loc[~df.index.isin([i for i, row in df.iterrows() if any(index == (None, None) for index in row['indices'])])]\n",
    "df = df.drop(columns=['indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>model_response</th>\n",
       "      <th>decision</th>\n",
       "      <th>problematic_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bioask_1000</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Czy możliwe jest oczyszczenie pseudopodiów do ...</td>\n",
       "      <td>Pseudopodia mogą być oczyszczane przy użyciu r...</td>\n",
       "      <td>`Dokument [1]:` Migracja komórek wymaga wypukł...</td>\n",
       "      <td>1547</td>\n",
       "      <td>Tak, tekst mówi o metodzie oczyszczania pseudo...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_1001</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Jaki jest mechanizm działania deaminazy cytydy...</td>\n",
       "      <td>Podczas odwrotnej transkrypcji APOBEC3G deamin...</td>\n",
       "      <td>`Dokument [1]:` Rodzina deaminaz deoksycytydyn...</td>\n",
       "      <td>2445</td>\n",
       "      <td>APOBEC3G hamuje replikację wirusa HIV-1 poprze...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_1009</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Ile selenoprotein jest zakodowanych w ludzkim ...</td>\n",
       "      <td>25. 15kDa, DI1, DI2, DI3, GPx1, GPx2, GPx3, GP...</td>\n",
       "      <td>`Dokument [1]:` TŁO: Białka zawierające seleno...</td>\n",
       "      <td>1296</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_101</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Która z ludzkich selenoprotein zawiera kilka r...</td>\n",
       "      <td>Selenoproteina P, która zawiera 10 selenocystein.</td>\n",
       "      <td>`Dokument [1]:` Selenoproteina P (Sepp1) jest ...</td>\n",
       "      <td>2282</td>\n",
       "      <td>Ludzka selenoproteina P (HSelP) zawiera 10 res...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_1021</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Jak leczy się chorobę Riedela (zapalenie tarcz...</td>\n",
       "      <td>Zapalenie tarczycy typu Riedela jest rzadkim s...</td>\n",
       "      <td>`Dokument [1]:` Wstęp: Inwazyjne włókniste zap...</td>\n",
       "      <td>2457</td>\n",
       "      <td>Leczenie kortykosteroidami w zapaleniu tarczyc...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9744</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Co było przyczyną zniesienia święta Trzeciego ...</td>\n",
       "      <td>krwawe demonstracje studenckie</td>\n",
       "      <td>`Dokument [ \"Święto Narodowe Trzeciego Maja\" ]...</td>\n",
       "      <td>347</td>\n",
       "      <td>Krwawych demonstracji studenckich w 1946 roku.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9909</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Dlaczego zamknięto pub Edwardsa w Dudley?</td>\n",
       "      <td>z powodu pożaru</td>\n",
       "      <td>`Dokument [ \"Duncan Edwards\" ]:` Edwards uważa...</td>\n",
       "      <td>368</td>\n",
       "      <td>W 2001 jego imieniem nazwano jeden z pubów zna...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9939</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Jaki piłkarz uległ wypadkowi podczas Ligii Mis...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>`Dokument [ \"Chelsea F.C.\" ]:` Głównym celem M...</td>\n",
       "      <td>507</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9967</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>W którym roku prawdopodobnie wymyślono \"grę\"?</td>\n",
       "      <td>1977</td>\n",
       "      <td>`Dokument [ \"Gra (gra umysłowa)\" ]:` Geneza „G...</td>\n",
       "      <td>327</td>\n",
       "      <td>1977</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9997</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Czy Franek Dolas trafił do więzienia?</td>\n",
       "      <td>tak</td>\n",
       "      <td>`Dokument [ \"Jak rozpętałem drugą wojnę świato...</td>\n",
       "      <td>477</td>\n",
       "      <td>Tak, Franek Dolas trafił do więzienia.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5896 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                                              query  \\\n",
       "bioask_1000        bioask  Czy możliwe jest oczyszczenie pseudopodiów do ...   \n",
       "bioask_1001        bioask  Jaki jest mechanizm działania deaminazy cytydy...   \n",
       "bioask_1009        bioask  Ile selenoprotein jest zakodowanych w ludzkim ...   \n",
       "bioask_101         bioask  Która z ludzkich selenoprotein zawiera kilka r...   \n",
       "bioask_1021        bioask  Jak leczy się chorobę Riedela (zapalenie tarcz...   \n",
       "...                   ...                                                ...   \n",
       "poquad_v2_9744  poquad_v2  Co było przyczyną zniesienia święta Trzeciego ...   \n",
       "poquad_v2_9909  poquad_v2          Dlaczego zamknięto pub Edwardsa w Dudley?   \n",
       "poquad_v2_9939  poquad_v2  Jaki piłkarz uległ wypadkowi podczas Ligii Mis...   \n",
       "poquad_v2_9967  poquad_v2      W którym roku prawdopodobnie wymyślono \"grę\"?   \n",
       "poquad_v2_9997  poquad_v2              Czy Franek Dolas trafił do więzienia?   \n",
       "\n",
       "                                                           answer  \\\n",
       "bioask_1000     Pseudopodia mogą być oczyszczane przy użyciu r...   \n",
       "bioask_1001     Podczas odwrotnej transkrypcji APOBEC3G deamin...   \n",
       "bioask_1009     25. 15kDa, DI1, DI2, DI3, GPx1, GPx2, GPx3, GP...   \n",
       "bioask_101      Selenoproteina P, która zawiera 10 selenocystein.   \n",
       "bioask_1021     Zapalenie tarczycy typu Riedela jest rzadkim s...   \n",
       "...                                                           ...   \n",
       "poquad_v2_9744                     krwawe demonstracje studenckie   \n",
       "poquad_v2_9909                                    z powodu pożaru   \n",
       "poquad_v2_9939  Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "poquad_v2_9967                                               1977   \n",
       "poquad_v2_9997                                                tak   \n",
       "\n",
       "                                                          context  \\\n",
       "bioask_1000     `Dokument [1]:` Migracja komórek wymaga wypukł...   \n",
       "bioask_1001     `Dokument [1]:` Rodzina deaminaz deoksycytydyn...   \n",
       "bioask_1009     `Dokument [1]:` TŁO: Białka zawierające seleno...   \n",
       "bioask_101      `Dokument [1]:` Selenoproteina P (Sepp1) jest ...   \n",
       "bioask_1021     `Dokument [1]:` Wstęp: Inwazyjne włókniste zap...   \n",
       "...                                                           ...   \n",
       "poquad_v2_9744  `Dokument [ \"Święto Narodowe Trzeciego Maja\" ]...   \n",
       "poquad_v2_9909  `Dokument [ \"Duncan Edwards\" ]:` Edwards uważa...   \n",
       "poquad_v2_9939  `Dokument [ \"Chelsea F.C.\" ]:` Głównym celem M...   \n",
       "poquad_v2_9967  `Dokument [ \"Gra (gra umysłowa)\" ]:` Geneza „G...   \n",
       "poquad_v2_9997  `Dokument [ \"Jak rozpętałem drugą wojnę świato...   \n",
       "\n",
       "                context_length  \\\n",
       "bioask_1000               1547   \n",
       "bioask_1001               2445   \n",
       "bioask_1009               1296   \n",
       "bioask_101                2282   \n",
       "bioask_1021               2457   \n",
       "...                        ...   \n",
       "poquad_v2_9744             347   \n",
       "poquad_v2_9909             368   \n",
       "poquad_v2_9939             507   \n",
       "poquad_v2_9967             327   \n",
       "poquad_v2_9997             477   \n",
       "\n",
       "                                                   model_response  decision  \\\n",
       "bioask_1000     Tak, tekst mówi o metodzie oczyszczania pseudo...      True   \n",
       "bioask_1001     APOBEC3G hamuje replikację wirusa HIV-1 poprze...      True   \n",
       "bioask_1009                                                    25      True   \n",
       "bioask_101      Ludzka selenoproteina P (HSelP) zawiera 10 res...      True   \n",
       "bioask_1021     Leczenie kortykosteroidami w zapaleniu tarczyc...      True   \n",
       "...                                                           ...       ...   \n",
       "poquad_v2_9744     Krwawych demonstracji studenckich w 1946 roku.      True   \n",
       "poquad_v2_9909  W 2001 jego imieniem nazwano jeden z pubów zna...      True   \n",
       "poquad_v2_9939  Nie mogę udzielić odpowiedzi na to pytanie na ...      True   \n",
       "poquad_v2_9967                                               1977      True   \n",
       "poquad_v2_9997             Tak, Franek Dolas trafił do więzienia.      True   \n",
       "\n",
       "               problematic_spans  \n",
       "bioask_1000                   []  \n",
       "bioask_1001                   []  \n",
       "bioask_1009                   []  \n",
       "bioask_101                    []  \n",
       "bioask_1021                   []  \n",
       "...                          ...  \n",
       "poquad_v2_9744                []  \n",
       "poquad_v2_9909                []  \n",
       "poquad_v2_9939                []  \n",
       "poquad_v2_9967                []  \n",
       "poquad_v2_9997                []  \n",
       "\n",
       "[5896 rows x 8 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>model_response</th>\n",
       "      <th>decision</th>\n",
       "      <th>problematic_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bioask_1000</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Czy możliwe jest oczyszczenie pseudopodiów do ...</td>\n",
       "      <td>Pseudopodia mogą być oczyszczane przy użyciu r...</td>\n",
       "      <td>`Dokument [1]:` Migracja komórek wymaga wypukł...</td>\n",
       "      <td>1547</td>\n",
       "      <td>Tak, tekst mówi o metodzie oczyszczania pseudo...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_1001</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Jaki jest mechanizm działania deaminazy cytydy...</td>\n",
       "      <td>Podczas odwrotnej transkrypcji APOBEC3G deamin...</td>\n",
       "      <td>`Dokument [1]:` Rodzina deaminaz deoksycytydyn...</td>\n",
       "      <td>2445</td>\n",
       "      <td>APOBEC3G hamuje replikację wirusa HIV-1 poprze...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_1009</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Ile selenoprotein jest zakodowanych w ludzkim ...</td>\n",
       "      <td>25. 15kDa, DI1, DI2, DI3, GPx1, GPx2, GPx3, GP...</td>\n",
       "      <td>`Dokument [1]:` TŁO: Białka zawierające seleno...</td>\n",
       "      <td>1296</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_101</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Która z ludzkich selenoprotein zawiera kilka r...</td>\n",
       "      <td>Selenoproteina P, która zawiera 10 selenocystein.</td>\n",
       "      <td>`Dokument [1]:` Selenoproteina P (Sepp1) jest ...</td>\n",
       "      <td>2282</td>\n",
       "      <td>Ludzka selenoproteina P (HSelP) zawiera 10 res...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_1021</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Jak leczy się chorobę Riedela (zapalenie tarcz...</td>\n",
       "      <td>Zapalenie tarczycy typu Riedela jest rzadkim s...</td>\n",
       "      <td>`Dokument [1]:` Wstęp: Inwazyjne włókniste zap...</td>\n",
       "      <td>2457</td>\n",
       "      <td>Leczenie kortykosteroidami w zapaleniu tarczyc...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9744</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Co było przyczyną zniesienia święta Trzeciego ...</td>\n",
       "      <td>krwawe demonstracje studenckie</td>\n",
       "      <td>`Dokument [ \"Święto Narodowe Trzeciego Maja\" ]...</td>\n",
       "      <td>347</td>\n",
       "      <td>Krwawych demonstracji studenckich w 1946 roku.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9909</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Dlaczego zamknięto pub Edwardsa w Dudley?</td>\n",
       "      <td>z powodu pożaru</td>\n",
       "      <td>`Dokument [ \"Duncan Edwards\" ]:` Edwards uważa...</td>\n",
       "      <td>368</td>\n",
       "      <td>W 2001 jego imieniem nazwano jeden z pubów zna...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9939</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Jaki piłkarz uległ wypadkowi podczas Ligii Mis...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>`Dokument [ \"Chelsea F.C.\" ]:` Głównym celem M...</td>\n",
       "      <td>507</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9967</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>W którym roku prawdopodobnie wymyślono \"grę\"?</td>\n",
       "      <td>1977</td>\n",
       "      <td>`Dokument [ \"Gra (gra umysłowa)\" ]:` Geneza „G...</td>\n",
       "      <td>327</td>\n",
       "      <td>1977</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_9997</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Czy Franek Dolas trafił do więzienia?</td>\n",
       "      <td>tak</td>\n",
       "      <td>`Dokument [ \"Jak rozpętałem drugą wojnę świato...</td>\n",
       "      <td>477</td>\n",
       "      <td>Tak, Franek Dolas trafił do więzienia.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5896 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                                              query  \\\n",
       "bioask_1000        bioask  Czy możliwe jest oczyszczenie pseudopodiów do ...   \n",
       "bioask_1001        bioask  Jaki jest mechanizm działania deaminazy cytydy...   \n",
       "bioask_1009        bioask  Ile selenoprotein jest zakodowanych w ludzkim ...   \n",
       "bioask_101         bioask  Która z ludzkich selenoprotein zawiera kilka r...   \n",
       "bioask_1021        bioask  Jak leczy się chorobę Riedela (zapalenie tarcz...   \n",
       "...                   ...                                                ...   \n",
       "poquad_v2_9744  poquad_v2  Co było przyczyną zniesienia święta Trzeciego ...   \n",
       "poquad_v2_9909  poquad_v2          Dlaczego zamknięto pub Edwardsa w Dudley?   \n",
       "poquad_v2_9939  poquad_v2  Jaki piłkarz uległ wypadkowi podczas Ligii Mis...   \n",
       "poquad_v2_9967  poquad_v2      W którym roku prawdopodobnie wymyślono \"grę\"?   \n",
       "poquad_v2_9997  poquad_v2              Czy Franek Dolas trafił do więzienia?   \n",
       "\n",
       "                                                           answer  \\\n",
       "bioask_1000     Pseudopodia mogą być oczyszczane przy użyciu r...   \n",
       "bioask_1001     Podczas odwrotnej transkrypcji APOBEC3G deamin...   \n",
       "bioask_1009     25. 15kDa, DI1, DI2, DI3, GPx1, GPx2, GPx3, GP...   \n",
       "bioask_101      Selenoproteina P, która zawiera 10 selenocystein.   \n",
       "bioask_1021     Zapalenie tarczycy typu Riedela jest rzadkim s...   \n",
       "...                                                           ...   \n",
       "poquad_v2_9744                     krwawe demonstracje studenckie   \n",
       "poquad_v2_9909                                    z powodu pożaru   \n",
       "poquad_v2_9939  Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "poquad_v2_9967                                               1977   \n",
       "poquad_v2_9997                                                tak   \n",
       "\n",
       "                                                          context  \\\n",
       "bioask_1000     `Dokument [1]:` Migracja komórek wymaga wypukł...   \n",
       "bioask_1001     `Dokument [1]:` Rodzina deaminaz deoksycytydyn...   \n",
       "bioask_1009     `Dokument [1]:` TŁO: Białka zawierające seleno...   \n",
       "bioask_101      `Dokument [1]:` Selenoproteina P (Sepp1) jest ...   \n",
       "bioask_1021     `Dokument [1]:` Wstęp: Inwazyjne włókniste zap...   \n",
       "...                                                           ...   \n",
       "poquad_v2_9744  `Dokument [ \"Święto Narodowe Trzeciego Maja\" ]...   \n",
       "poquad_v2_9909  `Dokument [ \"Duncan Edwards\" ]:` Edwards uważa...   \n",
       "poquad_v2_9939  `Dokument [ \"Chelsea F.C.\" ]:` Głównym celem M...   \n",
       "poquad_v2_9967  `Dokument [ \"Gra (gra umysłowa)\" ]:` Geneza „G...   \n",
       "poquad_v2_9997  `Dokument [ \"Jak rozpętałem drugą wojnę świato...   \n",
       "\n",
       "                context_length  \\\n",
       "bioask_1000               1547   \n",
       "bioask_1001               2445   \n",
       "bioask_1009               1296   \n",
       "bioask_101                2282   \n",
       "bioask_1021               2457   \n",
       "...                        ...   \n",
       "poquad_v2_9744             347   \n",
       "poquad_v2_9909             368   \n",
       "poquad_v2_9939             507   \n",
       "poquad_v2_9967             327   \n",
       "poquad_v2_9997             477   \n",
       "\n",
       "                                                   model_response  decision  \\\n",
       "bioask_1000     Tak, tekst mówi o metodzie oczyszczania pseudo...      True   \n",
       "bioask_1001     APOBEC3G hamuje replikację wirusa HIV-1 poprze...      True   \n",
       "bioask_1009                                                    25      True   \n",
       "bioask_101      Ludzka selenoproteina P (HSelP) zawiera 10 res...      True   \n",
       "bioask_1021     Leczenie kortykosteroidami w zapaleniu tarczyc...      True   \n",
       "...                                                           ...       ...   \n",
       "poquad_v2_9744     Krwawych demonstracji studenckich w 1946 roku.      True   \n",
       "poquad_v2_9909  W 2001 jego imieniem nazwano jeden z pubów zna...      True   \n",
       "poquad_v2_9939  Nie mogę udzielić odpowiedzi na to pytanie na ...      True   \n",
       "poquad_v2_9967                                               1977      True   \n",
       "poquad_v2_9997             Tak, Franek Dolas trafił do więzienia.      True   \n",
       "\n",
       "               problematic_spans  \n",
       "bioask_1000                   []  \n",
       "bioask_1001                   []  \n",
       "bioask_1009                   []  \n",
       "bioask_101                    []  \n",
       "bioask_1021                   []  \n",
       "...                          ...  \n",
       "poquad_v2_9744                []  \n",
       "poquad_v2_9909                []  \n",
       "poquad_v2_9939                []  \n",
       "poquad_v2_9967                []  \n",
       "poquad_v2_9997                []  \n",
       "\n",
       "[5896 rows x 8 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>document</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>response</th>\n",
       "      <th>decision</th>\n",
       "      <th>gpt4_explanation</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>cost</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#Document#: `Dokument [1]:` 18 sierpnia królow...</td>\n",
       "      <td>130</td>\n",
       "      <td>Wielka Armada liczyła 125 statków.</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that \"Wielka Armada...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#Document#: `Dokument [ \"Post Malone\" ]:` 20 l...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states, \"Nie mogę udzielić...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>#Document#: `Dokument [ \"Ouija (2015 film)\" ]:...</td>\n",
       "      <td>Ishita Dutta</td>\n",
       "      <td>Ishita Dutta</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that \"Ishita Dutta\"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.009995</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>#Document#: `Dokument [ \"Gotham Independent Fi...</td>\n",
       "      <td>scenarzystka</td>\n",
       "      <td>Obydwóch reżyserzy filmowi.</td>\n",
       "      <td>False</td>\n",
       "      <td>The proposed answer states that both Sidney Lu...</td>\n",
       "      <td>[\"Obydwóch reżyserzy filmowi\"]</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>#Document#: `Dokument [ \"Joanna Jędrzejczyk\" ]...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>W programie TVN Turbo MMAster.</td>\n",
       "      <td>False</td>\n",
       "      <td>The proposed answer states that Joanna Jędrzej...</td>\n",
       "      <td>[\"W programie TVN Turbo MMAster\"]</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>675</td>\n",
       "      <td>#Document#: `Dokument [1]:` TŁO: Pacjenci z za...</td>\n",
       "      <td>Celem badania klinicznego HAMLET (Hemicraniect...</td>\n",
       "      <td>&lt;CUDA_ERROR&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that the aim of the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.020580</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>676</td>\n",
       "      <td>#Document#: `Dokument [ \"Schizofrenia\" ]:` Nie...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>&lt;CUDA_ERROR&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that it cannot prov...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>677</td>\n",
       "      <td>#Document#: `Dokument [ \"Hunters Green\" ]:` Hu...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that Martin Beck gr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>678</td>\n",
       "      <td>#Document#: `Dokument [ \"President of Guyana\" ...</td>\n",
       "      <td>Arthur Chung</td>\n",
       "      <td>Forbes Burnham</td>\n",
       "      <td>False</td>\n",
       "      <td>The proposed answer states that Forbes Burnham...</td>\n",
       "      <td>[\"Forbes Burnham\"]</td>\n",
       "      <td>0.010650</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>679</td>\n",
       "      <td>#Document#: `Dokument [ \"Montana gubernatorial...</td>\n",
       "      <td>Amanda Curtis</td>\n",
       "      <td>Amanda Curtis</td>\n",
       "      <td>True</td>\n",
       "      <td>The proposed answer states that Roy Brown's ru...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>You will be provided with a document and a pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                           document  \\\n",
       "0        0  #Document#: `Dokument [1]:` 18 sierpnia królow...   \n",
       "1        1  #Document#: `Dokument [ \"Post Malone\" ]:` 20 l...   \n",
       "2        2  #Document#: `Dokument [ \"Ouija (2015 film)\" ]:...   \n",
       "3        3  #Document#: `Dokument [ \"Gotham Independent Fi...   \n",
       "4        4  #Document#: `Dokument [ \"Joanna Jędrzejczyk\" ]...   \n",
       "..     ...                                                ...   \n",
       "675    675  #Document#: `Dokument [1]:` TŁO: Pacjenci z za...   \n",
       "676    676  #Document#: `Dokument [ \"Schizofrenia\" ]:` Nie...   \n",
       "677    677  #Document#: `Dokument [ \"Hunters Green\" ]:` Hu...   \n",
       "678    678  #Document#: `Dokument [ \"President of Guyana\" ...   \n",
       "679    679  #Document#: `Dokument [ \"Montana gubernatorial...   \n",
       "\n",
       "                                          ground_truth  \\\n",
       "0                                                  130   \n",
       "1    Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "2                                         Ishita Dutta   \n",
       "3                                         scenarzystka   \n",
       "4    Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "..                                                 ...   \n",
       "675  Celem badania klinicznego HAMLET (Hemicraniect...   \n",
       "676  Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "677                                      Niagara Falls   \n",
       "678                                       Arthur Chung   \n",
       "679                                      Amanda Curtis   \n",
       "\n",
       "                                              response  decision  \\\n",
       "0                   Wielka Armada liczyła 125 statków.      True   \n",
       "1    Nie mogę udzielić odpowiedzi na to pytanie na ...      True   \n",
       "2                                         Ishita Dutta      True   \n",
       "3                          Obydwóch reżyserzy filmowi.     False   \n",
       "4                       W programie TVN Turbo MMAster.     False   \n",
       "..                                                 ...       ...   \n",
       "675                                       <CUDA_ERROR>      True   \n",
       "676                                       <CUDA_ERROR>      True   \n",
       "677                                      Niagara Falls      True   \n",
       "678                                     Forbes Burnham     False   \n",
       "679                                      Amanda Curtis      True   \n",
       "\n",
       "                                      gpt4_explanation  \\\n",
       "0    The proposed answer states that \"Wielka Armada...   \n",
       "1    The proposed answer states, \"Nie mogę udzielić...   \n",
       "2    The proposed answer states that \"Ishita Dutta\"...   \n",
       "3    The proposed answer states that both Sidney Lu...   \n",
       "4    The proposed answer states that Joanna Jędrzej...   \n",
       "..                                                 ...   \n",
       "675  The proposed answer states that the aim of the...   \n",
       "676  The proposed answer states that it cannot prov...   \n",
       "677  The proposed answer states that Martin Beck gr...   \n",
       "678  The proposed answer states that Forbes Burnham...   \n",
       "679  The proposed answer states that Roy Brown's ru...   \n",
       "\n",
       "                     problematic_spans      cost  \\\n",
       "0                                   []  0.008440   \n",
       "1                                   []  0.005290   \n",
       "2                                   []  0.009995   \n",
       "3       [\"Obydwóch reżyserzy filmowi\"]  0.006190   \n",
       "4    [\"W programie TVN Turbo MMAster\"]  0.004450   \n",
       "..                                 ...       ...   \n",
       "675                                 []  0.020580   \n",
       "676                                 []  0.005235   \n",
       "677                                 []  0.009395   \n",
       "678                 [\"Forbes Burnham\"]  0.010650   \n",
       "679                                 []  0.011895   \n",
       "\n",
       "                                                prompt  \n",
       "0    You will be provided with a document and a pro...  \n",
       "1    You will be provided with a document and a pro...  \n",
       "2    You will be provided with a document and a pro...  \n",
       "3    You will be provided with a document and a pro...  \n",
       "4    You will be provided with a document and a pro...  \n",
       "..                                                 ...  \n",
       "675  You will be provided with a document and a pro...  \n",
       "676  You will be provided with a document and a pro...  \n",
       "677  You will be provided with a document and a pro...  \n",
       "678  You will be provided with a document and a pro...  \n",
       "679  You will be provided with a document and a pro...  \n",
       "\n",
       "[680 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: bioask_1000\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    print(f\"Index: {i}\")\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "foramtted_contexts = []\n",
    "n_prompt_tokens = []\n",
    "hallu_indicies = []\n",
    "hallu_tokens = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    formatted_prompt = llm_rg._get_ready_prompt(\n",
    "        row=row,\n",
    "        prompt_columns=['query', 'context']\n",
    "    )\n",
    "\n",
    "    add_special_tokens = False if i in merged_df['id'].values else True\n",
    "\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", padding=True, add_special_tokens=add_special_tokens)\n",
    "    n_prompt_tokens.append(inputs['input_ids'].shape[1])\n",
    "\n",
    "    formatted_context = f\"{tokenizer.decode(inputs['input_ids'][0])}{row['model_response']}\"\n",
    "    foramtted_contexts.append(formatted_context)\n",
    "\n",
    "    hallu_idx = find_indices(formatted_context, row['problematic_spans'])\n",
    "    hallu_indicies.append(hallu_idx)\n",
    "\n",
    "    inputs = tokenizer(formatted_context, return_tensors=\"pt\", padding=True, return_offsets_mapping=True, add_special_tokens=False)\n",
    "    offset_mappings = inputs['offset_mapping'][0].tolist()\n",
    "\n",
    "    hallu_mask = [0] * len(offset_mappings)\n",
    "\n",
    "    for idx, (start, end) in enumerate(offset_mappings):\n",
    "\n",
    "        for hallu_start, hallu_end in hallu_idx:\n",
    "            if start >= hallu_start and end <= hallu_end:\n",
    "                hallu_mask[idx] = 1\n",
    "                \n",
    "    hallu_tokens.append(hallu_mask)\n",
    "\n",
    "df['formatted_context'] = foramtted_contexts\n",
    "df['prompt_length'] = n_prompt_tokens\n",
    "df['hallu_indicies'] = hallu_indicies\n",
    "df['hallu_tokens'] = hallu_tokens\n",
    "df['contain_hallu'] = df['problematic_spans'].apply(lambda x: True if x else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>model_response</th>\n",
       "      <th>decision</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>formatted_context</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>hallu_indicies</th>\n",
       "      <th>hallu_tokens</th>\n",
       "      <th>contain_hallu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bioask_1000</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Czy możliwe jest oczyszczenie pseudopodiów do ...</td>\n",
       "      <td>Pseudopodia mogą być oczyszczane przy użyciu r...</td>\n",
       "      <td>`Dokument [1]:` Migracja komórek wymaga wypukł...</td>\n",
       "      <td>1547</td>\n",
       "      <td>Tak, tekst mówi o metodzie oczyszczania pseudo...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>1521</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_1001</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Jaki jest mechanizm działania deaminazy cytydy...</td>\n",
       "      <td>Podczas odwrotnej transkrypcji APOBEC3G deamin...</td>\n",
       "      <td>`Dokument [1]:` Rodzina deaminaz deoksycytydyn...</td>\n",
       "      <td>2445</td>\n",
       "      <td>APOBEC3G hamuje replikację wirusa HIV-1 poprze...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>2214</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset                                              query  \\\n",
       "bioask_1000  bioask  Czy możliwe jest oczyszczenie pseudopodiów do ...   \n",
       "bioask_1001  bioask  Jaki jest mechanizm działania deaminazy cytydy...   \n",
       "\n",
       "                                                        answer  \\\n",
       "bioask_1000  Pseudopodia mogą być oczyszczane przy użyciu r...   \n",
       "bioask_1001  Podczas odwrotnej transkrypcji APOBEC3G deamin...   \n",
       "\n",
       "                                                       context  \\\n",
       "bioask_1000  `Dokument [1]:` Migracja komórek wymaga wypukł...   \n",
       "bioask_1001  `Dokument [1]:` Rodzina deaminaz deoksycytydyn...   \n",
       "\n",
       "             context_length  \\\n",
       "bioask_1000            1547   \n",
       "bioask_1001            2445   \n",
       "\n",
       "                                                model_response  decision  \\\n",
       "bioask_1000  Tak, tekst mówi o metodzie oczyszczania pseudo...      True   \n",
       "bioask_1001  APOBEC3G hamuje replikację wirusa HIV-1 poprze...      True   \n",
       "\n",
       "            problematic_spans  \\\n",
       "bioask_1000                []   \n",
       "bioask_1001                []   \n",
       "\n",
       "                                             formatted_context  prompt_length  \\\n",
       "bioask_1000  <bos><start_of_turn>user\\nYou are a helpful as...           1521   \n",
       "bioask_1001  <bos><start_of_turn>user\\nYou are a helpful as...           2214   \n",
       "\n",
       "            hallu_indicies                                       hallu_tokens  \\\n",
       "bioask_1000             []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "bioask_1001             []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "             contain_hallu  \n",
       "bioask_1000          False  \n",
       "bioask_1001          False  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(os.path.join('..', DATA_DIR, 'all_examples_with_idx.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3427: row['model_response'] = 'Obydwóch reżyserzy filmowi.'\n",
      "row['problematic_spans'] = ['Obydwóch reżyserzy filmowi']\n",
      "to_show_spans = ['Obydwóch reżyserzy filmowi']\n",
      "\n",
      "2095: row['model_response'] = 'W programie TVN Turbo MMAster.'\n",
      "row['problematic_spans'] = ['W programie TVN Turbo MMAster']\n",
      "to_show_spans = ['W programie TVN Turbo MMAster']\n",
      "\n",
      "2729: row['model_response'] = 'Komitet Organizacyjny miał złoto ze skradzionych przedmiotów po zagazowanych Żydach.'\n",
      "row['problematic_spans'] = ['skradzionych przedmiotów']\n",
      "to_show_spans = ['skradzionych przedmiotów']\n",
      "\n",
      "4537: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4367: row['model_response'] = 'Crystal Springs is a ghost town in the Pahranagat Valley region of Lincoln County, Nevada in the United States. It is a popular destination for passersby who want to visit the towns of Hiko and Rachel.'\n",
      "row['problematic_spans'] = ['Crystal Springs is a ghost town in the Pahranagat Valley region of Lincoln County', 'Nevada in the United States. It is a popular destination for passersby who want to visit the towns of Hiko and Rachel.']\n",
      "to_show_spans = ['Crystal Springs is a ghost town in the Pahranagat Valley region of Lincoln County', 'Nevada in the United States. It is a popular destination for passersby who want to visit the towns of Hiko and Rachel.']\n",
      "\n",
      "1312: row['model_response'] = 'The first line of the New York City Subway opened on September 10, 1932.'\n",
      "row['problematic_spans'] = ['The first line of the New York City Subway opened on September 10', '1932.']\n",
      "to_show_spans = ['The first line of the New York City Subway opened on September 10', '1932.']\n",
      "\n",
      "4472: row['model_response'] = 'Szezeong'\n",
      "row['problematic_spans'] = ['Szezeong']\n",
      "to_show_spans = ['Szezeong']\n",
      "\n",
      "5271: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4789: row['model_response'] = 'Dokumenty'\n",
      "row['problematic_spans'] = ['Dokumenty']\n",
      "to_show_spans = ['Dokumenty']\n",
      "\n",
      "1714: row['model_response'] = 'The provided text does not contain the answer to when the Isle of Wight became an island.'\n",
      "row['problematic_spans'] = ['The provided text does not contain the answer to when the Isle of Wight became an island.']\n",
      "to_show_spans = ['The provided text does not contain the answer to when the Isle of Wight became an island.']\n",
      "\n",
      "5156: row['model_response'] = '`Like Sunday, Like Rain`'\n",
      "row['problematic_spans'] = ['Like Sunday', 'Like Rain']\n",
      "to_show_spans = ['Like Sunday', 'Like Rain']\n",
      "\n",
      "2530: row['model_response'] = 'Gusina'\n",
      "row['problematic_spans'] = ['Gusina']\n",
      "to_show_spans = ['Gusina']\n",
      "\n",
      "2318: row['model_response'] = 'FIS to skrót od  **Fédération Internationale de Ski**.'\n",
      "row['problematic_spans'] = ['FIS to skrót od']\n",
      "to_show_spans = ['FIS to skrót od']\n",
      "\n",
      "2019: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "16: row['model_response'] = 'The text states that pearls were retrieved by divers in the Indian Ocean in areas such as the Persian Gulf, the Red Sea and the Gulf of Mannar.'\n",
      "row['problematic_spans'] = ['the Persian Gulf', 'the Red Sea']\n",
      "to_show_spans = ['the Persian Gulf', 'the Red Sea']\n",
      "\n",
      "5599: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1866: row['model_response'] = 'Książę Ludwik Orleański i książę Jan de Berry.'\n",
      "row['problematic_spans'] = ['Książę Ludwik Orleański', 'książę Jan de Berry']\n",
      "to_show_spans = ['Książę Ludwik Orleański', 'książę Jan de Berry']\n",
      "\n",
      "4560: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1523: row['model_response'] = 'This document does not contain the answer to who the quarterback for the Green Bay Packers is.'\n",
      "row['problematic_spans'] = ['This document does not contain the answer to who the quarterback for the Green Bay Packers is.']\n",
      "to_show_spans = ['This document does not contain the answer to who the quarterback for the Green Bay Packers is.']\n",
      "\n",
      "4154: row['model_response'] = 'Xherdan Shaqiri'\n",
      "row['problematic_spans'] = ['Xherdan Shaqiri']\n",
      "to_show_spans = ['Xherdan Shaqiri']\n",
      "\n",
      "1093: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "3653: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "6113: row['model_response'] = 'Według tekstu, białka IκB (IκBα, IκBβ i IκBε) oraz p105 powodują cytoplazmatyczną sekwestrację NF-κB.'\n",
      "row['problematic_spans'] = ['IκB (IκBα', 'IκBβ i IκBε) oraz p105']\n",
      "to_show_spans = ['IκB (IκBα', 'IκBβ i IκBε) oraz p105']\n",
      "\n",
      "3739: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "5151: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5425: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "4888: row['model_response'] = 'Grégory Levasseur produced the 2003 horror film directed by Marc Fratto.'\n",
      "row['problematic_spans'] = ['Grégory Levasseur produced the 2003 horror film directed by Marc Fratto.']\n",
      "to_show_spans = ['Grégory Levasseur produced the 2003 horror film directed by Marc Fratto.']\n",
      "\n",
      "4887: row['model_response'] = 'Idaho'\n",
      "row['problematic_spans'] = ['Idaho']\n",
      "to_show_spans = ['Idaho']\n",
      "\n",
      "819: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1938: row['model_response'] = '2006'\n",
      "row['problematic_spans'] = ['2006']\n",
      "to_show_spans = ['2006']\n",
      "\n",
      "2280: row['model_response'] = '`Just Like That`'\n",
      "row['problematic_spans'] = ['Just Like That']\n",
      "to_show_spans = ['Just Like That']\n",
      "\n",
      "741: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4383: row['model_response'] = 'Wieniec z liści dębowych.'\n",
      "row['problematic_spans'] = ['Wieniec z liści dębowych']\n",
      "to_show_spans = ['Wieniec z liści dębowych']\n",
      "\n",
      "4518: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5913: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "1500: row['model_response'] = 'An autocracy is a system of government in which supreme power (social and political) is concentrated in the hands of one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control.  \\n\\n\\nIn the provided text, it states that  \"Most historical autocrats depended on their nobles, the military, the priesthood, or other elite groups.\" \\n\\n\\nIt also states that \"Because autocrats need a power structure to rule, it can be difficult to draw a clear line between historical autocracies and oligarchies.\" \\n\\n\\nTherefore, the answer is:  **It depends on the specific autocracy, but often a single person makes the important government decisions, with the support of nobles, the military, the priesthood, or other elite groups.**'\n",
      "row['problematic_spans'] = ['It depends on the specific autocracy', 'but often a single person makes the important government decisions', 'with the support of nobles', 'the military', 'the priesthood', 'or other elite groups.']\n",
      "to_show_spans = ['It depends on the specific autocracy', 'but often a single person makes the important government decisions', 'with the support of nobles', 'the military', 'the priesthood', 'or other elite groups.']\n",
      "\n",
      "1177: row['model_response'] = 'This document does not contain the answer to who has the most votes for the all star game.'\n",
      "row['problematic_spans'] = ['This document does not contain the answer to who has the most votes for the all star game']\n",
      "to_show_spans = ['This document does not contain the answer to who has the most votes for the all star game']\n",
      "\n",
      "5774: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "914: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4586: row['model_response'] = 'Both Matthew Tuck and Frank Iero have been lead vocalists and rhythm guitarists in their respective bands.'\n",
      "row['problematic_spans'] = ['lead vocalists']\n",
      "to_show_spans = ['lead vocalists']\n",
      "\n",
      "2623: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "2317: row['model_response'] = 'Papież Pius IX.'\n",
      "row['problematic_spans'] = ['Papież Pius IX']\n",
      "to_show_spans = ['Papież Pius IX']\n",
      "\n",
      "4749: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "3894: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "5738: row['model_response'] = 'W wątrobie występują dejodynaz D1 i D3.'\n",
      "row['problematic_spans'] = ['D3']\n",
      "to_show_spans = ['D3']\n",
      "\n",
      "1999: row['model_response'] = 'W dniach 8-20 maja 2021 fregata wraz z zaokrętowanym śmigłowcem Super Seasprite reprezentowała polską banderę na międzynarodowych manewrach morskich Joint Warrior 21-1. \\n\\n\\nNie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['W dniach 8-20 maja 2021 fregata wraz z zaokrętowanym śmigłowcem Super Seasprite reprezentowała polską banderę na międzynarodowych manewrach morskich Joint Warrior 21-1.']\n",
      "to_show_spans = ['W dniach 8-20 maja 2021 fregata wraz z zaokrętowanym śmigłowcem Super Seasprite reprezentowała polską banderę na międzynarodowych manewrach morskich Joint Warrior 21-1.']\n",
      "\n",
      "1276: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5319: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "2680: row['model_response'] = 'Współcześnie w BBC używa się także innych akcentów.'\n",
      "row['problematic_spans'] = ['Współcześnie w BBC używa się także innych akcentów']\n",
      "to_show_spans = ['Współcześnie w BBC używa się także innych akcentów']\n",
      "\n",
      "1560: row['model_response'] = 'Ireen Wüst from the Netherlands achieved five medals (two gold and three silver), more than any other athlete.'\n",
      "row['problematic_spans'] = ['more than any other athlete']\n",
      "to_show_spans = ['more than any other athlete']\n",
      "\n",
      "481: row['model_response'] = 'Classical central-force problem'\n",
      "row['problematic_spans'] = ['Classical central-force problem']\n",
      "to_show_spans = ['Classical central-force problem']\n",
      "\n",
      "788: row['model_response'] = 'Claire McLeod ends up with Alex Ryan.'\n",
      "row['problematic_spans'] = ['Claire McLeod ends up with Alex Ryan']\n",
      "to_show_spans = ['Claire McLeod ends up with Alex Ryan']\n",
      "\n",
      "1103: row['model_response'] = 'The Radcliffe Line'\n",
      "row['problematic_spans'] = ['The Radcliffe Line']\n",
      "to_show_spans = ['The Radcliffe Line']\n",
      "\n",
      "1722: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4144: row['model_response'] = 'Tak.'\n",
      "row['problematic_spans'] = ['Tak']\n",
      "to_show_spans = ['Tak']\n",
      "\n",
      "4340: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4242: row['model_response'] = 'John Dustin Archbold, główny dobroczyńca, który przekazał pieniądze na budowę Archbold Gymnasium, sprzedał swoją firmę naftową Johnowi D. Rockefellerowi.'\n",
      "row['problematic_spans'] = ['sprzedał swoją firmę naftową Johnowi D. Rockefellerowi']\n",
      "to_show_spans = ['sprzedał swoją firmę naftową Johnowi D. Rockefellerowi']\n",
      "\n",
      "2211: row['model_response'] = 'II'\n",
      "row['problematic_spans'] = ['II']\n",
      "to_show_spans = ['II']\n",
      "\n",
      "1153: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "3505: row['model_response'] = 'Real Simple comes out more times in a year.'\n",
      "row['problematic_spans'] = ['Real Simple comes out more times in a year']\n",
      "to_show_spans = ['Real Simple comes out more times in a year']\n",
      "\n",
      "1590: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "3983: row['model_response'] = 'Nosal wznosi się w Karkonoszach.'\n",
      "row['problematic_spans'] = ['Nosal wznosi się w Karkonoszach']\n",
      "to_show_spans = ['Nosal wznosi się w Karkonoszach']\n",
      "\n",
      "3402: row['model_response'] = 'Kyshtym'\n",
      "row['problematic_spans'] = ['Kyshtym']\n",
      "to_show_spans = ['Kyshtym']\n",
      "\n",
      "649: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4145: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5938: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "4799: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "2002: row['model_response'] = 'Piąte.'\n",
      "row['problematic_spans'] = ['Piąte']\n",
      "to_show_spans = ['Piąte']\n",
      "\n",
      "5301: row['model_response'] = 'Na podstawie podanego tekstu można wnioskować, że starofryzski był językiem mówionym w regionie, w którym leży osada Kloster Muhde, ponieważ osada ta została nazwana na cześć rzeki Leda, a nazwa \"Muhde\" pochodzi od starofryzyjskiego słowa oznaczającego \"(ujście) rzeki\".'\n",
      "row['problematic_spans'] = ['starofryzski był językiem mówionym w regionie', 'w którym leży osada Kloster Muhde']\n",
      "to_show_spans = ['starofryzski był językiem mówionym w regionie', 'w którym leży osada Kloster Muhde']\n",
      "\n",
      "4501: row['model_response'] = 'Moon Moon Sen'\n",
      "row['problematic_spans'] = ['']\n",
      "to_show_spans = ['']\n",
      "\n",
      "6003: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "6187: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "4482: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1795: row['model_response'] = 'The provided text states:  \"It is excluded in critical editions of the New Testament, such as that of the United Bible Societies. It is absent in the oldest manuscripts and is not considered to be part of the original text of –\".'\n",
      "row['problematic_spans'] = ['It is excluded in critical editions of the New Testament', 'such as that of the United Bible Societies. It is absent in the oldest manuscripts and is not considered to be part of the original text of –']\n",
      "to_show_spans = ['It is excluded in critical editions of the New Testament', 'such as that of the United Bible Societies. It is absent in the oldest manuscripts and is not considered to be part of the original text of –']\n",
      "\n",
      "5321: row['model_response'] = 'Georgetown'\n",
      "row['problematic_spans'] = ['Georgetown']\n",
      "to_show_spans = ['Georgetown']\n",
      "\n",
      "3929: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1584: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1219: row['model_response'] = 'There are 105 national parks in India.'\n",
      "row['problematic_spans'] = ['105 national parks']\n",
      "to_show_spans = ['105 national parks']\n",
      "\n",
      "5391: row['model_response'] = 'W wieku 25.'\n",
      "row['problematic_spans'] = ['W wieku 25']\n",
      "to_show_spans = ['W wieku 25']\n",
      "\n",
      "1181: row['model_response'] = 'The answer is not present in the provided text.'\n",
      "row['problematic_spans'] = ['The answer is not present in the provided text.']\n",
      "to_show_spans = ['The answer is not present in the provided text.']\n",
      "\n",
      "835: row['model_response'] = \"The provided text mentions that some Republican candidates expressed support for states' rights during the period from 1948 to 1984. It also states that the Southern states viewed the Republican position on banning slavery in U.S. territories as a violation of their constitutional rights and a step towards abolishing slavery.  Additionally, the text mentions that Jefferson Davis, who led the Confederacy, defined equality in terms of the equal rights of states and opposed the declaration that all men are created equal. \\n\\n\\nTherefore, based on the provided context, the following supported states' rights during the Civil War:\\n\\n* **Some Republican candidates** (during the period from 1948 to 1984)\\n* **The Southern states**\\n* **Jefferson Davis** \\n\\n\\n\\nLet me know if you have any other questions.\"\n",
      "row['problematic_spans'] = [\"some Republican candidates expressed support for states' rights during the period from 1948 to 1984\", 'the Southern states viewed the Republican position on banning slavery in U.S. territories as a violation of their constitutional rights']\n",
      "to_show_spans = [\"some Republican candidates expressed support for states' rights during the period from 1948 to 1984\", 'the Southern states viewed the Republican position on banning slavery in U.S. territories as a violation of their constitutional rights']\n",
      "\n",
      "3908: row['model_response'] = 'Evgeny Belyaev'\n",
      "row['problematic_spans'] = ['Evgeny Belyaev']\n",
      "to_show_spans = ['Evgeny Belyaev']\n",
      "\n",
      "2657: row['model_response'] = 'U wybrzeży Australii spotykany na całej północy, od Perth na zachodzie po Półwysep Jork na wschodzie i dalej na południe, aż po Sydney. W wodach Oceanu Spokojnego zamieszkuje okolice Wysp Vanuatu, Palau, Salomona, Fidżi, Gilberta, Marshalla, Mikronezji, Tonga, Samoa, Mariany, wybrzeża Nowej Kaledonii i Nowej Gwinei oraz wody Morza Koralowego i Morza Filipińskiego.'\n",
      "row['problematic_spans'] = ['U wybrzeży Australii spotykany na całej północy', 'od Perth na zachodzie po Półwysep Jork na wschodzie i dalej na południe', 'aż po Sydney.']\n",
      "to_show_spans = ['U wybrzeży Australii spotykany na całej północy', 'od Perth na zachodzie po Półwysep Jork na wschodzie i dalej na południe', 'aż po Sydney.']\n",
      "\n",
      "766: row['model_response'] = 'The final episode of Quantum Leap aired in its Wednesday slot in May 1993.'\n",
      "row['problematic_spans'] = ['The final episode of Quantum Leap aired in its Wednesday slot in May 1993.']\n",
      "to_show_spans = ['The final episode of Quantum Leap aired in its Wednesday slot in May 1993.']\n",
      "\n",
      "1143: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "2252: row['model_response'] = 'GameSpot'\n",
      "row['problematic_spans'] = ['GameSpot']\n",
      "to_show_spans = ['GameSpot']\n",
      "\n",
      "6043: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "2730: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5263: row['model_response'] = 'Akcja filmu Vinci dotyczy kradzieży obrazu \"Dama z gronostajem\" Leonarda da Vinci.'\n",
      "row['problematic_spans'] = ['Dama z gronostajem']\n",
      "to_show_spans = ['Dama z gronostajem']\n",
      "\n",
      "5107: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5451: row['model_response'] = 'The Greatest Love Songs of All Time was released by the artist who was performing a residency show at the casino in **Las Vegas**.'\n",
      "row['problematic_spans'] = ['Las Vegas']\n",
      "to_show_spans = ['Las Vegas']\n",
      "\n",
      "3824: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "3938: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "726: row['model_response'] = 'the rate of a chemical reaction.'\n",
      "row['problematic_spans'] = ['the rate of a chemical reaction']\n",
      "to_show_spans = ['the rate of a chemical reaction']\n",
      "\n",
      "1763: row['model_response'] = 'Cathy Lee Crosby'\n",
      "row['problematic_spans'] = ['Cathy Lee Crosby']\n",
      "to_show_spans = ['Cathy Lee Crosby']\n",
      "\n",
      "307: row['model_response'] = '1991'\n",
      "row['problematic_spans'] = ['1991']\n",
      "to_show_spans = ['1991']\n",
      "\n",
      "686: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "3782: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4996: row['model_response'] = 'Król.'\n",
      "row['problematic_spans'] = ['Król']\n",
      "to_show_spans = ['Król']\n",
      "\n",
      "2011: row['model_response'] = 'Tak, trzy piosenki Quebonafide trafiły na listy OLiS.'\n",
      "row['problematic_spans'] = ['trzy piosenki Quebonafide']\n",
      "to_show_spans = ['trzy piosenki Quebonafide']\n",
      "\n",
      "2719: row['model_response'] = 'W podrzucie.'\n",
      "row['problematic_spans'] = ['W podrzucie']\n",
      "to_show_spans = ['W podrzucie']\n",
      "\n",
      "6143: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.']\n",
      "\n",
      "5976: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1236: row['model_response'] = 'The Ottomans'\n",
      "row['problematic_spans'] = ['The Ottomans']\n",
      "to_show_spans = ['The Ottomans']\n",
      "\n",
      "5395: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "983: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1428: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1984: row['model_response'] = 'Na podstawie podanego tekstu, gracz może wpłynąć na zainicjowanie przemijania pór roku.'\n",
      "row['problematic_spans'] = ['Na podstawie podanego tekstu', 'gracz może wpłynąć na zainicjowanie przemijania pór roku']\n",
      "to_show_spans = ['Na podstawie podanego tekstu', 'gracz może wpłynąć na zainicjowanie przemijania pór roku']\n",
      "\n",
      "5199: row['model_response'] = 'Virtuti Militari'\n",
      "row['problematic_spans'] = ['']\n",
      "to_show_spans = ['']\n",
      "\n",
      "6067: row['model_response'] = 'GTPazy Rag'\n",
      "row['problematic_spans'] = ['GTPazy Rag']\n",
      "to_show_spans = ['GTPazy Rag']\n",
      "\n",
      "4474: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "2587: row['model_response'] = 'Tak, nazwa Cetartiodactyla była używana do oznaczenia parzystokopytnych wraz z waleniami.'\n",
      "row['problematic_spans'] = ['nazwa Cetartiodactyla była używana do oznaczenia parzystokopytnych wraz z waleniami']\n",
      "to_show_spans = ['nazwa Cetartiodactyla była używana do oznaczenia parzystokopytnych wraz z waleniami']\n",
      "\n",
      "4969: row['model_response'] = \"Axl Rose rose to fame in the 1980s with Guns N' Roses. Masatoshi Ono's first solo single was released in 1992.  So the answer is the 1980s and 1990s.\"\n",
      "row['problematic_spans'] = ['the 1980s and 1990s']\n",
      "to_show_spans = ['the 1980s and 1990s']\n",
      "\n",
      "6183: row['model_response'] = 'Niedobór BMAL1 skutkuje przedwczesnym starzeniem się u myszy, rozwojem patologii takich jak zaćma i zapalenie skóry, a także wpływa na zachowania eksploracyjne i habituacyjne. \\n\\nPonadto, niedobór BMAL1:\\n\\n* Zmniejsza długość życia myszy o 15% w porównaniu do myszy typu dzikiego.\\n* Zwiększa adipogenezę, przerost adipocytów i otyłość.\\n* Zaburza regulację homeostazy reaktywnych form tlenu (ROS) w komórkach.\\n* Zwiększa wrażliwość komórek na stres oksydacyjny i zmniejsza wrażliwość na leki przeciwnowotworowe.\\n* Zaburza oscylacje okołodobowe w ekspresji genów i homeostazę ROS w mózgu.\\n* Wywołuje nadpobudli'\n",
      "row['problematic_spans'] = ['Zmniejsza długość życia myszy o 15% w porównaniu do myszy typu dzikiego.', 'Zwiększa adipogenezę', 'przerost adipocytów i otyłość.']\n",
      "to_show_spans = ['Zmniejsza długość życia myszy o 15% w porównaniu do myszy typu dzikiego.', 'Zwiększa adipogenezę', 'przerost adipocytów i otyłość.']\n",
      "\n",
      "5029: row['model_response'] = 'Barry Cable. Rozegrał ponad 400 meczów na poziomie seniorów.'\n",
      "row['problematic_spans'] = ['Barry Cable. Rozegrał ponad 400 meczów na poziomie seniorów.']\n",
      "to_show_spans = ['Barry Cable. Rozegrał ponad 400 meczów na poziomie seniorów.']\n",
      "\n",
      "1665: row['model_response'] = 'Brazil remains the largest coffee exporting nation.'\n",
      "row['problematic_spans'] = ['remains the largest coffee exporting nation']\n",
      "to_show_spans = ['remains the largest coffee exporting nation']\n",
      "\n",
      "982: row['model_response'] = 'Daya Jethalal Gada'\n",
      "row['problematic_spans'] = ['Daya Jethalal Gada']\n",
      "to_show_spans = ['Daya Jethalal Gada']\n",
      "\n",
      "1511: row['model_response'] = 'Canada signed the United Nations Declaration on the Rights of Indigenous Peoples in 2010.'\n",
      "row['problematic_spans'] = ['in 2010']\n",
      "to_show_spans = ['in 2010']\n",
      "\n",
      "115: row['model_response'] = 'Jack McCoy was created by Michael S. Chernuchin and portrayed by Sam Waterston from 1994 until the end of the series in 2010.'\n",
      "row['problematic_spans'] = ['Jack McCoy was created by Michael S. Chernuchin and portrayed by Sam Waterston from 1994 until the end of the series in 2010.']\n",
      "to_show_spans = ['Jack McCoy was created by Michael S. Chernuchin and portrayed by Sam Waterston from 1994 until the end of the series in 2010.']\n",
      "\n",
      "2193: row['model_response'] = 'Matt Miller, Shelby Miller, Lee Harris, Audrey Tindall, Dominic Banks, Monet Tumusiime i Rory Monahan.'\n",
      "row['problematic_spans'] = ['Matt Miller', 'Shelby Miller', 'Lee Harris', 'Audrey Tindall', 'Dominic Banks', 'Monet Tumusiime', 'Rory Monahan']\n",
      "to_show_spans = ['Matt Miller', 'Shelby Miller', 'Lee Harris', 'Audrey Tindall', 'Dominic Banks', 'Monet Tumusiime', 'Rory Monahan']\n",
      "\n",
      "4801: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5737: row['model_response'] = 'W badaniu wykazano, że domniemane patogeny przyzębia są głównym składnikiem mikrobioty wyhodowanej z próbek płytki nazębnej uzyskanych z eksperymentalnych miejsc peri-implantitis. Ogólnie rzecz biorąc, typy i względne proporcje przypuszczalnych patogenów przyzębia w płytce nazębnej związanej z peri-implantitis i zapaleniem przyzębia wywołanym ligaturą były podobne.  Jedynie poziomy beztlenowych Actinomyces i krętków różniły się istotnie w obu miejscach.'\n",
      "row['problematic_spans'] = ['domniemane patogeny przyzębia', 'typy i względne proporcje przypuszczalnych patogenów przyzębia']\n",
      "to_show_spans = ['domniemane patogeny przyzębia', 'typy i względne proporcje przypuszczalnych patogenów przyzębia']\n",
      "\n",
      "489: row['model_response'] = 'Amerigo Vespucci explored the waters of Cuba, the Bahamas, and Hispaniola.'\n",
      "row['problematic_spans'] = ['Amerigo Vespucci explored the waters of Cuba', 'the Bahamas', 'and Hispaniola']\n",
      "to_show_spans = ['Amerigo Vespucci explored the waters of Cuba', 'the Bahamas', 'and Hispaniola']\n",
      "\n",
      "508: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1603: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4602: row['model_response'] = 'Shaolin and Wu Tang'\n",
      "row['problematic_spans'] = ['Shaolin and Wu Tang']\n",
      "to_show_spans = ['Shaolin and Wu Tang']\n",
      "\n",
      "3724: row['model_response'] = 'Chas Chandler'\n",
      "row['problematic_spans'] = ['Chas Chandler']\n",
      "to_show_spans = ['Chas Chandler']\n",
      "\n",
      "4645: row['model_response'] = 'Kurza Stopka to wschodnie skrzydło zamku w  **Gdańsku**.'\n",
      "row['problematic_spans'] = ['Gdańsku']\n",
      "to_show_spans = ['Gdańsku']\n",
      "\n",
      "2648: row['model_response'] = 'Niezbędne stały się nie tylko podatkowe kontrole krajowe, ale i nadzór o wymiarze międzynarodowym, ogólnoeuropejskim. Temu właśnie służyć ma sieć szybkiej wymiany informacji o podatku od towarów i usług EUROFISC, ustanowiony Rozporządzeniem Rady Nr 904/2010 z 7 października 2010 r. w sprawie współpracy administracyjnej oraz zwalczania oszustw w dziedzinie podatku od wartości dodanej (Dz.U. L 268 z 12.10.2010 r. s.1).'\n",
      "row['problematic_spans'] = ['Temu właśnie służyć ma sieć szybkiej wymiany informacji o podatku od towarów i usług EUROFISC', 'ustanowiony Rozporządzeniem Rady Nr 904/2010 z 7 października 2010 r. w sprawie współpracy administracyjnej oraz zwalczania oszustw w dziedzinie podatku od wartości dodanej (Dz.U. L 268 z 12.10.2010 r. s.1)']\n",
      "to_show_spans = ['Temu właśnie służyć ma sieć szybkiej wymiany informacji o podatku od towarów i usług EUROFISC', 'ustanowiony Rozporządzeniem Rady Nr 904/2010 z 7 października 2010 r. w sprawie współpracy administracyjnej oraz zwalczania oszustw w dziedzinie podatku od wartości dodanej (Dz.U. L 268 z 12.10.2010 r. s.1)']\n",
      "\n",
      "5323: row['model_response'] = 'Tak, tekst podaje, że w samym wnętrzu Księżyca zanotowano temperaturę przekraczającą +60 stopni Celsjusza.'\n",
      "row['problematic_spans'] = ['w samym wnętrzu Księżyca zanotowano temperaturę przekraczającą +60 stopni Celsjusza']\n",
      "to_show_spans = ['w samym wnętrzu Księżyca zanotowano temperaturę przekraczającą +60 stopni Celsjusza']\n",
      "\n",
      "3478: row['model_response'] = 'Film Jordan Roberts z 2017 roku to film animowany komputerowo w technologii 3D.'\n",
      "row['problematic_spans'] = ['Film Jordan Roberts z 2017 roku to film animowany komputerowo w technologii 3D.']\n",
      "to_show_spans = ['Film Jordan Roberts z 2017 roku to film animowany komputerowo w technologii 3D.']\n",
      "\n",
      "5689: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5686: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "2240: row['model_response'] = 'Tak, Augustowi udało się odbić Warszawę.'\n",
      "row['problematic_spans'] = ['Tak', 'Augustowi udało się odbić Warszawę']\n",
      "to_show_spans = ['Tak', 'Augustowi udało się odbić Warszawę']\n",
      "\n",
      "4535: row['model_response'] = 'American Blues zawierał perkusistę z grupy ZZ Top.'\n",
      "row['problematic_spans'] = ['z grupy ZZ Top']\n",
      "to_show_spans = ['z grupy ZZ Top']\n",
      "\n",
      "1250: row['model_response'] = 'The name for the CH3COO- ion is acetate.'\n",
      "row['problematic_spans'] = ['acetate']\n",
      "to_show_spans = ['acetate']\n",
      "\n",
      "151: row['model_response'] = 'Based on the provided text, here are the factories that assemble parts made in other countries:\\n\\n* **Playmobil:**  Malta specializes in making the characters and a few accessories, Spain specializes in accessories, and Germany makes the bigger items. Parts from each location are then assembled in a final packaging location.\\n* **Automotive industry by country (Greece):**\\n    * **Opel:** Assemble the first generation of the FWD Kadett.\\n    * **Alfa Romeo:** Assembled Alfasud.\\n    * **Teokar:** Assemble 45 different models including the Nissan Sunny (sport 106),Datsun Cherry,Datsun Pick up 1600 & king cab.\\n    * **Steyer:** In Thessaloniki since 1968, they assembled mainly trucks, light commercial and military vehicles.\\n    * **Enfield:** Enfield 8000 in Syros (first full electric production car).\\n    * **Namco'\n",
      "row['problematic_spans'] = ['Namco']\n",
      "to_show_spans = ['Namco']\n",
      "\n",
      "5240: row['model_response'] = 'Keisha Castle-Hughes won the award for Best Young Actor/Actress at the 2004 Broadcast Film Critics Association Awards.'\n",
      "row['problematic_spans'] = ['at the 2004 Broadcast Film Critics Association Awards']\n",
      "to_show_spans = ['at the 2004 Broadcast Film Critics Association Awards']\n",
      "\n",
      "1849: row['model_response'] = '1227'\n",
      "row['problematic_spans'] = ['1227']\n",
      "to_show_spans = ['1227']\n",
      "\n",
      "1465: row['model_response'] = 'The white stork is a symbol of  parental devotion, purity, and good luck in Western culture.  It is particularly known for its association with bringing babies to new parents.'\n",
      "row['problematic_spans'] = ['parental devotion', 'purity', 'good luck']\n",
      "to_show_spans = ['parental devotion', 'purity', 'good luck']\n",
      "\n",
      "4180: row['model_response'] = 'Muhammad Ali (ur. Raymond Patterson)'\n",
      "row['problematic_spans'] = ['Muhammad Ali (ur. Raymond Patterson)']\n",
      "to_show_spans = ['Muhammad Ali (ur. Raymond Patterson)']\n",
      "\n",
      "137: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4991: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "3710: row['model_response'] = 'Teatr Absurdu'\n",
      "row['problematic_spans'] = ['Teatr Absurdu']\n",
      "to_show_spans = ['Teatr Absurdu']\n",
      "\n",
      "589: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "4620: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "772: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "1781: row['model_response'] = 'The text states that fingerprinting was introduced to the United States by New York City Police Department Deputy Commissioner Joseph A. Faurot in December 1905.  It also mentions that the first United Kingdom Fingerprint Bureau was founded in Scotland Yard in 1901.'\n",
      "row['problematic_spans'] = ['fingerprinting was introduced to the United States by New York City Police Department Deputy Commissioner Joseph A. Faurot in December 1905', 'the first United Kingdom Fingerprint Bureau was founded in Scotland Yard in 1901']\n",
      "to_show_spans = ['fingerprinting was introduced to the United States by New York City Police Department Deputy Commissioner Joseph A. Faurot in December 1905', 'the first United Kingdom Fingerprint Bureau was founded in Scotland Yard in 1901']\n",
      "\n",
      "5347: row['model_response'] = 'Karol Dickens'\n",
      "row['problematic_spans'] = ['Karol Dickens']\n",
      "to_show_spans = ['Karol Dickens']\n",
      "\n",
      "1788: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5858: row['model_response'] = 'W tekście wymienione są następujące inhibitory białka TPL2/MAP3K8:\\n\\n* 1,7-naftyrydyno-3-karbonitryl\\n* 8-halo-4-(3-chloro-4-fluoro-phenylamino)-6-[(1H-[1,2,3]triazol-4-ylmethyl)-amino]-quinoline-3-carbonitriles (4)\\n* 8-chloro-4-(3-chloro-4-fluorofenyloamino)-6-((1-(1-etylopiperydyn-4-ylo)-1H-1,2,3-triazol-4-ylo)metyloamino)chinolino-3-karbonitryl (34)\\n* erlotynib (Tarceva)'\n",
      "row['problematic_spans'] = ['erlotynib (Tarceva)']\n",
      "to_show_spans = ['erlotynib (Tarceva)']\n",
      "\n",
      "3750: row['model_response'] = 'Kingpin (TV series)'\n",
      "row['problematic_spans'] = ['Kingpin (TV series)']\n",
      "to_show_spans = ['Kingpin (TV series)']\n",
      "\n",
      "2382: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5940: row['model_response'] = 'Minimalne nieobecne słowa to minimalne nieobecne słowa, które zachowują swoje właściwości, jeśli usunie się z nich dowolny znak z lewej lub prawej strony.'\n",
      "row['problematic_spans'] = ['Minimalne nieobecne słowa to minimalne nieobecne słowa']\n",
      "to_show_spans = ['Minimalne nieobecne słowa to minimalne nieobecne słowa']\n",
      "\n",
      "630: row['model_response'] = '1848, when a Frenchman, Antonio Manguino, constructed a wooden pleasure wheel to attract visitors to his start-up fair in Walton Spring, Georgia.'\n",
      "row['problematic_spans'] = ['1848', 'when a Frenchman', 'Antonio Manguino', 'constructed a wooden pleasure wheel to attract visitors to his start-up fair in Walton Spring', 'Georgia.']\n",
      "to_show_spans = ['1848', 'when a Frenchman', 'Antonio Manguino', 'constructed a wooden pleasure wheel to attract visitors to his start-up fair in Walton Spring', 'Georgia.']\n",
      "\n",
      "2962: row['model_response'] = 'Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu.'\n",
      "row['problematic_spans'] = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "to_show_spans = ['Nie mogę udzielić odpowiedzi na to pytanie na podstawie podanego kontekstu']\n",
      "\n",
      "5436: row['model_response'] = 'Tony Ingham played for Leeds United and Queens Park Rangers.'\n",
      "row['problematic_spans'] = ['Tony Ingham played for Leeds United and Queens Park Rangers']\n",
      "to_show_spans = ['Tony Ingham played for Leeds United and Queens Park Rangers']\n",
      "\n",
      "1600: row['model_response'] = 'Forbes Burnham'\n",
      "row['problematic_spans'] = ['Forbes Burnham']\n",
      "to_show_spans = ['Forbes Burnham']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "\n",
    "    if row['problematic_spans']:\n",
    "\n",
    "        formatted_prompt = row['formatted_context']\n",
    "        to_show_spans = [formatted_prompt[start:end] for start, end in row['hallu_indicies']]\n",
    "        print(f\"{row['index']}: {row['model_response'] = }\\n{row['problematic_spans'] = }\\n{to_show_spans = }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: <bos>: 0\n",
      "2: <bos>: 0\n",
      "106: <start_of_turn>: 0\n",
      "1645: user: 0\n",
      "108: \n",
      ": 0\n",
      "2045: You: 0\n",
      "708: ▁are: 0\n",
      "476: ▁a: 0\n",
      "10055: ▁helpful: 0\n",
      "20409: ▁assistant: 0\n",
      "235265: .: 0\n",
      "3883: ▁Your: 0\n",
      "3356: ▁job: 0\n",
      "877: ▁will: 0\n",
      "614: ▁be: 0\n",
      "577: ▁to: 0\n",
      "3448: ▁answer: 0\n",
      "3920: ▁questions: 0\n",
      "31115: ▁accurately: 0\n",
      "3482: ▁based: 0\n",
      "611: ▁on: 0\n",
      "573: ▁the: 0\n",
      "2764: ▁given: 0\n",
      "4807: ▁context: 0\n",
      "578: ▁and: 0\n",
      "780: ▁not: 0\n",
      "861: ▁your: 0\n",
      "8678: ▁internal: 0\n",
      "5567: ▁knowledge: 0\n",
      "235265: .: 0\n",
      "108: \n",
      ": 0\n",
      "141: ▁▁▁▁: 0\n",
      "2495: If: 0\n",
      "692: ▁you: 0\n",
      "798: ▁can: 0\n",
      "780: ▁not: 0\n",
      "3448: ▁answer: 0\n",
      "573: ▁the: 0\n",
      "2872: ▁question: 0\n",
      "1297: ▁only: 0\n",
      "3482: ▁based: 0\n",
      "611: ▁on: 0\n",
      "573: ▁the: 0\n",
      "4646: ▁provided: 0\n",
      "4807: ▁context: 0\n",
      "235269: ,: 0\n",
      "2203: ▁return: 0\n",
      "573: ▁the: 0\n",
      "3448: ▁answer: 0\n",
      "235292: :: 0\n",
      "4103: ▁`: 0\n",
      "28317: Nie: 0\n",
      "153095: ▁mogę: 0\n",
      "13869: ▁ud: 0\n",
      "5139: zie: 0\n",
      "133944: lić: 0\n",
      "165557: ▁odpowiedzi: 0\n",
      "1584: ▁na: 0\n",
      "577: ▁to: 0\n",
      "158462: ▁pytanie: 0\n",
      "1584: ▁na: 0\n",
      "145082: ▁podstawie: 0\n",
      "3478: ▁pod: 0\n",
      "112730: anego: 0\n",
      "5224: ▁kon: 0\n",
      "9837: tek: 0\n",
      "16901: stu: 0\n",
      "27271: `.: 0\n",
      "108: \n",
      ": 0\n",
      "24985: Given: 0\n",
      "573: ▁the: 0\n",
      "4807: ▁context: 0\n",
      "4103: ▁`: 0\n",
      "71157: CONTEXT: 0\n",
      "235376: `: 0\n",
      "578: ▁and: 0\n",
      "573: ▁the: 0\n",
      "8164: ▁query: 0\n",
      "4103: ▁`: 0\n",
      "63741: QUERY: 0\n",
      "235376: `: 0\n",
      "3582: ▁below: 0\n",
      "235269: ,: 0\n",
      "3743: ▁please: 0\n",
      "3658: ▁provide: 0\n",
      "671: ▁an: 0\n",
      "3448: ▁answer: 0\n",
      "4103: ▁`: 0\n",
      "72601: ANSWER: 0\n",
      "235376: `: 0\n",
      "577: ▁to: 0\n",
      "573: ▁the: 0\n",
      "2872: ▁question: 0\n",
      "235265: .: 0\n",
      "235248: ▁: 0\n",
      "108: \n",
      ": 0\n",
      "141: ▁▁▁▁: 0\n",
      "235376: `: 0\n",
      "71157: CONTEXT: 0\n",
      "74412: `:: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "128794: Montana: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235304: 3: 0\n",
      "235318: 6: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "714: ▁The: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235304: 3: 0\n",
      "235318: 6: 0\n",
      "37191: ▁Montana: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "3895: ▁took: 0\n",
      "2040: ▁place: 0\n",
      "611: ▁on: 0\n",
      "5516: ▁November: 0\n",
      "235248: ▁: 0\n",
      "235304: 3: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235304: 3: 0\n",
      "235318: 6: 0\n",
      "235265: .: 0\n",
      "5531: ▁Inc: 0\n",
      "55665: umbent: 0\n",
      "17486: ▁Governor: 0\n",
      "576: ▁of: 0\n",
      "37191: ▁Montana: 0\n",
      "109105: ▁Elmer: 0\n",
      "55571: ▁Holt: 0\n",
      "235269: ,: 0\n",
      "1064: ▁who: 0\n",
      "5981: ▁became: 0\n",
      "23699: ▁governor: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235304: 3: 0\n",
      "235308: 5: 0\n",
      "3054: ▁upon: 0\n",
      "573: ▁the: 0\n",
      "4168: ▁death: 0\n",
      "576: ▁of: 0\n",
      "7851: ▁Frank: 0\n",
      "10137: ▁Henry: 0\n",
      "1911: ▁Co: 0\n",
      "2472: oney: 0\n",
      "235269: ,: 0\n",
      "8876: ▁ran: 0\n",
      "604: ▁for: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "50368: election: 0\n",
      "235265: .: 0\n",
      "1315: ▁He: 0\n",
      "729: ▁was: 0\n",
      "40438: ▁challenged: 0\n",
      "575: ▁in: 0\n",
      "573: ▁the: 0\n",
      "25682: ▁Democratic: 0\n",
      "7920: ▁primary: 0\n",
      "731: ▁by: 0\n",
      "476: ▁a: 0\n",
      "1758: ▁number: 0\n",
      "576: ▁of: 0\n",
      "8246: ▁challeng: 0\n",
      "618: ers: 0\n",
      "235269: ,: 0\n",
      "578: ▁and: 0\n",
      "729: ▁was: 0\n",
      "89286: ▁narrowly: 0\n",
      "29534: ▁defeated: 0\n",
      "604: ▁for: 0\n",
      "8354: ▁ren: 0\n",
      "59431: omination: 0\n",
      "731: ▁by: 0\n",
      "3520: ▁United: 0\n",
      "3858: ▁States: 0\n",
      "133980: ▁Congressman: 0\n",
      "7582: ▁Roy: 0\n",
      "637: ▁E: 0\n",
      "235265: .: 0\n",
      "207200: ▁Ayers: 0\n",
      "576: ▁of: 0\n",
      "37191: ▁Montana: 0\n",
      "235303: ': 0\n",
      "235256: s: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "491: nd: 0\n",
      "80700: ▁congressional: 0\n",
      "9220: ▁district: 0\n",
      "235265: .: 0\n",
      "207200: ▁Ayers: 0\n",
      "11303: ▁advanced: 0\n",
      "577: ▁to: 0\n",
      "573: ▁the: 0\n",
      "3311: ▁general: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "1570: ▁where: 0\n",
      "693: ▁he: 0\n",
      "20360: ▁faced: 0\n",
      "7851: ▁Frank: 0\n",
      "586: ▁A: 0\n",
      "235265: .: 0\n",
      "17082: ▁Haz: 0\n",
      "61878: elb: 0\n",
      "7795: aker: 0\n",
      "235269: ,: 0\n",
      "573: ▁the: 0\n",
      "5730: ▁former: 0\n",
      "41943: ▁Lieutenant: 0\n",
      "17486: ▁Governor: 0\n",
      "576: ▁of: 0\n",
      "37191: ▁Montana: 0\n",
      "578: ▁and: 0\n",
      "573: ▁the: 0\n",
      "25338: ▁Republican: 0\n",
      "88524: ▁nominee: 0\n",
      "235265: .: 0\n",
      "25879: ▁Following: 0\n",
      "476: ▁a: 0\n",
      "3387: ▁close: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "207200: ▁Ayers: 0\n",
      "89286: ▁narrowly: 0\n",
      "29534: ▁defeated: 0\n",
      "17082: ▁Haz: 0\n",
      "61878: elb: 0\n",
      "7795: aker: 0\n",
      "577: ▁to: 0\n",
      "3709: ▁win: 0\n",
      "1212: ▁what: 0\n",
      "1134: ▁would: 0\n",
      "614: ▁be: 0\n",
      "926: ▁his: 0\n",
      "1370: ▁first: 0\n",
      "578: ▁and: 0\n",
      "1297: ▁only: 0\n",
      "5168: ▁term: 0\n",
      "685: ▁as: 0\n",
      "23699: ▁governor: 0\n",
      "235265: .: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "86926: Christi: 0\n",
      "11361: andy: 0\n",
      "3250: ▁San: 0\n",
      "100107: jaya: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "17847: ▁Christi: 0\n",
      "11361: andy: 0\n",
      "3250: ▁San: 0\n",
      "100107: jaya: 0\n",
      "591: ▁(: 0\n",
      "18791: Han: 0\n",
      "3423: zi: 0\n",
      "235292: :: 0\n",
      "118029: ▁黃: 0\n",
      "238293: 漢: 0\n",
      "235822: 山: 0\n",
      "235269: ,: 0\n",
      "640: ▁H: 0\n",
      "125189: anyu: 0\n",
      "596: ▁P: 0\n",
      "107184: inyin: 0\n",
      "235292: :: 0\n",
      "664: ▁\": 0\n",
      "18691: Hu: 0\n",
      "12365: áng: 0\n",
      "64476: ▁Hà: 0\n",
      "558: ns: 0\n",
      "235259: h: 0\n",
      "57584: ān: 0\n",
      "824: \",: 0\n",
      "42488: ▁Hak: 0\n",
      "1161: ka: 0\n",
      "235292: :: 0\n",
      "664: ▁\": 0\n",
      "175599: Bong: 0\n",
      "9073: ▁Hon: 0\n",
      "50189: ▁Sham: 0\n",
      "824: \",: 0\n",
      "7565: ▁born: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235315: 9: 0\n",
      "4482: ▁March: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "235310: 4: 0\n",
      "235275: ): 0\n",
      "603: ▁is: 0\n",
      "573: ▁the: 0\n",
      "74974: ▁incumbent: 0\n",
      "27206: ▁Deputy: 0\n",
      "17486: ▁Governor: 0\n",
      "576: ▁of: 0\n",
      "4589: ▁West: 0\n",
      "145584: ▁Kalimantan: 0\n",
      "2754: ▁since: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235310: 4: 0\n",
      "5468: ▁January: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235276: 0: 0\n",
      "235321: 8: 0\n",
      "235265: .: 0\n",
      "1315: ▁He: 0\n",
      "729: ▁was: 0\n",
      "17710: ▁elected: 0\n",
      "577: ▁to: 0\n",
      "573: ▁the: 0\n",
      "2053: ▁post: 0\n",
      "3584: ▁together: 0\n",
      "675: ▁with: 0\n",
      "926: ▁his: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "235269: ,: 0\n",
      "74974: ▁incumbent: 0\n",
      "17486: ▁Governor: 0\n",
      "163194: ▁Cornel: 0\n",
      "502: is: 0\n",
      "235269: ,: 0\n",
      "1452: ▁after: 0\n",
      "14557: ▁winning: 0\n",
      "573: ▁the: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235276: 0: 0\n",
      "235324: 7: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "235265: .: 0\n",
      "2365: ▁They: 0\n",
      "1049: ▁were: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "74115: elected: 0\n",
      "604: ▁for: 0\n",
      "573: ▁the: 0\n",
      "2257: ▁second: 0\n",
      "5168: ▁term: 0\n",
      "611: ▁on: 0\n",
      "573: ▁the: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235274: 1: 0\n",
      "235284: 2: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "235265: .: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "23662: William: 0\n",
      "713: ▁J: 0\n",
      "235265: .: 0\n",
      "113121: ▁Maguire: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "7130: ▁William: 0\n",
      "713: ▁J: 0\n",
      "235265: .: 0\n",
      "113121: ▁Maguire: 0\n",
      "591: ▁(: 0\n",
      "10944: June: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235284: 2: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235274: 1: 0\n",
      "235318: 6: 0\n",
      "1157: ▁–: 0\n",
      "5424: ▁October: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235324: 7: 0\n",
      "235275: ): 0\n",
      "729: ▁was: 0\n",
      "671: ▁an: 0\n",
      "3725: ▁American: 0\n",
      "25338: ▁Republican: 0\n",
      "10438: ▁Party: 0\n",
      "43504: ▁politician: 0\n",
      "1064: ▁who: 0\n",
      "9180: ▁served: 0\n",
      "575: ▁in: 0\n",
      "573: ▁the: 0\n",
      "1622: ▁New: 0\n",
      "17108: ▁Jersey: 0\n",
      "5105: ▁General: 0\n",
      "10166: ▁Assembly: 0\n",
      "774: ▁from: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235324: 7: 0\n",
      "235318: 6: 0\n",
      "577: ▁to: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235284: 2: 0\n",
      "235265: .: 0\n",
      "1315: ▁He: 0\n",
      "9180: ▁served: 0\n",
      "685: ▁as: 0\n",
      "24268: ▁Mayor: 0\n",
      "576: ▁of: 0\n",
      "19114: ▁Clark: 0\n",
      "235269: ,: 0\n",
      "1622: ▁New: 0\n",
      "17108: ▁Jersey: 0\n",
      "578: ▁and: 0\n",
      "685: ▁as: 0\n",
      "476: ▁a: 0\n",
      "8418: ▁Union: 0\n",
      "4992: ▁County: 0\n",
      "6394: ▁Free: 0\n",
      "6148: holder: 0\n",
      "235265: .: 0\n",
      "113121: ▁Maguire: 0\n",
      "729: ▁was: 0\n",
      "17710: ▁elected: 0\n",
      "577: ▁to: 0\n",
      "573: ▁the: 0\n",
      "3040: ▁State: 0\n",
      "10166: ▁Assembly: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235324: 7: 0\n",
      "235308: 5: 0\n",
      "235269: ,: 0\n",
      "5327: ▁running: 0\n",
      "675: ▁with: 0\n",
      "3936: ▁future: 0\n",
      "17486: ▁Governor: 0\n",
      "19177: ▁Donald: 0\n",
      "3828: ▁Di: 0\n",
      "108491: Francesco: 0\n",
      "235289: ;: 0\n",
      "984: ▁they: 0\n",
      "29534: ▁defeated: 0\n",
      "74974: ▁incumbent: 0\n",
      "53136: ▁Democrat: 0\n",
      "43990: ▁Betty: 0\n",
      "14270: ▁Wilson: 0\n",
      "578: ▁and: 0\n",
      "1070: ▁her: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "235269: ,: 0\n",
      "7130: ▁William: 0\n",
      "586: ▁A: 0\n",
      "235265: .: 0\n",
      "18270: ▁Wolf: 0\n",
      "235269: ,: 0\n",
      "573: ▁the: 0\n",
      "23703: ▁Rah: 0\n",
      "1677: way: 0\n",
      "25682: ▁Democratic: 0\n",
      "26560: ▁Municipal: 0\n",
      "17818: ▁Chairman: 0\n",
      "235265: .: 0\n",
      "1315: ▁He: 0\n",
      "729: ▁was: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "74115: elected: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235324: 7: 0\n",
      "235324: 7: 0\n",
      "235265: .: 0\n",
      "25879: ▁Following: 0\n",
      "573: ▁the: 0\n",
      "55027: ▁resignation: 0\n",
      "576: ▁of: 0\n",
      "3040: ▁State: 0\n",
      "31203: ▁Senator: 0\n",
      "8234: ▁Peter: 0\n",
      "713: ▁J: 0\n",
      "235265: .: 0\n",
      "221263: ▁McDonough: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235324: 7: 0\n",
      "235315: 9: 0\n",
      "235269: ,: 0\n",
      "113121: ▁Maguire: 0\n",
      "8876: ▁ran: 0\n",
      "604: ▁for: 0\n",
      "573: ▁the: 0\n",
      "3040: ▁State: 0\n",
      "17598: ▁Senate: 0\n",
      "235269: ,: 0\n",
      "901: ▁but: 0\n",
      "5501: ▁lost: 0\n",
      "476: ▁a: 0\n",
      "8744: ▁vote: 0\n",
      "576: ▁of: 0\n",
      "476: ▁a: 0\n",
      "25338: ▁Republican: 0\n",
      "24931: ▁convention: 0\n",
      "577: ▁to: 0\n",
      "3828: ▁Di: 0\n",
      "108491: Francesco: 0\n",
      "235265: .: 0\n",
      "1315: ▁He: 0\n",
      "729: ▁was: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "74115: elected: 0\n",
      "577: ▁to: 0\n",
      "573: ▁the: 0\n",
      "10166: ▁Assembly: 0\n",
      "235269: ,: 0\n",
      "675: ▁with: 0\n",
      "3936: ▁future: 0\n",
      "133980: ▁Congressman: 0\n",
      "11270: ▁Bob: 0\n",
      "138292: ▁Franks: 0\n",
      "685: ▁as: 0\n",
      "926: ▁his: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "235265: .: 0\n",
      "113121: ▁Maguire: 0\n",
      "235303: ': 0\n",
      "235256: s: 0\n",
      "6269: ▁political: 0\n",
      "7460: ▁career: 0\n",
      "3392: ▁came: 0\n",
      "577: ▁to: 0\n",
      "671: ▁an: 0\n",
      "1580: ▁end: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235274: 1: 0\n",
      "235269: ,: 0\n",
      "1185: ▁when: 0\n",
      "582: ▁re: 0\n",
      "44121: district: 0\n",
      "574: ing: 0\n",
      "46037: ▁traded: 0\n",
      "25682: ▁Democratic: 0\n",
      "16751: ▁towns: 0\n",
      "575: ▁in: 0\n",
      "8418: ▁Union: 0\n",
      "4992: ▁County: 0\n",
      "604: ▁for: 0\n",
      "6792: ▁solid: 0\n",
      "25338: ▁Republican: 0\n",
      "16751: ▁towns: 0\n",
      "575: ▁in: 0\n",
      "52344: ▁Essex: 0\n",
      "4992: ▁County: 0\n",
      "235265: .: 0\n",
      "3828: ▁Di: 0\n",
      "108491: Francesco: 0\n",
      "729: ▁was: 0\n",
      "15853: ▁facing: 0\n",
      "476: ▁a: 0\n",
      "7920: ▁primary: 0\n",
      "10247: ▁challenge: 0\n",
      "774: ▁from: 0\n",
      "671: ▁an: 0\n",
      "52344: ▁Essex: 0\n",
      "4992: ▁County: 0\n",
      "25338: ▁Republican: 0\n",
      "235289: ;: 0\n",
      "577: ▁to: 0\n",
      "10548: ▁secure: 0\n",
      "573: ▁the: 0\n",
      "52344: ▁Essex: 0\n",
      "8344: ▁organization: 0\n",
      "2017: ▁line: 0\n",
      "575: ▁in: 0\n",
      "476: ▁a: 0\n",
      "9220: ▁district: 0\n",
      "1570: ▁where: 0\n",
      "25338: ▁Republican: 0\n",
      "7920: ▁primary: 0\n",
      "11621: ▁election: 0\n",
      "28242: ▁voters: 0\n",
      "1049: ▁were: 0\n",
      "48145: ▁evenly: 0\n",
      "10544: ▁split: 0\n",
      "1865: ▁between: 0\n",
      "52344: ▁Essex: 0\n",
      "578: ▁and: 0\n",
      "8418: ▁Union: 0\n",
      "235269: ,: 0\n",
      "3828: ▁Di: 0\n",
      "108491: Francesco: 0\n",
      "11327: ▁agreed: 0\n",
      "577: ▁to: 0\n",
      "2507: ▁put: 0\n",
      "671: ▁an: 0\n",
      "52344: ▁Essex: 0\n",
      "25338: ▁Republican: 0\n",
      "611: ▁on: 0\n",
      "926: ▁his: 0\n",
      "15457: ▁ticket: 0\n",
      "235265: .: 0\n",
      "3350: ▁John: 0\n",
      "12112: ▁Ren: 0\n",
      "556: na: 0\n",
      "235269: ,: 0\n",
      "573: ▁the: 0\n",
      "52344: ▁Essex: 0\n",
      "25338: ▁Republican: 0\n",
      "17818: ▁Chairman: 0\n",
      "235269: ,: 0\n",
      "16841: ▁preferred: 0\n",
      "674: ▁that: 0\n",
      "138292: ▁Franks: 0\n",
      "591: ▁(: 0\n",
      "10569: who: 0\n",
      "1093: ▁had: 0\n",
      "6800: ▁worked: 0\n",
      "611: ▁on: 0\n",
      "12112: ▁Ren: 0\n",
      "556: na: 0\n",
      "235303: ': 0\n",
      "235256: s: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235324: 7: 0\n",
      "235324: 7: 0\n",
      "12551: ▁bid: 0\n",
      "604: ▁for: 0\n",
      "4992: ▁County: 0\n",
      "17818: ▁Chairman: 0\n",
      "823: ),: 0\n",
      "947: ▁get: 0\n",
      "573: ▁the: 0\n",
      "2257: ▁second: 0\n",
      "10166: ▁Assembly: 0\n",
      "10250: ▁seat: 0\n",
      "235265: .: 0\n",
      "113121: ▁Maguire: 0\n",
      "235269: ,: 0\n",
      "14221: ▁replaced: 0\n",
      "731: ▁by: 0\n",
      "17621: ▁Mill: 0\n",
      "16392: burn: 0\n",
      "24268: ▁Mayor: 0\n",
      "118025: ▁Maureen: 0\n",
      "116826: ▁Ogden: 0\n",
      "235269: ,: 0\n",
      "1498: ▁did: 0\n",
      "780: ▁not: 0\n",
      "2060: ▁run: 0\n",
      "604: ▁for: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "50368: election: 0\n",
      "235265: .: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "61121: Nicole: 0\n",
      "26583: ▁Pool: 0\n",
      "1066: man: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "42462: ▁Nicole: 0\n",
      "26583: ▁Pool: 0\n",
      "1066: man: 0\n",
      "603: ▁is: 0\n",
      "476: ▁a: 0\n",
      "25338: ▁Republican: 0\n",
      "4757: ▁member: 0\n",
      "576: ▁of: 0\n",
      "573: ▁the: 0\n",
      "4612: ▁North: 0\n",
      "32234: ▁Dakota: 0\n",
      "17598: ▁Senate: 0\n",
      "235269: ,: 0\n",
      "19017: ▁representing: 0\n",
      "573: ▁the: 0\n",
      "235248: ▁: 0\n",
      "235304: 3: 0\n",
      "235304: 3: 0\n",
      "1924: rd: 0\n",
      "9220: ▁district: 0\n",
      "235265: .: 0\n",
      "26583: ▁Pool: 0\n",
      "1066: man: 0\n",
      "729: ▁was: 0\n",
      "1370: ▁first: 0\n",
      "17710: ▁elected: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235274: 1: 0\n",
      "235284: 2: 0\n",
      "235269: ,: 0\n",
      "90134: ▁defeating: 0\n",
      "53136: ▁Democrat: 0\n",
      "27579: ▁Warren: 0\n",
      "169319: ▁Emmer: 0\n",
      "235265: .: 0\n",
      "878: ▁In: 0\n",
      "573: ▁the: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235274: 1: 0\n",
      "235318: 6: 0\n",
      "4612: ▁North: 0\n",
      "32234: ▁Dakota: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "1284: ▁she: 0\n",
      "729: ▁was: 0\n",
      "12228: ▁chosen: 0\n",
      "573: ▁the: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "604: ▁for: 0\n",
      "20035: ▁Attorney: 0\n",
      "5105: ▁General: 0\n",
      "27363: ▁Wayne: 0\n",
      "47116: ▁Sten: 0\n",
      "22998: eh: 0\n",
      "14948: jem: 0\n",
      "235265: .: 0\n",
      "26583: ▁Pool: 0\n",
      "1066: man: 0\n",
      "7094: ▁currently: 0\n",
      "3598: ▁works: 0\n",
      "685: ▁as: 0\n",
      "476: ▁a: 0\n",
      "1536: ▁high: 0\n",
      "2493: ▁school: 0\n",
      "4645: ▁English: 0\n",
      "9382: ▁teacher: 0\n",
      "575: ▁in: 0\n",
      "113673: ▁Bismarck: 0\n",
      "235265: .: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "128794: Montana: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "714: ▁The: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "37191: ▁Montana: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "3895: ▁took: 0\n",
      "2040: ▁place: 0\n",
      "611: ▁on: 0\n",
      "5516: ▁November: 0\n",
      "235248: ▁: 0\n",
      "235308: 5: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "235265: .: 0\n",
      "5531: ▁Inc: 0\n",
      "55665: umbent: 0\n",
      "17486: ▁Governor: 0\n",
      "576: ▁of: 0\n",
      "37191: ▁Montana: 0\n",
      "29287: ▁Marc: 0\n",
      "35175: ▁Rac: 0\n",
      "210456: icot: 0\n",
      "235269: ,: 0\n",
      "1064: ▁who: 0\n",
      "729: ▁was: 0\n",
      "1370: ▁first: 0\n",
      "17710: ▁elected: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235284: 2: 0\n",
      "235269: ,: 0\n",
      "8876: ▁ran: 0\n",
      "604: ▁for: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "50368: election: 0\n",
      "235265: .: 0\n",
      "4660: ▁After: 0\n",
      "14557: ▁winning: 0\n",
      "573: ▁the: 0\n",
      "25338: ▁Republican: 0\n",
      "7920: ▁primary: 0\n",
      "2691: ▁against: 0\n",
      "476: ▁a: 0\n",
      "31319: ▁conservative: 0\n",
      "58329: ▁activist: 0\n",
      "235269: ,: 0\n",
      "693: ▁he: 0\n",
      "8509: ▁moved: 0\n",
      "611: ▁on: 0\n",
      "577: ▁to: 0\n",
      "573: ▁the: 0\n",
      "3311: ▁general: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "1570: ▁where: 0\n",
      "693: ▁he: 0\n",
      "729: ▁was: 0\n",
      "1142: ▁set: 0\n",
      "577: ▁to: 0\n",
      "3142: ▁face: 0\n",
      "165125: ▁Chet: 0\n",
      "599: ▁B: 0\n",
      "925: lay: 0\n",
      "843: lock: 0\n",
      "235269: ,: 0\n",
      "476: ▁a: 0\n",
      "5730: ▁former: 0\n",
      "3040: ▁State: 0\n",
      "31203: ▁Senator: 0\n",
      "578: ▁and: 0\n",
      "573: ▁the: 0\n",
      "25682: ▁Democratic: 0\n",
      "88524: ▁nominee: 0\n",
      "235265: .: 0\n",
      "4560: ▁However: 0\n",
      "235269: ,: 0\n",
      "611: ▁on: 0\n",
      "5424: ▁October: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235304: 3: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "235269: ,: 0\n",
      "599: ▁B: 0\n",
      "925: lay: 0\n",
      "843: lock: 0\n",
      "7404: ▁died: 0\n",
      "576: ▁of: 0\n",
      "476: ▁a: 0\n",
      "3760: ▁heart: 0\n",
      "6279: ▁attack: 0\n",
      "235269: ,: 0\n",
      "578: ▁and: 0\n",
      "573: ▁the: 0\n",
      "37191: ▁Montana: 0\n",
      "25682: ▁Democratic: 0\n",
      "10438: ▁Party: 0\n",
      "6410: ▁selected: 0\n",
      "926: ▁his: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "235269: ,: 0\n",
      "3040: ▁State: 0\n",
      "31203: ▁Senator: 0\n",
      "54141: ▁Judy: 0\n",
      "124221: ▁Jacobson: 0\n",
      "235269: ,: 0\n",
      "577: ▁to: 0\n",
      "7919: ▁replace: 0\n",
      "1357: ▁him: 0\n",
      "685: ▁as: 0\n",
      "573: ▁the: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "88524: ▁nominee: 0\n",
      "235269: ,: 0\n",
      "578: ▁and: 0\n",
      "1284: ▁she: 0\n",
      "5852: ▁therefore: 0\n",
      "9223: ▁appeared: 0\n",
      "611: ▁on: 0\n",
      "573: ▁the: 0\n",
      "43738: ▁ballot: 0\n",
      "685: ▁as: 0\n",
      "2145: ▁both: 0\n",
      "573: ▁the: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "88524: ▁nominee: 0\n",
      "578: ▁and: 0\n",
      "573: ▁the: 0\n",
      "67432: ▁lieutenant: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "88524: ▁nominee: 0\n",
      "235265: .: 0\n",
      "92397: ▁Ultimately: 0\n",
      "235269: ,: 0\n",
      "4187: ▁however: 0\n",
      "235269: ,: 0\n",
      "35175: ▁Rac: 0\n",
      "210456: icot: 0\n",
      "729: ▁was: 0\n",
      "3326: ▁able: 0\n",
      "577: ▁to: 0\n",
      "22597: ▁defeat: 0\n",
      "124221: ▁Jacobson: 0\n",
      "575: ▁in: 0\n",
      "476: ▁a: 0\n",
      "130565: ▁landslide: 0\n",
      "577: ▁to: 0\n",
      "3709: ▁win: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "50368: election: 0\n",
      "577: ▁to: 0\n",
      "926: ▁his: 0\n",
      "2257: ▁second: 0\n",
      "578: ▁and: 0\n",
      "2048: ▁final: 0\n",
      "5168: ▁term: 0\n",
      "685: ▁as: 0\n",
      "23699: ▁governor: 0\n",
      "235265: .: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "17870: North: 0\n",
      "32234: ▁Dakota: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235321: 8: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "714: ▁The: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235321: 8: 0\n",
      "4612: ▁North: 0\n",
      "32234: ▁Dakota: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "3895: ▁took: 0\n",
      "2040: ▁place: 0\n",
      "611: ▁on: 0\n",
      "5516: ▁November: 0\n",
      "235248: ▁: 0\n",
      "235321: 8: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235321: 8: 0\n",
      "577: ▁to: 0\n",
      "4226: ▁elect: 0\n",
      "573: ▁the: 0\n",
      "17486: ▁Governor: 0\n",
      "576: ▁of: 0\n",
      "4612: ▁North: 0\n",
      "32234: ▁Dakota: 0\n",
      "235265: .: 0\n",
      "5531: ▁Inc: 0\n",
      "55665: umbent: 0\n",
      "25682: ▁Democratic: 0\n",
      "17486: ▁Governor: 0\n",
      "7373: ▁George: 0\n",
      "586: ▁A: 0\n",
      "235265: .: 0\n",
      "570: ▁S: 0\n",
      "4311: inner: 0\n",
      "729: ▁was: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "74115: elected: 0\n",
      "577: ▁to: 0\n",
      "476: ▁a: 0\n",
      "2257: ▁second: 0\n",
      "5168: ▁term: 0\n",
      "675: ▁with: 0\n",
      "235248: ▁: 0\n",
      "235308: 5: 0\n",
      "235321: 8: 0\n",
      "235358: %: 0\n",
      "576: ▁of: 0\n",
      "573: ▁the: 0\n",
      "8744: ▁vote: 0\n",
      "235269: ,: 0\n",
      "90134: ▁defeating: 0\n",
      "25338: ▁Republican: 0\n",
      "88524: ▁nominee: 0\n",
      "15201: ▁Leon: 0\n",
      "24586: ▁Mall: 0\n",
      "4743: berg: 0\n",
      "235269: ,: 0\n",
      "476: ▁a: 0\n",
      "43559: ▁businessman: 0\n",
      "578: ▁and: 0\n",
      "664: ▁\": 0\n",
      "2236: anti: 0\n",
      "235290: -: 0\n",
      "16334: tax: 0\n",
      "63008: ▁crus: 0\n",
      "9899: ader: 0\n",
      "235281: \": 0\n",
      "578: ▁and: 0\n",
      "926: ▁his: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "49031: ▁Donna: 0\n",
      "104882: ▁Nal: 0\n",
      "1000: ew: 0\n",
      "8978: aja: 0\n",
      "235265: .: 0\n",
      "35597: ▁Lloyd: 0\n",
      "21576: ▁Om: 0\n",
      "107017: dahl: 0\n",
      "235269: ,: 0\n",
      "1064: ▁who: 0\n",
      "1093: ▁had: 0\n",
      "1125: ▁been: 0\n",
      "14824: ▁appointed: 0\n",
      "41943: ▁Lieutenant: 0\n",
      "17486: ▁Governor: 0\n",
      "576: ▁of: 0\n",
      "4612: ▁North: 0\n",
      "32234: ▁Dakota: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235324: 7: 0\n",
      "1452: ▁after: 0\n",
      "573: ▁the: 0\n",
      "4168: ▁death: 0\n",
      "576: ▁of: 0\n",
      "30422: ▁Ruth: 0\n",
      "1842: ▁Me: 0\n",
      "24298: iers: 0\n",
      "235269: ,: 0\n",
      "729: ▁was: 0\n",
      "17710: ▁elected: 0\n",
      "611: ▁on: 0\n",
      "573: ▁the: 0\n",
      "15457: ▁ticket: 0\n",
      "235265: .: 0\n",
      "1877: ▁As: 0\n",
      "576: ▁of: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235274: 1: 0\n",
      "235324: 7: 0\n",
      "235269: ,: 0\n",
      "603: ▁is: 0\n",
      "573: ▁the: 0\n",
      "1546: ▁most: 0\n",
      "6077: ▁recent: 0\n",
      "11621: ▁election: 0\n",
      "575: ▁in: 0\n",
      "948: ▁which: 0\n",
      "476: ▁a: 0\n",
      "53136: ▁Democrat: 0\n",
      "729: ▁was: 0\n",
      "17710: ▁elected: 0\n",
      "17486: ▁Governor: 0\n",
      "576: ▁of: 0\n",
      "4612: ▁North: 0\n",
      "32234: ▁Dakota: 0\n",
      "235265: .: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "18692: United: 0\n",
      "3858: ▁States: 0\n",
      "33363: ▁presidential: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "714: ▁The: 0\n",
      "3520: ▁United: 0\n",
      "3858: ▁States: 0\n",
      "33363: ▁presidential: 0\n",
      "11621: ▁election: 0\n",
      "576: ▁of: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "729: ▁was: 0\n",
      "573: ▁the: 0\n",
      "235248: ▁: 0\n",
      "235308: 5: 0\n",
      "235304: 3: 0\n",
      "1924: rd: 0\n",
      "12605: ▁quad: 0\n",
      "91769: renn: 0\n",
      "918: ial: 0\n",
      "33363: ▁presidential: 0\n",
      "11621: ▁election: 0\n",
      "235265: .: 0\n",
      "1165: ▁It: 0\n",
      "729: ▁was: 0\n",
      "4600: ▁held: 0\n",
      "611: ▁on: 0\n",
      "10111: ▁Tuesday: 0\n",
      "235269: ,: 0\n",
      "5516: ▁November: 0\n",
      "235248: ▁: 0\n",
      "235308: 5: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "235265: .: 0\n",
      "714: ▁The: 0\n",
      "25682: ▁Democratic: 0\n",
      "4975: ▁national: 0\n",
      "15457: ▁ticket: 0\n",
      "729: ▁was: 0\n",
      "5140: ▁led: 0\n",
      "731: ▁by: 0\n",
      "74974: ▁incumbent: 0\n",
      "6021: ▁President: 0\n",
      "8352: ▁Bill: 0\n",
      "30472: ▁Clinton: 0\n",
      "235269: ,: 0\n",
      "578: ▁and: 0\n",
      "926: ▁his: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "235269: ,: 0\n",
      "74974: ▁incumbent: 0\n",
      "17939: ▁Vice: 0\n",
      "6021: ▁President: 0\n",
      "1414: ▁Al: 0\n",
      "58783: ▁Gore: 0\n",
      "235265: .: 0\n",
      "714: ▁The: 0\n",
      "25338: ▁Republican: 0\n",
      "88524: ▁nominee: 0\n",
      "604: ▁for: 0\n",
      "6021: ▁President: 0\n",
      "729: ▁was: 0\n",
      "11270: ▁Bob: 0\n",
      "138840: ▁Dole: 0\n",
      "235269: ,: 0\n",
      "573: ▁the: 0\n",
      "5730: ▁former: 0\n",
      "25338: ▁Republican: 0\n",
      "27812: ▁Leader: 0\n",
      "576: ▁of: 0\n",
      "573: ▁the: 0\n",
      "3520: ▁United: 0\n",
      "3858: ▁States: 0\n",
      "17598: ▁Senate: 0\n",
      "578: ▁and: 0\n",
      "1497: ▁long: 0\n",
      "235290: -: 0\n",
      "1602: time: 0\n",
      "31203: ▁Senator: 0\n",
      "774: ▁from: 0\n",
      "22144: ▁Kansas: 0\n",
      "1064: ▁who: 0\n",
      "729: ▁was: 0\n",
      "10067: ▁previously: 0\n",
      "573: ▁the: 0\n",
      "16832: ▁vice: 0\n",
      "235290: -: 0\n",
      "9143: pres: 0\n",
      "12311: idential: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "576: ▁of: 0\n",
      "6021: ▁President: 0\n",
      "46000: ▁Gerald: 0\n",
      "15090: ▁Ford: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235324: 7: 0\n",
      "235318: 6: 0\n",
      "235269: ,: 0\n",
      "2412: ▁following: 0\n",
      "17939: ▁Vice: 0\n",
      "6021: ▁President: 0\n",
      "23053: ▁Nelson: 0\n",
      "102010: ▁Rockefeller: 0\n",
      "235303: ': 0\n",
      "235256: s: 0\n",
      "22531: ▁retirement: 0\n",
      "774: ▁from: 0\n",
      "16127: ▁politics: 0\n",
      "674: ▁that: 0\n",
      "1162: ▁year: 0\n",
      "235265: .: 0\n",
      "138840: ▁Dole: 0\n",
      "235303: ': 0\n",
      "235256: s: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "604: ▁for: 0\n",
      "17939: ▁Vice: 0\n",
      "6021: ▁President: 0\n",
      "729: ▁was: 0\n",
      "6592: ▁Jack: 0\n",
      "65545: ▁Kemp: 0\n",
      "235269: ,: 0\n",
      "476: ▁a: 0\n",
      "5730: ▁former: 0\n",
      "27023: ▁NFL: 0\n",
      "9715: ▁football: 0\n",
      "5398: ▁player: 0\n",
      "578: ▁and: 0\n",
      "573: ▁the: 0\n",
      "27013: ▁Housing: 0\n",
      "11264: ▁Secretary: 0\n",
      "1362: ▁under: 0\n",
      "7373: ▁George: 0\n",
      "640: ▁H: 0\n",
      "235265: .: 0\n",
      "647: ▁W: 0\n",
      "235265: .: 0\n",
      "24060: ▁Bush: 0\n",
      "235265: .: 0\n",
      "7211: ▁Business: 0\n",
      "1066: man: 0\n",
      "19106: ▁Ross: 0\n",
      "2399: ▁Per: 0\n",
      "562: ot: 0\n",
      "8876: ▁ran: 0\n",
      "685: ▁as: 0\n",
      "16152: ▁candidate: 0\n",
      "604: ▁for: 0\n",
      "573: ▁the: 0\n",
      "40275: ▁Reform: 0\n",
      "10438: ▁Party: 0\n",
      "675: ▁with: 0\n",
      "82250: ▁economist: 0\n",
      "4639: ▁Pat: 0\n",
      "7269: ▁Cho: 0\n",
      "607: ate: 0\n",
      "685: ▁as: 0\n",
      "926: ▁his: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "235289: ;: 0\n",
      "693: ▁he: 0\n",
      "4956: ▁received: 0\n",
      "2644: ▁less: 0\n",
      "4562: ▁media: 0\n",
      "6137: ▁attention: 0\n",
      "578: ▁and: 0\n",
      "729: ▁was: 0\n",
      "30111: ▁excluded: 0\n",
      "774: ▁from: 0\n",
      "573: ▁the: 0\n",
      "33363: ▁presidential: 0\n",
      "58539: ▁debates: 0\n",
      "578: ▁and: 0\n",
      "235269: ,: 0\n",
      "2183: ▁while: 0\n",
      "2076: ▁still: 0\n",
      "29319: ▁obtaining: 0\n",
      "18525: ▁substantial: 0\n",
      "3190: ▁results: 0\n",
      "604: ▁for: 0\n",
      "476: ▁a: 0\n",
      "4906: ▁third: 0\n",
      "235290: -: 0\n",
      "17921: party: 0\n",
      "16152: ▁candidate: 0\n",
      "235269: ,: 0\n",
      "731: ▁by: 0\n",
      "752: ▁U: 0\n",
      "235265: .: 0\n",
      "235277: S: 0\n",
      "235265: .: 0\n",
      "10053: ▁standards: 0\n",
      "235269: ,: 0\n",
      "1498: ▁did: 0\n",
      "780: ▁not: 0\n",
      "14290: ▁renew: 0\n",
      "926: ▁his: 0\n",
      "3361: ▁success: 0\n",
      "576: ▁of: 0\n",
      "573: ▁the: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235315: 9: 0\n",
      "235284: 2: 0\n",
      "11621: ▁election: 0\n",
      "235265: .: 0\n",
      "11956: ▁Turn: 0\n",
      "745: out: 0\n",
      "729: ▁was: 0\n",
      "14198: ▁registered: 0\n",
      "696: ▁at: 0\n",
      "235248: ▁: 0\n",
      "235310: 4: 0\n",
      "235315: 9: 0\n",
      "235265: .: 0\n",
      "235276: 0: 0\n",
      "13520: %,: 0\n",
      "573: ▁the: 0\n",
      "18558: ▁lowest: 0\n",
      "604: ▁for: 0\n",
      "476: ▁a: 0\n",
      "33363: ▁presidential: 0\n",
      "11621: ▁election: 0\n",
      "2754: ▁since: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235284: 2: 0\n",
      "235310: 4: 0\n",
      "235265: .: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "128794: Montana: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235321: 8: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "714: ▁The: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235321: 8: 0\n",
      "37191: ▁Montana: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "3895: ▁took: 0\n",
      "2040: ▁place: 0\n",
      "611: ▁on: 0\n",
      "5516: ▁November: 0\n",
      "235248: ▁: 0\n",
      "235321: 8: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235321: 8: 0\n",
      "235265: .: 0\n",
      "5531: ▁Inc: 0\n",
      "55665: umbent: 0\n",
      "17486: ▁Governor: 0\n",
      "576: ▁of: 0\n",
      "37191: ▁Montana: 0\n",
      "27789: ▁Ted: 0\n",
      "21396: ▁Schw: 0\n",
      "13961: inden: 0\n",
      "235269: ,: 0\n",
      "1064: ▁who: 0\n",
      "729: ▁was: 0\n",
      "1370: ▁first: 0\n",
      "17710: ▁elected: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235276: 0: 0\n",
      "578: ▁and: 0\n",
      "729: ▁was: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "74115: elected: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235321: 8: 0\n",
      "235310: 4: 0\n",
      "235269: ,: 0\n",
      "26858: ▁declined: 0\n",
      "577: ▁to: 0\n",
      "8361: ▁seek: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "50368: election: 0\n",
      "577: ▁to: 0\n",
      "476: ▁a: 0\n",
      "4906: ▁third: 0\n",
      "5168: ▁term: 0\n",
      "235269: ,: 0\n",
      "10241: ▁creating: 0\n",
      "671: ▁an: 0\n",
      "2174: ▁open: 0\n",
      "10250: ▁seat: 0\n",
      "235265: .: 0\n",
      "12936: ▁Stan: 0\n",
      "70637: ▁Stephens: 0\n",
      "235269: ,: 0\n",
      "573: ▁the: 0\n",
      "5730: ▁former: 0\n",
      "6021: ▁President: 0\n",
      "576: ▁of: 0\n",
      "573: ▁the: 0\n",
      "37191: ▁Montana: 0\n",
      "17598: ▁Senate: 0\n",
      "235269: ,: 0\n",
      "2792: ▁won: 0\n",
      "476: ▁a: 0\n",
      "3387: ▁close: 0\n",
      "25338: ▁Republican: 0\n",
      "7920: ▁primary: 0\n",
      "235269: ,: 0\n",
      "578: ▁and: 0\n",
      "11303: ▁advanced: 0\n",
      "577: ▁to: 0\n",
      "573: ▁the: 0\n",
      "3311: ▁general: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "1570: ▁where: 0\n",
      "693: ▁he: 0\n",
      "729: ▁was: 0\n",
      "21240: ▁opposed: 0\n",
      "731: ▁by: 0\n",
      "7536: ▁Thomas: 0\n",
      "9201: ▁Lee: 0\n",
      "16566: ▁Judge: 0\n",
      "235269: ,: 0\n",
      "21396: ▁Schw: 0\n",
      "13961: inden: 0\n",
      "235303: ': 0\n",
      "235256: s: 0\n",
      "64081: ▁predecessor: 0\n",
      "685: ▁as: 0\n",
      "23699: ▁governor: 0\n",
      "578: ▁and: 0\n",
      "573: ▁the: 0\n",
      "25682: ▁Democratic: 0\n",
      "88524: ▁nominee: 0\n",
      "235265: .: 0\n",
      "14861: ▁Though: 0\n",
      "573: ▁the: 0\n",
      "3311: ▁general: 0\n",
      "11621: ▁election: 0\n",
      "729: ▁was: 0\n",
      "216449: ▁hotly: 0\n",
      "81667: ▁contested: 0\n",
      "235269: ,: 0\n",
      "70637: ▁Stephens: 0\n",
      "20614: ▁ultimately: 0\n",
      "29534: ▁defeated: 0\n",
      "16566: ▁Judge: 0\n",
      "235269: ,: 0\n",
      "12433: ▁becoming: 0\n",
      "573: ▁the: 0\n",
      "1370: ▁first: 0\n",
      "25338: ▁Republican: 0\n",
      "577: ▁to: 0\n",
      "3709: ▁win: 0\n",
      "476: ▁a: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "575: ▁in: 0\n",
      "37191: ▁Montana: 0\n",
      "2754: ▁since: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "235310: 4: 0\n",
      "235265: .: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "128794: Montana: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235276: 0: 0\n",
      "235321: 8: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "714: ▁The: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235276: 0: 0\n",
      "235321: 8: 0\n",
      "37191: ▁Montana: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "729: ▁was: 0\n",
      "4600: ▁held: 0\n",
      "611: ▁on: 0\n",
      "5516: ▁November: 0\n",
      "235248: ▁: 0\n",
      "235310: 4: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235276: 0: 0\n",
      "235321: 8: 0\n",
      "577: ▁to: 0\n",
      "4226: ▁elect: 0\n",
      "573: ▁the: 0\n",
      "23699: ▁governor: 0\n",
      "578: ▁and: 0\n",
      "67432: ▁lieutenant: 0\n",
      "23699: ▁governor: 0\n",
      "576: ▁of: 0\n",
      "573: ▁the: 0\n",
      "752: ▁U: 0\n",
      "235265: .: 0\n",
      "235277: S: 0\n",
      "235265: .: 0\n",
      "2329: ▁state: 0\n",
      "576: ▁of: 0\n",
      "37191: ▁Montana: 0\n",
      "235265: .: 0\n",
      "5531: ▁Inc: 0\n",
      "55665: umbent: 0\n",
      "23699: ▁governor: 0\n",
      "19924: ▁Brian: 0\n",
      "220780: ▁Schweitzer: 0\n",
      "235269: ,: 0\n",
      "476: ▁a: 0\n",
      "53136: ▁Democrat: 0\n",
      "1064: ▁who: 0\n",
      "729: ▁was: 0\n",
      "17710: ▁elected: 0\n",
      "577: ▁to: 0\n",
      "926: ▁his: 0\n",
      "1370: ▁first: 0\n",
      "2785: ▁four: 0\n",
      "235290: -: 0\n",
      "4085: year: 0\n",
      "5168: ▁term: 0\n",
      "575: ▁in: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235276: 0: 0\n",
      "235310: 4: 0\n",
      "235269: ,: 0\n",
      "729: ▁was: 0\n",
      "17710: ▁elected: 0\n",
      "577: ▁to: 0\n",
      "476: ▁a: 0\n",
      "2257: ▁second: 0\n",
      "5168: ▁term: 0\n",
      "675: ▁with: 0\n",
      "235248: ▁: 0\n",
      "235318: 6: 0\n",
      "235308: 5: 0\n",
      "235265: .: 0\n",
      "235308: 5: 0\n",
      "842: ▁per: 0\n",
      "2565: ▁cent: 0\n",
      "576: ▁of: 0\n",
      "573: ▁the: 0\n",
      "8744: ▁vote: 0\n",
      "235265: .: 0\n",
      "3350: ▁John: 0\n",
      "2513: ▁Bo: 0\n",
      "743: hl: 0\n",
      "4676: inger: 0\n",
      "235269: ,: 0\n",
      "476: ▁a: 0\n",
      "25338: ▁Republican: 0\n",
      "578: ▁and: 0\n",
      "573: ▁the: 0\n",
      "74974: ▁incumbent: 0\n",
      "67432: ▁lieutenant: 0\n",
      "23699: ▁governor: 0\n",
      "235269: ,: 0\n",
      "729: ▁was: 0\n",
      "3631: ▁once: 0\n",
      "1653: ▁again: 0\n",
      "220780: ▁Schweitzer: 0\n",
      "235303: ': 0\n",
      "235256: s: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "235269: ,: 0\n",
      "578: ▁and: 0\n",
      "729: ▁was: 0\n",
      "582: ▁re: 0\n",
      "235290: -: 0\n",
      "74115: elected: 0\n",
      "577: ▁to: 0\n",
      "476: ▁a: 0\n",
      "2257: ▁second: 0\n",
      "5168: ▁term: 0\n",
      "235265: .: 0\n",
      "714: ▁The: 0\n",
      "25338: ▁Republican: 0\n",
      "88524: ▁nominee: 0\n",
      "729: ▁was: 0\n",
      "7582: ▁Roy: 0\n",
      "9231: ▁Brown: 0\n",
      "235269: ,: 0\n",
      "476: ▁a: 0\n",
      "4757: ▁member: 0\n",
      "576: ▁of: 0\n",
      "573: ▁the: 0\n",
      "37191: ▁Montana: 0\n",
      "17598: ▁Senate: 0\n",
      "235265: .: 0\n",
      "9231: ▁Brown: 0\n",
      "235303: ': 0\n",
      "235256: s: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "729: ▁was: 0\n",
      "43559: ▁businessman: 0\n",
      "235269: ,: 0\n",
      "578: ▁and: 0\n",
      "3936: ▁future: 0\n",
      "752: ▁U: 0\n",
      "235265: .: 0\n",
      "235277: S: 0\n",
      "235265: .: 0\n",
      "41097: ▁Representative: 0\n",
      "578: ▁and: 0\n",
      "752: ▁U: 0\n",
      "235265: .: 0\n",
      "235277: S: 0\n",
      "235265: .: 0\n",
      "31203: ▁Senator: 0\n",
      "235269: ,: 0\n",
      "15717: ▁Steve: 0\n",
      "608: ▁D: 0\n",
      "49878: aines: 0\n",
      "235265: .: 0\n",
      "4103: ▁`: 0\n",
      "132651: Dokument: 0\n",
      "892: ▁[: 0\n",
      "664: ▁\": 0\n",
      "16265: Steve: 0\n",
      "608: ▁D: 0\n",
      "49878: aines: 0\n",
      "235281: \": 0\n",
      "5896: ▁]: 0\n",
      "52735: :`: 0\n",
      "23114: ▁Steven: 0\n",
      "6046: ▁David: 0\n",
      "608: ▁D: 0\n",
      "49878: aines: 0\n",
      "591: ▁(: 0\n",
      "9813: born: 0\n",
      "4826: ▁August: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235269: ,: 0\n",
      "235248: ▁: 0\n",
      "235274: 1: 0\n",
      "235315: 9: 0\n",
      "235318: 6: 0\n",
      "235284: 2: 0\n",
      "235275: ): 0\n",
      "603: ▁is: 0\n",
      "671: ▁an: 0\n",
      "3725: ▁American: 0\n",
      "43559: ▁businessman: 0\n",
      "235269: ,: 0\n",
      "53840: ▁entrepreneur: 0\n",
      "235269: ,: 0\n",
      "578: ▁and: 0\n",
      "573: ▁the: 0\n",
      "21098: ▁junior: 0\n",
      "3520: ▁United: 0\n",
      "3858: ▁States: 0\n",
      "31203: ▁Senator: 0\n",
      "774: ▁from: 0\n",
      "37191: ▁Montana: 0\n",
      "235265: .: 0\n",
      "1315: ▁He: 0\n",
      "729: ▁was: 0\n",
      "573: ▁the: 0\n",
      "3520: ▁United: 0\n",
      "3858: ▁States: 0\n",
      "41097: ▁Representative: 0\n",
      "604: ▁for: 0\n",
      "37191: ▁Montana: 0\n",
      "235303: ': 0\n",
      "235256: s: 0\n",
      "696: ▁at: 0\n",
      "235290: -: 0\n",
      "13210: large: 0\n",
      "80700: ▁congressional: 0\n",
      "9220: ▁district: 0\n",
      "774: ▁from: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235274: 1: 0\n",
      "235304: 3: 0\n",
      "577: ▁to: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235274: 1: 0\n",
      "235308: 5: 0\n",
      "235265: .: 0\n",
      "878: ▁In: 0\n",
      "573: ▁the: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235274: 1: 0\n",
      "235310: 4: 0\n",
      "11621: ▁election: 0\n",
      "235269: ,: 0\n",
      "693: ▁he: 0\n",
      "2792: ▁won: 0\n",
      "671: ▁an: 0\n",
      "2174: ▁open: 0\n",
      "752: ▁U: 0\n",
      "235265: .: 0\n",
      "235277: S: 0\n",
      "235265: .: 0\n",
      "17598: ▁Senate: 0\n",
      "10250: ▁seat: 0\n",
      "235269: ,: 0\n",
      "90134: ▁defeating: 0\n",
      "53136: ▁Democrat: 0\n",
      "43069: ▁Amanda: 0\n",
      "46138: ▁Curtis: 0\n",
      "235265: .: 0\n",
      "235248: ▁: 0\n",
      "109: \n",
      "\n",
      ": 0\n",
      "141: ▁▁▁▁: 0\n",
      "235376: `: 0\n",
      "63741: QUERY: 0\n",
      "74412: `:: 0\n",
      "7582: ▁Roy: 0\n",
      "75051: ▁Browns: 0\n",
      "5327: ▁running: 0\n",
      "17380: ▁mate: 0\n",
      "575: ▁in: 0\n",
      "573: ▁the: 0\n",
      "235248: ▁: 0\n",
      "235284: 2: 0\n",
      "235276: 0: 0\n",
      "235276: 0: 0\n",
      "235321: 8: 0\n",
      "37191: ▁Montana: 0\n",
      "219677: ▁gubernatorial: 0\n",
      "11621: ▁election: 0\n",
      "2792: ▁won: 0\n",
      "926: ▁his: 0\n",
      "2474: ▁current: 0\n",
      "100235: ▁senate: 0\n",
      "10250: ▁seat: 0\n",
      "731: ▁by: 0\n",
      "90134: ▁defeating: 0\n",
      "1212: ▁what: 0\n",
      "110765: ▁democrat: 0\n",
      "235336: ?: 0\n",
      "109: \n",
      "\n",
      ": 0\n",
      "141: ▁▁▁▁: 0\n",
      "235376: `: 0\n",
      "72601: ANSWER: 0\n",
      "74412: `:: 0\n",
      "107: <end_of_turn>: 0\n",
      "108: \n",
      ": 0\n",
      "106: <start_of_turn>: 0\n",
      "2516: model: 0\n",
      "108: \n",
      ": 0\n",
      "58713: Amanda: 0\n",
      "46138: ▁Curtis: 0\n"
     ]
    }
   ],
   "source": [
    "for i, h in zip(inputs['input_ids'][0], hallu_mask):\n",
    "    print(f\"{i}: {reverted_tokenizer[i.item()]}: {h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main analysis - everything we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>model_response</th>\n",
       "      <th>decision</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>formatted_context</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>hallu_indicies</th>\n",
       "      <th>hallu_tokens</th>\n",
       "      <th>contain_hallu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bioask_1000</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Czy możliwe jest oczyszczenie pseudopodiów do ...</td>\n",
       "      <td>Pseudopodia mogą być oczyszczane przy użyciu r...</td>\n",
       "      <td>`Dokument [1]:` Migracja komórek wymaga wypukł...</td>\n",
       "      <td>1547</td>\n",
       "      <td>Tak, tekst mówi o metodzie oczyszczania pseudo...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>1521</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioask_1001</th>\n",
       "      <td>bioask</td>\n",
       "      <td>Jaki jest mechanizm działania deaminazy cytydy...</td>\n",
       "      <td>Podczas odwrotnej transkrypcji APOBEC3G deamin...</td>\n",
       "      <td>`Dokument [1]:` Rodzina deaminaz deoksycytydyn...</td>\n",
       "      <td>2445</td>\n",
       "      <td>APOBEC3G hamuje replikację wirusa HIV-1 poprze...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>2214</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset                                              query  \\\n",
       "bioask_1000  bioask  Czy możliwe jest oczyszczenie pseudopodiów do ...   \n",
       "bioask_1001  bioask  Jaki jest mechanizm działania deaminazy cytydy...   \n",
       "\n",
       "                                                        answer  \\\n",
       "bioask_1000  Pseudopodia mogą być oczyszczane przy użyciu r...   \n",
       "bioask_1001  Podczas odwrotnej transkrypcji APOBEC3G deamin...   \n",
       "\n",
       "                                                       context  \\\n",
       "bioask_1000  `Dokument [1]:` Migracja komórek wymaga wypukł...   \n",
       "bioask_1001  `Dokument [1]:` Rodzina deaminaz deoksycytydyn...   \n",
       "\n",
       "             context_length  \\\n",
       "bioask_1000            1547   \n",
       "bioask_1001            2445   \n",
       "\n",
       "                                                model_response  decision  \\\n",
       "bioask_1000  Tak, tekst mówi o metodzie oczyszczania pseudo...      True   \n",
       "bioask_1001  APOBEC3G hamuje replikację wirusa HIV-1 poprze...      True   \n",
       "\n",
       "            problematic_spans  \\\n",
       "bioask_1000                []   \n",
       "bioask_1001                []   \n",
       "\n",
       "                                             formatted_context  prompt_length  \\\n",
       "bioask_1000  <bos><start_of_turn>user\\nYou are a helpful as...           1521   \n",
       "bioask_1001  <bos><start_of_turn>user\\nYou are a helpful as...           2214   \n",
       "\n",
       "            hallu_indicies                                       hallu_tokens  \\\n",
       "bioask_1000             []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "bioask_1001             []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "             contain_hallu  \n",
       "bioask_1000          False  \n",
       "bioask_1001          False  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_count, true_count = df['contain_hallu'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5064, 832)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_count, true_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=42,\n",
    "    stratify=df['contain_hallu']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_parquet(os.path.join('..', 'data', 'train_all_sample.parquet'))\n",
    "test_set.to_parquet(os.path.join('..', 'data', 'test_all_sample.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter only needed attension files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SAMPLE_FILE = 'train_all_sample.parquet'\n",
    "TEST_SAMPLE_FILE = 'test_research_sample.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(os.path.join('..', DATA_DIR, TRAIN_SAMPLE_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nq             1403\n",
       "poquad_v2      1169\n",
       "hotpotqa_en     847\n",
       "polqa           560\n",
       "hotpotqa_pl     520\n",
       "bioask          217\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>model_response</th>\n",
       "      <th>decision</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>formatted_context</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>hallu_indicies</th>\n",
       "      <th>hallu_tokens</th>\n",
       "      <th>contain_hallu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nq_507</th>\n",
       "      <td>nq</td>\n",
       "      <td>where is the capital city of alabama located</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>`Dokument [ \"Alabama\" ]:` capital from 1817 to...</td>\n",
       "      <td>1598</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>1597</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poquad_v2_27597</th>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Czy występowała kiedykolwiek w Polsce?</td>\n",
       "      <td>tak</td>\n",
       "      <td>`Dokument [ \"Montserrat Caballé\" ]:` W 1963 od...</td>\n",
       "      <td>423</td>\n",
       "      <td>Tak, tekst mówi, że \"Kilkakrotnie gościła takż...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>422</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset                                         query  \\\n",
       "nq_507                  nq  where is the capital city of alabama located   \n",
       "poquad_v2_27597  poquad_v2        Czy występowała kiedykolwiek w Polsce?   \n",
       "\n",
       "                     answer  \\\n",
       "nq_507           Montgomery   \n",
       "poquad_v2_27597         tak   \n",
       "\n",
       "                                                           context  \\\n",
       "nq_507           `Dokument [ \"Alabama\" ]:` capital from 1817 to...   \n",
       "poquad_v2_27597  `Dokument [ \"Montserrat Caballé\" ]:` W 1963 od...   \n",
       "\n",
       "                 context_length  \\\n",
       "nq_507                     1598   \n",
       "poquad_v2_27597             423   \n",
       "\n",
       "                                                    model_response  decision  \\\n",
       "nq_507                                                  Montgomery      True   \n",
       "poquad_v2_27597  Tak, tekst mówi, że \"Kilkakrotnie gościła takż...      True   \n",
       "\n",
       "                problematic_spans  \\\n",
       "nq_507                         []   \n",
       "poquad_v2_27597                []   \n",
       "\n",
       "                                                 formatted_context  \\\n",
       "nq_507           <bos><start_of_turn>user\\nYou are a helpful as...   \n",
       "poquad_v2_27597  <bos><start_of_turn>user\\nYou are a helpful as...   \n",
       "\n",
       "                 prompt_length hallu_indicies  \\\n",
       "nq_507                    1597             []   \n",
       "poquad_v2_27597            422             []   \n",
       "\n",
       "                                                      hallu_tokens  \\\n",
       "nq_507           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "poquad_v2_27597  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                 contain_hallu  \n",
       "nq_507                   False  \n",
       "poquad_v2_27597          False  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nq_507                                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "poquad_v2_27597                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "poquad_v2_45033                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "hotpotqa_en_5ae3deb35542992e3233c488    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "poquad_v2_17864                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "                                                              ...                        \n",
       "hotpotqa_pl_5add2b435542990d50227e11    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "poquad_v2_11955                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "polqa_6926                              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "nq_223                                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "nq_679                                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: hallu_tokens, Length: 4716, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hallu_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSET_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_att_pipe(\n",
    "    att_path: str,\n",
    "    n_context_tokens: int,\n",
    "    n_prompt_tokens: int,\n",
    "    offset_size: int = 16\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function to prepare the attention tensor for further analysis.\n",
    "    It removes the prompt tokens and the last offset_size tokens from the context.\n",
    "    \"\"\"\n",
    "\n",
    "    att_tensor = np.load(att_path)\n",
    "    print('Initial shape:', att_tensor.shape)\n",
    "    att_tensor = att_tensor[..., n_prompt_tokens - offset_size: n_context_tokens, :n_context_tokens]\n",
    "    print('Final shape:', att_tensor.shape)\n",
    "\n",
    "    return att_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_times = []\n",
    "tensor_sizes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_file: 340.npy\n",
      "n_context_tokens = 335, n_prompt_tokens = 330\n",
      "Initial shape: (42, 16, 338, 338)\n",
      "Final shape: (42, 16, 21, 335)\n",
      "Size of att_tensor 340: 9.0170 MB\n",
      "att_file: 443.npy\n",
      "n_context_tokens = 1674, n_prompt_tokens = 1665\n",
      "Initial shape: (42, 16, 1677, 1677)\n",
      "Final shape: (42, 16, 25, 1674)\n",
      "Size of att_tensor 443: 53.6407 MB\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "\n",
    "    start = perf_counter()\n",
    "\n",
    "    att_file = f\"{row['gpt_index']}.npy\"\n",
    "    print(f\"att_file: {att_file}\")\n",
    "\n",
    "    n_context_tokens = len(row['hallu_tokens'])\n",
    "    n_prompt_tokens = row['prompt_length']\n",
    "\n",
    "    print(f\"{n_context_tokens = }, {n_prompt_tokens = }\")\n",
    "\n",
    "    att_path = os.path.join(ATT_PATH, att_file)\n",
    "    att_tensor = prep_att_pipe(att_path, n_context_tokens, n_prompt_tokens, OFFSET_SIZE)\n",
    "\n",
    "    loading_times.append(perf_counter() - start)\n",
    "\n",
    "    size_in_mb = att_tensor.nbytes / (1024 * 1024)\n",
    "    tensor_sizes.append(size_in_mb)\n",
    "    print(f\"Size of att_tensor {row['gpt_index']}: {size_in_mb:.4f} MB\")\n",
    "\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 16, 25, 1674)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Mean loading time: 0.6715 s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Mean tensor size: 44.3507 MB"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"### Mean loading time: {np.mean(loading_times):.4f} s\"))\n",
    "display(Markdown(f\"### Mean tensor size: {np.mean(tensor_sizes):.4f} MB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Estimated time for loading all samples: 355.25 s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Estimated memory usage: 22.912 GB"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_SAMPLES = len(df)\n",
    "display(Markdown(f\"### Estimated time for loading all samples: {np.mean(loading_times) * N_SAMPLES:.2f} s\"))\n",
    "display(Markdown(f\"### Estimated memory usage: {np.mean(tensor_sizes) * N_SAMPLES / 1024:.3f} GB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Available memory: 69.765 GB"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "available_memory = psutil.virtual_memory().available\n",
    "available_memory_gb = available_memory / (1024 ** 3)\n",
    "\n",
    "display(Markdown(f\"### Available memory: {available_memory_gb:.3f} GB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, so it is possible to load all data if we reshape / cut data in a smart way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "nq             142\n",
       "poquad_v2      141\n",
       "hotpotqa_en     89\n",
       "polqa           67\n",
       "hotpotqa_pl     53\n",
       "bioask          37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contain_hallu\n",
       "False    403\n",
       "True     126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['contain_hallu'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(os.path.join('..', 'data', 'new_version_merged_df.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nq_0</td>\n",
       "      <td>nq</td>\n",
       "      <td>who got the first nobel prize in physics</td>\n",
       "      <td>Wilhelm Conrad Röntgen</td>\n",
       "      <td>`Dokument [ \"Nobel Prize in Physics\" ]:` recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nq_1</td>\n",
       "      <td>nq</td>\n",
       "      <td>when is the next deadpool movie being released</td>\n",
       "      <td>May 18, 2018</td>\n",
       "      <td>`Dokument [ \"Deadpool (video game)\" ]:` 2015 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nq_2</td>\n",
       "      <td>nq</td>\n",
       "      <td>the south west wind blows across nigeria between</td>\n",
       "      <td>till September</td>\n",
       "      <td>`Dokument [ \"Geography of Nigeria\" ]:` south a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nq_3</td>\n",
       "      <td>nq</td>\n",
       "      <td>what does hp mean in war and order</td>\n",
       "      <td>hit points or health points</td>\n",
       "      <td>`Dokument [ \"Order of War\" ]:` Order of War Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nq_4</td>\n",
       "      <td>nq</td>\n",
       "      <td>who wrote the first declaration of human rights</td>\n",
       "      <td>Cyrus</td>\n",
       "      <td>`Dokument [ \"Drafting of the Universal Declara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>bioask_440</td>\n",
       "      <td>bioask</td>\n",
       "      <td>Jaki jest odsetek osób reagujących na leczenie...</td>\n",
       "      <td>Tetrabenazyna jest stosowana empirycznie w lec...</td>\n",
       "      <td>`Dokument [1]:` WPROWADZENIE: Zwapnienia mózgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>bioask_715</td>\n",
       "      <td>bioask</td>\n",
       "      <td>Która kinaza jest hamowana przez Tripolinę A?</td>\n",
       "      <td>Tripolina A zmniejszała lokalizację pAurory A ...</td>\n",
       "      <td>`Dokument [1]:` Regulatory mitotyczne wykazują...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>bioask_1207</td>\n",
       "      <td>bioask</td>\n",
       "      <td>Jaka jest rola prognostyczna zmienionego profi...</td>\n",
       "      <td>Zmieniony profil tarczycy po operacji kardioch...</td>\n",
       "      <td>`Dokument [1]:` CEL: Pomimo poprawy postępowan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>bioask_1327</td>\n",
       "      <td>bioask</td>\n",
       "      <td>Czy istnieje różnica w szybkości fuzji i rozsz...</td>\n",
       "      <td>Tak. W kilku badaniach oszacowano, że fuzja i ...</td>\n",
       "      <td>`Dokument [1]:` Domeny białkowe są zwartymi ew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>bioask_511</td>\n",
       "      <td>bioask</td>\n",
       "      <td>Czy mutacje BBS są związane z zespołową chorob...</td>\n",
       "      <td>W 3 rodzinach z zespołem Bardeta-Biedla (BBS) ...</td>\n",
       "      <td>`Dokument [1]:` Choroba Hirschsprunga (HSCR) j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6224 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id dataset                                           question  \\\n",
       "0            nq_0      nq           who got the first nobel prize in physics   \n",
       "1            nq_1      nq     when is the next deadpool movie being released   \n",
       "2            nq_2      nq   the south west wind blows across nigeria between   \n",
       "3            nq_3      nq                 what does hp mean in war and order   \n",
       "4            nq_4      nq    who wrote the first declaration of human rights   \n",
       "...           ...     ...                                                ...   \n",
       "6219   bioask_440  bioask  Jaki jest odsetek osób reagujących na leczenie...   \n",
       "6220   bioask_715  bioask      Która kinaza jest hamowana przez Tripolinę A?   \n",
       "6221  bioask_1207  bioask  Jaka jest rola prognostyczna zmienionego profi...   \n",
       "6222  bioask_1327  bioask  Czy istnieje różnica w szybkości fuzji i rozsz...   \n",
       "6223   bioask_511  bioask  Czy mutacje BBS są związane z zespołową chorob...   \n",
       "\n",
       "                                                 answer  \\\n",
       "0                                Wilhelm Conrad Röntgen   \n",
       "1                                          May 18, 2018   \n",
       "2                                        till September   \n",
       "3                           hit points or health points   \n",
       "4                                                 Cyrus   \n",
       "...                                                 ...   \n",
       "6219  Tetrabenazyna jest stosowana empirycznie w lec...   \n",
       "6220  Tripolina A zmniejszała lokalizację pAurory A ...   \n",
       "6221  Zmieniony profil tarczycy po operacji kardioch...   \n",
       "6222  Tak. W kilku badaniach oszacowano, że fuzja i ...   \n",
       "6223  W 3 rodzinach z zespołem Bardeta-Biedla (BBS) ...   \n",
       "\n",
       "                                                context  \n",
       "0     `Dokument [ \"Nobel Prize in Physics\" ]:` recei...  \n",
       "1     `Dokument [ \"Deadpool (video game)\" ]:` 2015 i...  \n",
       "2     `Dokument [ \"Geography of Nigeria\" ]:` south a...  \n",
       "3     `Dokument [ \"Order of War\" ]:` Order of War Or...  \n",
       "4     `Dokument [ \"Drafting of the Universal Declara...  \n",
       "...                                                 ...  \n",
       "6219  `Dokument [1]:` WPROWADZENIE: Zwapnienia mózgu...  \n",
       "6220  `Dokument [1]:` Regulatory mitotyczne wykazują...  \n",
       "6221  `Dokument [1]:` CEL: Pomimo poprawy postępowan...  \n",
       "6222  `Dokument [1]:` Domeny białkowe są zwartymi ew...  \n",
       "6223  `Dokument [1]:` Choroba Hirschsprunga (HSCR) j...  \n",
       "\n",
       "[6224 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>formatted_context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>answer_length</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>model_response</th>\n",
       "      <th>gpt_index</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>hallu_indicies</th>\n",
       "      <th>hallu_tokens</th>\n",
       "      <th>contain_hallu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3265</td>\n",
       "      <td>poquad_v2_9553</td>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Jak nazywa się tradycyjne odzienie mieszkańców...</td>\n",
       "      <td>ta’ovala</td>\n",
       "      <td>`Dokument [ \"Tonga na Zimowych Igrzyskach Olim...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>573</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>`ta’ovala`</td>\n",
       "      <td>340</td>\n",
       "      <td>330</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1601</td>\n",
       "      <td>nq_2342</td>\n",
       "      <td>nq</td>\n",
       "      <td>who hosted and won the inagural world cup</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>`Dokument [ \"Patrick Nally\" ]:` marketing for ...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>1908</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>Uruguay hosted and won the inaugural World Cup.</td>\n",
       "      <td>443</td>\n",
       "      <td>1665</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1590</td>\n",
       "      <td>nq_2324</td>\n",
       "      <td>nq</td>\n",
       "      <td>who is president of india in present time</td>\n",
       "      <td>Ram Nath Kovind</td>\n",
       "      <td>`Dokument [ \"A. P. J. Abdul Kalam\" ]:` 11th pr...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>1719</td>\n",
       "      <td>5</td>\n",
       "      <td>[Nie mogę udzielić odpowiedzi na to pytanie na...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>218</td>\n",
       "      <td>1476</td>\n",
       "      <td>[[6469, 6543]]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              id    dataset  \\\n",
       "0   3265  poquad_v2_9553  poquad_v2   \n",
       "1   1601         nq_2342         nq   \n",
       "2   1590         nq_2324         nq   \n",
       "\n",
       "                                               query           answer  \\\n",
       "0  Jak nazywa się tradycyjne odzienie mieszkańców...         ta’ovala   \n",
       "1          who hosted and won the inagural world cup          Uruguay   \n",
       "2          who is president of india in present time  Ram Nath Kovind   \n",
       "\n",
       "                                             context  \\\n",
       "0  `Dokument [ \"Tonga na Zimowych Igrzyskach Olim...   \n",
       "1  `Dokument [ \"Patrick Nally\" ]:` marketing for ...   \n",
       "2  `Dokument [ \"A. P. J. Abdul Kalam\" ]:` 11th pr...   \n",
       "\n",
       "                                   formatted_context  context_length  \\\n",
       "0  <bos><start_of_turn>user\\nYou are a helpful as...             573   \n",
       "1  <bos><start_of_turn>user\\nYou are a helpful as...            1908   \n",
       "2  <bos><start_of_turn>user\\nYou are a helpful as...            1719   \n",
       "\n",
       "   answer_length                                  problematic_spans  \\\n",
       "0              4                                                 []   \n",
       "1              2                                                 []   \n",
       "2              5  [Nie mogę udzielić odpowiedzi na to pytanie na...   \n",
       "\n",
       "                                      model_response  gpt_index  \\\n",
       "0                                         `ta’ovala`        340   \n",
       "1    Uruguay hosted and won the inaugural World Cup.        443   \n",
       "2  Nie mogę udzielić odpowiedzi na to pytanie na ...        218   \n",
       "\n",
       "   prompt_length  hallu_indicies  \\\n",
       "0            330              []   \n",
       "1           1665              []   \n",
       "2           1476  [[6469, 6543]]   \n",
       "\n",
       "                                        hallu_tokens  contain_hallu  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          False  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          False  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           True  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "```python\n",
    "Y.append(row['hallu_tokens'][n_prompt_tokens - OFFSET_SIZE: ])\n",
    "```\n",
    "### Here comes the trick - it is not the attenion vector for new token, but but previous one which **produced** that token. We need to find what characterizes the previous token attenions - they cause next token. And also attension pattern for last token is always the same so to describe that token we need to take its predestors. For example we can take the `window aproach` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSET_SIZE = 4\n",
    "FIRST_N_TOKENS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client.from_service_account_json(\n",
    "    os.path.join(\"..\", \"secrets\", \"storage-gcp-key.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Bucket: hallucination-detection>\n"
     ]
    }
   ],
   "source": [
    "for t in client.list_buckets():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'hallucination-detection'\n",
    "bucket = client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>formatted_context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>answer_length</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>model_response</th>\n",
       "      <th>gpt_index</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>hallu_indicies</th>\n",
       "      <th>hallu_tokens</th>\n",
       "      <th>contain_hallu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3265</td>\n",
       "      <td>poquad_v2_9553</td>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Jak nazywa się tradycyjne odzienie mieszkańców...</td>\n",
       "      <td>ta’ovala</td>\n",
       "      <td>`Dokument [ \"Tonga na Zimowych Igrzyskach Olim...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>573</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>`ta’ovala`</td>\n",
       "      <td>340</td>\n",
       "      <td>330</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1601</td>\n",
       "      <td>nq_2342</td>\n",
       "      <td>nq</td>\n",
       "      <td>who hosted and won the inagural world cup</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>`Dokument [ \"Patrick Nally\" ]:` marketing for ...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>1908</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>Uruguay hosted and won the inaugural World Cup.</td>\n",
       "      <td>443</td>\n",
       "      <td>1665</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              id    dataset  \\\n",
       "0   3265  poquad_v2_9553  poquad_v2   \n",
       "1   1601         nq_2342         nq   \n",
       "\n",
       "                                               query    answer  \\\n",
       "0  Jak nazywa się tradycyjne odzienie mieszkańców...  ta’ovala   \n",
       "1          who hosted and won the inagural world cup   Uruguay   \n",
       "\n",
       "                                             context  \\\n",
       "0  `Dokument [ \"Tonga na Zimowych Igrzyskach Olim...   \n",
       "1  `Dokument [ \"Patrick Nally\" ]:` marketing for ...   \n",
       "\n",
       "                                   formatted_context  context_length  \\\n",
       "0  <bos><start_of_turn>user\\nYou are a helpful as...             573   \n",
       "1  <bos><start_of_turn>user\\nYou are a helpful as...            1908   \n",
       "\n",
       "   answer_length problematic_spans  \\\n",
       "0              4                []   \n",
       "1              2                []   \n",
       "\n",
       "                                    model_response  gpt_index  prompt_length  \\\n",
       "0                                       `ta’ovala`        340            330   \n",
       "1  Uruguay hosted and won the inaugural World Cup.        443           1665   \n",
       "\n",
       "  hallu_indicies                                       hallu_tokens  \\\n",
       "0             []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1             []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "   contain_hallu  \n",
       "0          False  \n",
       "1          False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>formatted_context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>answer_length</th>\n",
       "      <th>problematic_spans</th>\n",
       "      <th>model_response</th>\n",
       "      <th>gpt_index</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>hallu_indicies</th>\n",
       "      <th>hallu_tokens</th>\n",
       "      <th>contain_hallu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2201</td>\n",
       "      <td>poquad_v2_7837</td>\n",
       "      <td>poquad_v2</td>\n",
       "      <td>Jak nazywał się ostatni krążownik liniowy na ś...</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>`Dokument [ \"Krążowniki liniowe typu Lion\" ]:`...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a helpful as...</td>\n",
       "      <td>589</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Nie mogę udzielić odpowiedzi na to pytanie na ...</td>\n",
       "      <td>351</td>\n",
       "      <td>346</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index              id    dataset  \\\n",
       "15   2201  poquad_v2_7837  poquad_v2   \n",
       "\n",
       "                                                query  \\\n",
       "15  Jak nazywał się ostatni krążownik liniowy na ś...   \n",
       "\n",
       "                                               answer  \\\n",
       "15  Nie mogę udzielić odpowiedzi na to pytanie na ...   \n",
       "\n",
       "                                              context  \\\n",
       "15  `Dokument [ \"Krążowniki liniowe typu Lion\" ]:`...   \n",
       "\n",
       "                                    formatted_context  context_length  \\\n",
       "15  <bos><start_of_turn>user\\nYou are a helpful as...             589   \n",
       "\n",
       "    answer_length problematic_spans  \\\n",
       "15             17                []   \n",
       "\n",
       "                                       model_response  gpt_index  \\\n",
       "15  Nie mogę udzielić odpowiedzi na to pytanie na ...        351   \n",
       "\n",
       "    prompt_length hallu_indicies  \\\n",
       "15            346             []   \n",
       "\n",
       "                                         hallu_tokens  contain_hallu  \n",
       "15  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          False  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['gpt_index'] == 351]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_file: 508.npy\n",
      "n_context_tokens = 1662, n_prompt_tokens = 1626\n",
      "Initial shape: (42, 16, 1665, 1665)\n",
      "Final shape: (42, 16, 52, 1662)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/508_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 506.npy\n",
      "n_context_tokens = 365, n_prompt_tokens = 345\n",
      "Initial shape: (42, 16, 368, 368)\n",
      "Final shape: (42, 16, 36, 365)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/506_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 361.npy\n",
      "n_context_tokens = 1073, n_prompt_tokens = 1056\n",
      "Initial shape: (42, 16, 1076, 1076)\n",
      "Final shape: (42, 16, 33, 1073)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/361_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 603.npy\n",
      "n_context_tokens = 1525, n_prompt_tokens = 1499\n",
      "Initial shape: (42, 16, 1528, 1528)\n",
      "Final shape: (42, 16, 42, 1525)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/603_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 170.npy\n",
      "n_context_tokens = 1417, n_prompt_tokens = 1397\n",
      "Initial shape: (42, 16, 1420, 1420)\n",
      "Final shape: (42, 16, 36, 1417)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/170_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 60.npy\n",
      "n_context_tokens = 1638, n_prompt_tokens = 1635\n",
      "Initial shape: (42, 16, 1641, 1641)\n",
      "Final shape: (42, 16, 19, 1638)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/60_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 624.npy\n",
      "n_context_tokens = 412, n_prompt_tokens = 374\n",
      "Initial shape: (42, 16, 415, 415)\n",
      "Final shape: (42, 16, 54, 412)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/624_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 376.npy\n",
      "n_context_tokens = 1518, n_prompt_tokens = 1515\n",
      "Initial shape: (42, 16, 1521, 1521)\n",
      "Final shape: (42, 16, 19, 1518)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/376_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 92.npy\n",
      "n_context_tokens = 881, n_prompt_tokens = 864\n",
      "Initial shape: (42, 16, 884, 884)\n",
      "Final shape: (42, 16, 33, 881)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/92_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 590.npy\n",
      "n_context_tokens = 953, n_prompt_tokens = 914\n",
      "Initial shape: (42, 16, 956, 956)\n",
      "Final shape: (42, 16, 55, 953)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/590_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 251.npy\n",
      "n_context_tokens = 962, n_prompt_tokens = 884\n",
      "Initial shape: (42, 16, 966, 966)\n",
      "Final shape: (42, 16, 94, 962)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/251_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 327.npy\n",
      "n_context_tokens = 2065, n_prompt_tokens = 2034\n",
      "Initial shape: (42, 16, 2068, 2068)\n",
      "Final shape: (42, 16, 47, 2065)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/327_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 496.npy\n",
      "n_context_tokens = 1782, n_prompt_tokens = 1765\n",
      "Initial shape: (42, 16, 1785, 1785)\n",
      "Final shape: (42, 16, 33, 1782)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/496_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 679.npy\n",
      "n_context_tokens = 1876, n_prompt_tokens = 1874\n",
      "Initial shape: (42, 16, 1879, 1879)\n",
      "Final shape: (42, 16, 18, 1876)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/679_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 187.npy\n",
      "n_context_tokens = 441, n_prompt_tokens = 433\n",
      "Initial shape: (42, 16, 444, 444)\n",
      "Final shape: (42, 16, 24, 441)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/187_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 558.npy\n",
      "n_context_tokens = 531, n_prompt_tokens = 514\n",
      "Initial shape: (42, 16, 534, 534)\n",
      "Final shape: (42, 16, 33, 531)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/558_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 98.npy\n",
      "n_context_tokens = 1712, n_prompt_tokens = 1695\n",
      "Initial shape: (42, 16, 1715, 1715)\n",
      "Final shape: (42, 16, 33, 1712)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/98_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 400.npy\n",
      "n_context_tokens = 1579, n_prompt_tokens = 1575\n",
      "Initial shape: (42, 16, 1582, 1582)\n",
      "Final shape: (42, 16, 20, 1579)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/400_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 513.npy\n",
      "n_context_tokens = 338, n_prompt_tokens = 321\n",
      "Initial shape: (42, 16, 341, 341)\n",
      "Final shape: (42, 16, 33, 338)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/513_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 663.npy\n",
      "n_context_tokens = 1658, n_prompt_tokens = 1656\n",
      "Initial shape: (42, 16, 1661, 1661)\n",
      "Final shape: (42, 16, 18, 1658)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/663_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 153.npy\n",
      "n_context_tokens = 2154, n_prompt_tokens = 2137\n",
      "Initial shape: (42, 16, 2157, 2157)\n",
      "Final shape: (42, 16, 33, 2154)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/153_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 281.npy\n",
      "n_context_tokens = 391, n_prompt_tokens = 389\n",
      "Initial shape: (42, 16, 394, 394)\n",
      "Final shape: (42, 16, 18, 391)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/281_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 373.npy\n",
      "n_context_tokens = 627, n_prompt_tokens = 607\n",
      "Initial shape: (42, 16, 630, 630)\n",
      "Final shape: (42, 16, 36, 627)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/373_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 578.npy\n",
      "n_context_tokens = 1538, n_prompt_tokens = 1519\n",
      "Initial shape: (42, 16, 1541, 1541)\n",
      "Final shape: (42, 16, 35, 1538)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/578_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 139.npy\n",
      "n_context_tokens = 888, n_prompt_tokens = 849\n",
      "Initial shape: (42, 16, 891, 891)\n",
      "Final shape: (42, 16, 55, 888)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/139_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 124.npy\n",
      "n_context_tokens = 2346, n_prompt_tokens = 2344\n",
      "Initial shape: (42, 16, 2349, 2349)\n",
      "Final shape: (42, 16, 18, 2346)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/124_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 369.npy\n",
      "n_context_tokens = 693, n_prompt_tokens = 676\n",
      "Initial shape: (42, 16, 696, 696)\n",
      "Final shape: (42, 16, 33, 693)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/369_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 100.npy\n",
      "n_context_tokens = 418, n_prompt_tokens = 416\n",
      "Initial shape: (42, 16, 421, 421)\n",
      "Final shape: (42, 16, 18, 418)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/100_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 471.npy\n",
      "n_context_tokens = 1591, n_prompt_tokens = 1527\n",
      "Initial shape: (42, 16, 1594, 1594)\n",
      "Final shape: (42, 16, 80, 1591)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/471_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 51.npy\n",
      "n_context_tokens = 581, n_prompt_tokens = 564\n",
      "Initial shape: (42, 16, 584, 584)\n",
      "Final shape: (42, 16, 33, 581)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/51_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 472.npy\n",
      "n_context_tokens = 508, n_prompt_tokens = 472\n",
      "Initial shape: (42, 16, 511, 511)\n",
      "Final shape: (42, 16, 52, 508)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/472_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 655.npy\n",
      "n_context_tokens = 418, n_prompt_tokens = 401\n",
      "Initial shape: (42, 16, 421, 421)\n",
      "Final shape: (42, 16, 33, 418)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/655_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 210.npy\n",
      "n_context_tokens = 2029, n_prompt_tokens = 2001\n",
      "Initial shape: (42, 16, 2032, 2032)\n",
      "Final shape: (42, 16, 44, 2029)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/210_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 212.npy\n",
      "n_context_tokens = 1259, n_prompt_tokens = 1247\n",
      "Initial shape: (42, 16, 1262, 1262)\n",
      "Final shape: (42, 16, 28, 1259)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/212_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 314.npy\n",
      "n_context_tokens = 1615, n_prompt_tokens = 1596\n",
      "Initial shape: (42, 16, 1618, 1618)\n",
      "Final shape: (42, 16, 35, 1615)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/314_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 276.npy\n",
      "n_context_tokens = 1836, n_prompt_tokens = 1820\n",
      "Initial shape: (42, 16, 1839, 1839)\n",
      "Final shape: (42, 16, 32, 1836)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/276_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 429.npy\n",
      "n_context_tokens = 1267, n_prompt_tokens = 1261\n",
      "Initial shape: (42, 16, 1270, 1270)\n",
      "Final shape: (42, 16, 22, 1267)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/429_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 623.npy\n",
      "n_context_tokens = 1392, n_prompt_tokens = 1339\n",
      "Initial shape: (42, 16, 1395, 1395)\n",
      "Final shape: (42, 16, 69, 1392)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/623_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 334.npy\n",
      "n_context_tokens = 461, n_prompt_tokens = 455\n",
      "Initial shape: (42, 16, 462, 462)\n",
      "Final shape: (42, 16, 22, 461)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/334_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 261.npy\n",
      "n_context_tokens = 407, n_prompt_tokens = 401\n",
      "Initial shape: (42, 16, 410, 410)\n",
      "Final shape: (42, 16, 22, 407)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/261_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 480.npy\n",
      "n_context_tokens = 366, n_prompt_tokens = 349\n",
      "Initial shape: (42, 16, 369, 369)\n",
      "Final shape: (42, 16, 33, 366)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/480_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 651.npy\n",
      "n_context_tokens = 907, n_prompt_tokens = 892\n",
      "Initial shape: (42, 16, 910, 910)\n",
      "Final shape: (42, 16, 31, 907)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/651_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 344.npy\n",
      "n_context_tokens = 838, n_prompt_tokens = 830\n",
      "Initial shape: (42, 16, 841, 841)\n",
      "Final shape: (42, 16, 24, 838)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/344_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 368.npy\n",
      "n_context_tokens = 837, n_prompt_tokens = 833\n",
      "Initial shape: (42, 16, 840, 840)\n",
      "Final shape: (42, 16, 20, 837)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/368_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 231.npy\n",
      "n_context_tokens = 946, n_prompt_tokens = 929\n",
      "Initial shape: (42, 16, 949, 949)\n",
      "Final shape: (42, 16, 33, 946)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/231_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 477.npy\n",
      "n_context_tokens = 1625, n_prompt_tokens = 1622\n",
      "Initial shape: (42, 16, 1628, 1628)\n",
      "Final shape: (42, 16, 19, 1625)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/477_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 148.npy\n",
      "n_context_tokens = 417, n_prompt_tokens = 386\n",
      "Initial shape: (42, 16, 420, 420)\n",
      "Final shape: (42, 16, 47, 417)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/148_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 606.npy\n",
      "n_context_tokens = 921, n_prompt_tokens = 917\n",
      "Initial shape: (42, 16, 924, 924)\n",
      "Final shape: (42, 16, 20, 921)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/606_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 545.npy\n",
      "n_context_tokens = 1587, n_prompt_tokens = 1563\n",
      "Initial shape: (42, 16, 1590, 1590)\n",
      "Final shape: (42, 16, 40, 1587)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/545_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 345.npy\n",
      "n_context_tokens = 392, n_prompt_tokens = 389\n",
      "Initial shape: (42, 16, 395, 395)\n",
      "Final shape: (42, 16, 19, 392)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/345_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 147.npy\n",
      "n_context_tokens = 925, n_prompt_tokens = 917\n",
      "Initial shape: (42, 16, 928, 928)\n",
      "Final shape: (42, 16, 24, 925)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/147_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 237.npy\n",
      "n_context_tokens = 983, n_prompt_tokens = 981\n",
      "Initial shape: (42, 16, 986, 986)\n",
      "Final shape: (42, 16, 18, 983)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/237_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 279.npy\n",
      "n_context_tokens = 1573, n_prompt_tokens = 1525\n",
      "Initial shape: (42, 16, 1577, 1577)\n",
      "Final shape: (42, 16, 64, 1573)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/279_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 422.npy\n",
      "n_context_tokens = 1913, n_prompt_tokens = 1909\n",
      "Initial shape: (42, 16, 1916, 1916)\n",
      "Final shape: (42, 16, 20, 1913)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/422_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 673.npy\n",
      "n_context_tokens = 1442, n_prompt_tokens = 1427\n",
      "Initial shape: (42, 16, 1445, 1445)\n",
      "Final shape: (42, 16, 31, 1442)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/673_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 65.npy\n",
      "n_context_tokens = 563, n_prompt_tokens = 560\n",
      "Initial shape: (42, 16, 566, 566)\n",
      "Final shape: (42, 16, 19, 563)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/65_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 234.npy\n",
      "n_context_tokens = 1377, n_prompt_tokens = 1351\n",
      "Initial shape: (42, 16, 1380, 1380)\n",
      "Final shape: (42, 16, 42, 1377)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/234_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 31.npy\n",
      "n_context_tokens = 1594, n_prompt_tokens = 1591\n",
      "Initial shape: (42, 16, 1597, 1597)\n",
      "Final shape: (42, 16, 19, 1594)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/31_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 350.npy\n",
      "n_context_tokens = 1491, n_prompt_tokens = 1461\n",
      "Initial shape: (42, 16, 1494, 1494)\n",
      "Final shape: (42, 16, 46, 1491)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/350_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 356.npy\n",
      "n_context_tokens = 468, n_prompt_tokens = 415\n",
      "Initial shape: (42, 16, 471, 471)\n",
      "Final shape: (42, 16, 69, 468)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/356_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 500.npy\n",
      "n_context_tokens = 438, n_prompt_tokens = 428\n",
      "Initial shape: (42, 16, 441, 441)\n",
      "Final shape: (42, 16, 26, 438)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/500_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 71.npy\n",
      "n_context_tokens = 1664, n_prompt_tokens = 1648\n",
      "Initial shape: (42, 16, 1667, 1667)\n",
      "Final shape: (42, 16, 32, 1664)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/71_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 622.npy\n",
      "n_context_tokens = 321, n_prompt_tokens = 304\n",
      "Initial shape: (42, 16, 324, 324)\n",
      "Final shape: (42, 16, 33, 321)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/622_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 448.npy\n",
      "n_context_tokens = 1415, n_prompt_tokens = 1398\n",
      "Initial shape: (42, 16, 1418, 1418)\n",
      "Final shape: (42, 16, 33, 1415)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/448_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 620.npy\n",
      "n_context_tokens = 928, n_prompt_tokens = 925\n",
      "Initial shape: (42, 16, 931, 931)\n",
      "Final shape: (42, 16, 19, 928)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/620_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 297.npy\n",
      "n_context_tokens = 1673, n_prompt_tokens = 1598\n",
      "Initial shape: (42, 16, 1677, 1677)\n",
      "Final shape: (42, 16, 91, 1673)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/297_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 397.npy\n",
      "n_context_tokens = 346, n_prompt_tokens = 341\n",
      "Initial shape: (42, 16, 349, 349)\n",
      "Final shape: (42, 16, 21, 346)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/397_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 377.npy\n",
      "n_context_tokens = 1642, n_prompt_tokens = 1640\n",
      "Initial shape: (42, 16, 1645, 1645)\n",
      "Final shape: (42, 16, 18, 1642)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/377_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 260.npy\n",
      "n_context_tokens = 1488, n_prompt_tokens = 1486\n",
      "Initial shape: (42, 16, 1491, 1491)\n",
      "Final shape: (42, 16, 18, 1488)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/260_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 470.npy\n",
      "n_context_tokens = 1530, n_prompt_tokens = 1504\n",
      "Initial shape: (42, 16, 1533, 1533)\n",
      "Final shape: (42, 16, 42, 1530)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/470_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 533.npy\n",
      "n_context_tokens = 758, n_prompt_tokens = 751\n",
      "Initial shape: (42, 16, 761, 761)\n",
      "Final shape: (42, 16, 23, 758)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/533_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 119.npy\n",
      "n_context_tokens = 1383, n_prompt_tokens = 1366\n",
      "Initial shape: (42, 16, 1386, 1386)\n",
      "Final shape: (42, 16, 33, 1383)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/119_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 489.npy\n",
      "n_context_tokens = 1513, n_prompt_tokens = 1510\n",
      "Initial shape: (42, 16, 1516, 1516)\n",
      "Final shape: (42, 16, 19, 1513)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/489_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 421.npy\n",
      "n_context_tokens = 1582, n_prompt_tokens = 1545\n",
      "Initial shape: (42, 16, 1585, 1585)\n",
      "Final shape: (42, 16, 53, 1582)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/421_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 49.npy\n",
      "n_context_tokens = 1569, n_prompt_tokens = 1566\n",
      "Initial shape: (42, 16, 1572, 1572)\n",
      "Final shape: (42, 16, 19, 1569)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/49_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 17.npy\n",
      "n_context_tokens = 2080, n_prompt_tokens = 2063\n",
      "Initial shape: (42, 16, 2083, 2083)\n",
      "Final shape: (42, 16, 33, 2080)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/17_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 661.npy\n",
      "n_context_tokens = 336, n_prompt_tokens = 328\n",
      "Initial shape: (42, 16, 339, 339)\n",
      "Final shape: (42, 16, 24, 336)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/661_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 594.npy\n",
      "n_context_tokens = 782, n_prompt_tokens = 774\n",
      "Initial shape: (42, 16, 785, 785)\n",
      "Final shape: (42, 16, 24, 782)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/594_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 582.npy\n",
      "n_context_tokens = 308, n_prompt_tokens = 291\n",
      "Initial shape: (42, 16, 311, 311)\n",
      "Final shape: (42, 16, 33, 308)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/582_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 418.npy\n",
      "n_context_tokens = 872, n_prompt_tokens = 851\n",
      "Initial shape: (42, 16, 875, 875)\n",
      "Final shape: (42, 16, 37, 872)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/418_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 128.npy\n",
      "n_context_tokens = 1608, n_prompt_tokens = 1606\n",
      "Initial shape: (42, 16, 1611, 1611)\n",
      "Final shape: (42, 16, 18, 1608)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/128_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 621.npy\n",
      "n_context_tokens = 836, n_prompt_tokens = 833\n",
      "Initial shape: (42, 16, 839, 839)\n",
      "Final shape: (42, 16, 19, 836)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/621_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 307.npy\n",
      "n_context_tokens = 1787, n_prompt_tokens = 1616\n",
      "Initial shape: (42, 16, 1791, 1791)\n",
      "Final shape: (42, 16, 187, 1787)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/307_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 226.npy\n",
      "n_context_tokens = 1501, n_prompt_tokens = 1498\n",
      "Initial shape: (42, 16, 1504, 1504)\n",
      "Final shape: (42, 16, 19, 1501)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/226_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 84.npy\n",
      "n_context_tokens = 965, n_prompt_tokens = 948\n",
      "Initial shape: (42, 16, 968, 968)\n",
      "Final shape: (42, 16, 33, 965)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/84_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 66.npy\n",
      "n_context_tokens = 1733, n_prompt_tokens = 1693\n",
      "Initial shape: (42, 16, 1736, 1736)\n",
      "Final shape: (42, 16, 56, 1733)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/66_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 240.npy\n",
      "n_context_tokens = 1423, n_prompt_tokens = 1406\n",
      "Initial shape: (42, 16, 1426, 1426)\n",
      "Final shape: (42, 16, 33, 1423)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/240_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 436.npy\n",
      "n_context_tokens = 597, n_prompt_tokens = 593\n",
      "Initial shape: (42, 16, 600, 600)\n",
      "Final shape: (42, 16, 20, 597)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/436_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 262.npy\n",
      "n_context_tokens = 350, n_prompt_tokens = 333\n",
      "Initial shape: (42, 16, 353, 353)\n",
      "Final shape: (42, 16, 33, 350)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/262_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 531.npy\n",
      "n_context_tokens = 490, n_prompt_tokens = 488\n",
      "Initial shape: (42, 16, 493, 493)\n",
      "Final shape: (42, 16, 18, 490)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/531_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 352.npy\n",
      "n_context_tokens = 1536, n_prompt_tokens = 1514\n",
      "Initial shape: (42, 16, 1539, 1539)\n",
      "Final shape: (42, 16, 38, 1536)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/352_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 30.npy\n",
      "n_context_tokens = 412, n_prompt_tokens = 391\n",
      "Initial shape: (42, 16, 415, 415)\n",
      "Final shape: (42, 16, 37, 412)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/30_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 465.npy\n",
      "n_context_tokens = 1299, n_prompt_tokens = 1288\n",
      "Initial shape: (42, 16, 1302, 1302)\n",
      "Final shape: (42, 16, 27, 1299)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/465_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 629.npy\n",
      "n_context_tokens = 433, n_prompt_tokens = 428\n",
      "Initial shape: (42, 16, 436, 436)\n",
      "Final shape: (42, 16, 21, 433)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/629_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 181.npy\n",
      "n_context_tokens = 1045, n_prompt_tokens = 1025\n",
      "Initial shape: (42, 16, 1048, 1048)\n",
      "Final shape: (42, 16, 36, 1045)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/181_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 413.npy\n",
      "n_context_tokens = 1215, n_prompt_tokens = 1212\n",
      "Initial shape: (42, 16, 1218, 1218)\n",
      "Final shape: (42, 16, 19, 1215)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/413_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 403.npy\n",
      "n_context_tokens = 546, n_prompt_tokens = 516\n",
      "Initial shape: (42, 16, 549, 549)\n",
      "Final shape: (42, 16, 46, 546)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/403_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 357.npy\n",
      "n_context_tokens = 1822, n_prompt_tokens = 1783\n",
      "Initial shape: (42, 16, 1825, 1825)\n",
      "Final shape: (42, 16, 55, 1822)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/357_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 529.npy\n",
      "n_context_tokens = 1668, n_prompt_tokens = 1650\n",
      "Initial shape: (42, 16, 1671, 1671)\n",
      "Final shape: (42, 16, 34, 1668)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/529_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 4.npy\n",
      "n_context_tokens = 351, n_prompt_tokens = 342\n",
      "Initial shape: (42, 16, 354, 354)\n",
      "Final shape: (42, 16, 25, 351)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/4_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 568.npy\n",
      "n_context_tokens = 1004, n_prompt_tokens = 925\n",
      "Initial shape: (42, 16, 1007, 1007)\n",
      "Final shape: (42, 16, 95, 1004)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/568_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 35.npy\n",
      "n_context_tokens = 457, n_prompt_tokens = 455\n",
      "Initial shape: (42, 16, 460, 460)\n",
      "Final shape: (42, 16, 18, 457)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/35_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 643.npy\n",
      "n_context_tokens = 1540, n_prompt_tokens = 1538\n",
      "Initial shape: (42, 16, 1543, 1543)\n",
      "Final shape: (42, 16, 18, 1540)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/643_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 3.npy\n",
      "n_context_tokens = 605, n_prompt_tokens = 596\n",
      "Initial shape: (42, 16, 608, 608)\n",
      "Final shape: (42, 16, 25, 605)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/3_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 114.npy\n",
      "n_context_tokens = 324, n_prompt_tokens = 320\n",
      "Initial shape: (42, 16, 327, 327)\n",
      "Final shape: (42, 16, 20, 324)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/114_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 109.npy\n",
      "n_context_tokens = 712, n_prompt_tokens = 702\n",
      "Initial shape: (42, 16, 715, 715)\n",
      "Final shape: (42, 16, 26, 712)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/109_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 336.npy\n",
      "n_context_tokens = 1507, n_prompt_tokens = 1500\n",
      "Initial shape: (42, 16, 1510, 1510)\n",
      "Final shape: (42, 16, 23, 1507)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/336_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 264.npy\n",
      "n_context_tokens = 465, n_prompt_tokens = 423\n",
      "Initial shape: (42, 16, 468, 468)\n",
      "Final shape: (42, 16, 58, 465)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/264_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 366.npy\n",
      "n_context_tokens = 1787, n_prompt_tokens = 1759\n",
      "Initial shape: (42, 16, 1790, 1790)\n",
      "Final shape: (42, 16, 44, 1787)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/366_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 73.npy\n",
      "n_context_tokens = 1444, n_prompt_tokens = 1441\n",
      "Initial shape: (42, 16, 1447, 1447)\n",
      "Final shape: (42, 16, 19, 1444)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/73_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 600.npy\n",
      "n_context_tokens = 440, n_prompt_tokens = 423\n",
      "Initial shape: (42, 16, 443, 443)\n",
      "Final shape: (42, 16, 33, 440)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/600_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 669.npy\n",
      "n_context_tokens = 642, n_prompt_tokens = 638\n",
      "Initial shape: (42, 16, 645, 645)\n",
      "Final shape: (42, 16, 20, 642)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/669_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 303.npy\n",
      "n_context_tokens = 1613, n_prompt_tokens = 1603\n",
      "Initial shape: (42, 16, 1616, 1616)\n",
      "Final shape: (42, 16, 26, 1613)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/303_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 263.npy\n",
      "n_context_tokens = 1181, n_prompt_tokens = 1164\n",
      "Initial shape: (42, 16, 1184, 1184)\n",
      "Final shape: (42, 16, 33, 1181)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/263_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 379.npy\n",
      "n_context_tokens = 1645, n_prompt_tokens = 1641\n",
      "Initial shape: (42, 16, 1648, 1648)\n",
      "Final shape: (42, 16, 20, 1645)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/379_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 150.npy\n",
      "n_context_tokens = 968, n_prompt_tokens = 951\n",
      "Initial shape: (42, 16, 971, 971)\n",
      "Final shape: (42, 16, 33, 968)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/150_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 67.npy\n",
      "n_context_tokens = 1143, n_prompt_tokens = 1112\n",
      "Initial shape: (42, 16, 1146, 1146)\n",
      "Final shape: (42, 16, 47, 1143)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/67_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 588.npy\n",
      "n_context_tokens = 1534, n_prompt_tokens = 1499\n",
      "Initial shape: (42, 16, 1537, 1537)\n",
      "Final shape: (42, 16, 51, 1534)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/588_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 81.npy\n",
      "n_context_tokens = 471, n_prompt_tokens = 445\n",
      "Initial shape: (42, 16, 474, 474)\n",
      "Final shape: (42, 16, 42, 471)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/81_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 12.npy\n",
      "n_context_tokens = 1134, n_prompt_tokens = 1117\n",
      "Initial shape: (42, 16, 1137, 1137)\n",
      "Final shape: (42, 16, 33, 1134)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/12_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 243.npy\n",
      "n_context_tokens = 1538, n_prompt_tokens = 1491\n",
      "Initial shape: (42, 16, 1541, 1541)\n",
      "Final shape: (42, 16, 63, 1538)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/243_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 123.npy\n",
      "n_context_tokens = 1036, n_prompt_tokens = 1024\n",
      "Initial shape: (42, 16, 1039, 1039)\n",
      "Final shape: (42, 16, 28, 1036)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/123_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 497.npy\n",
      "n_context_tokens = 319, n_prompt_tokens = 310\n",
      "Initial shape: (42, 16, 322, 322)\n",
      "Final shape: (42, 16, 25, 319)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/497_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 69.npy\n",
      "n_context_tokens = 619, n_prompt_tokens = 616\n",
      "Initial shape: (42, 16, 622, 622)\n",
      "Final shape: (42, 16, 19, 619)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/69_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 159.npy\n",
      "n_context_tokens = 445, n_prompt_tokens = 371\n",
      "Initial shape: (42, 16, 448, 448)\n",
      "Final shape: (42, 16, 90, 445)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/159_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 292.npy\n",
      "n_context_tokens = 350, n_prompt_tokens = 335\n",
      "Initial shape: (42, 16, 353, 353)\n",
      "Final shape: (42, 16, 31, 350)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/292_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 1.npy\n",
      "n_context_tokens = 381, n_prompt_tokens = 364\n",
      "Initial shape: (42, 16, 384, 384)\n",
      "Final shape: (42, 16, 33, 381)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/1_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 142.npy\n",
      "n_context_tokens = 554, n_prompt_tokens = 459\n",
      "Initial shape: (42, 16, 557, 557)\n",
      "Final shape: (42, 16, 111, 554)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/142_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 445.npy\n",
      "n_context_tokens = 1424, n_prompt_tokens = 1385\n",
      "Initial shape: (42, 16, 1427, 1427)\n",
      "Final shape: (42, 16, 55, 1424)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/445_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 289.npy\n",
      "n_context_tokens = 1414, n_prompt_tokens = 1391\n",
      "Initial shape: (42, 16, 1417, 1417)\n",
      "Final shape: (42, 16, 39, 1414)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/289_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 227.npy\n",
      "n_context_tokens = 461, n_prompt_tokens = 430\n",
      "Initial shape: (42, 16, 464, 464)\n",
      "Final shape: (42, 16, 47, 461)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/227_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 431.npy\n",
      "n_context_tokens = 618, n_prompt_tokens = 601\n",
      "Initial shape: (42, 16, 621, 621)\n",
      "Final shape: (42, 16, 33, 618)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/431_reduced.npy\n",
      "\n",
      "\n",
      "\n",
      "att_file: 21.npy\n",
      "n_context_tokens = 1142, n_prompt_tokens = 1140\n",
      "Initial shape: (42, 16, 1145, 1145)\n",
      "Final shape: (42, 16, 18, 1142)\n",
      "Array uploaded to gs://hallucination-detection/test_attensions/21_reduced.npy\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "\n",
    "    att_file = f\"{row['gpt_index']}.npy\"\n",
    "    print(f\"att_file: {att_file}\")\n",
    "\n",
    "    n_context_tokens = len(row['hallu_tokens'])\n",
    "    n_prompt_tokens = row['prompt_length']\n",
    "\n",
    "    print(f\"{n_context_tokens = }, {n_prompt_tokens = }\")\n",
    "\n",
    "    att_path = os.path.join(ATT_PATH, att_file)\n",
    "    att_tensor = prep_att_pipe(att_path, n_context_tokens, n_prompt_tokens, OFFSET_SIZE)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    np.save(buffer, att_tensor)\n",
    "    buffer.seek(0)  \n",
    "\n",
    "    blob_name = os.path.join(\"test_attensions\", f\"{row['gpt_index']}_reduced.npy\")\n",
    "\n",
    "    try:\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob.upload_from_file(buffer, content_type='application/octet-stream')\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading {blob_name}: {e}\")\n",
    "    else:\n",
    "        print(f'Array uploaded to gs://{bucket_name}/{blob_name}')\n",
    "        \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attensions/\n",
      "attensions/134_reduced.npy\n",
      "attensions/143_reduced.npy\n",
      "attensions/218_reduced.npy\n",
      "attensions/219_reduced.npy\n",
      "attensions/253_reduced.npy\n",
      "attensions/256_reduced.npy\n",
      "attensions/308_reduced.npy\n",
      "attensions/317_reduced.npy\n",
      "attensions/340_reduced.npy\n",
      "attensions/351_reduced.npy\n",
      "attensions/427_reduced.npy\n",
      "attensions/443_reduced.npy\n",
      "attensions/457_reduced.npy\n",
      "attensions/469_reduced.npy\n",
      "attensions/597_reduced.npy\n",
      "attensions/657_reduced.npy\n"
     ]
    }
   ],
   "source": [
    "f_loaded_from_bucket = bucket.list_blobs()\n",
    "for f in f_loaded_from_bucket:\n",
    "    print(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_file: 340.npy\n",
      "n_context_tokens = 335, n_prompt_tokens = 330\n",
      "Initial shape: (42, 16, 338, 338)\n",
      "Final shape: (42, 16, 8, 334)\n",
      "att_file: 443.npy\n",
      "n_context_tokens = 1674, n_prompt_tokens = 1665\n",
      "Initial shape: (42, 16, 1677, 1677)\n",
      "Final shape: (42, 16, 8, 1669)\n",
      "att_file: 218.npy\n",
      "n_context_tokens = 1493, n_prompt_tokens = 1476\n",
      "Initial shape: (42, 16, 1496, 1496)\n",
      "Final shape: (42, 16, 8, 1480)\n",
      "att_file: 253.npy\n",
      "n_context_tokens = 1492, n_prompt_tokens = 1469\n",
      "Initial shape: (42, 16, 1495, 1495)\n",
      "Final shape: (42, 16, 8, 1473)\n",
      "att_file: 597.npy\n",
      "n_context_tokens = 532, n_prompt_tokens = 528\n",
      "Initial shape: (42, 16, 535, 535)\n",
      "Final shape: (42, 16, 8, 532)\n",
      "att_file: 457.npy\n",
      "n_context_tokens = 1101, n_prompt_tokens = 1081\n",
      "Initial shape: (42, 16, 1104, 1104)\n",
      "Final shape: (42, 16, 8, 1085)\n",
      "att_file: 657.npy\n",
      "n_context_tokens = 971, n_prompt_tokens = 964\n",
      "Initial shape: (42, 16, 974, 974)\n",
      "Final shape: (42, 16, 8, 968)\n",
      "att_file: 317.npy\n",
      "n_context_tokens = 542, n_prompt_tokens = 537\n",
      "Initial shape: (42, 16, 545, 545)\n",
      "Final shape: (42, 16, 8, 541)\n",
      "att_file: 308.npy\n",
      "n_context_tokens = 1587, n_prompt_tokens = 1573\n",
      "Initial shape: (42, 16, 1590, 1590)\n",
      "Final shape: (42, 16, 8, 1577)\n",
      "att_file: 256.npy\n",
      "n_context_tokens = 652, n_prompt_tokens = 646\n",
      "Initial shape: (42, 16, 655, 655)\n",
      "Final shape: (42, 16, 8, 650)\n",
      "att_file: 219.npy\n",
      "n_context_tokens = 478, n_prompt_tokens = 468\n",
      "Initial shape: (42, 16, 481, 481)\n",
      "Final shape: (42, 16, 8, 472)\n",
      "att_file: 134.npy\n",
      "n_context_tokens = 3024, n_prompt_tokens = 3000\n",
      "Initial shape: (42, 16, 3027, 3027)\n",
      "Final shape: (42, 16, 8, 3004)\n",
      "att_file: 469.npy\n",
      "n_context_tokens = 595, n_prompt_tokens = 581\n",
      "Initial shape: (42, 16, 598, 598)\n",
      "Final shape: (42, 16, 8, 585)\n",
      "att_file: 143.npy\n",
      "n_context_tokens = 329, n_prompt_tokens = 312\n",
      "Initial shape: (42, 16, 332, 332)\n",
      "Final shape: (42, 16, 8, 316)\n",
      "att_file: 427.npy\n",
      "n_context_tokens = 1549, n_prompt_tokens = 1547\n",
      "Initial shape: (42, 16, 1552, 1552)\n",
      "Final shape: (42, 16, 8, 1551)\n",
      "att_file: 351.npy\n",
      "n_context_tokens = 363, n_prompt_tokens = 346\n",
      "Initial shape: (42, 16, 366, 366)\n",
      "Final shape: (42, 16, 8, 350)\n",
      "att_file: 47.npy\n",
      "n_context_tokens = 1571, n_prompt_tokens = 1540\n",
      "Initial shape: (42, 16, 1574, 1574)\n",
      "Final shape: (42, 16, 8, 1544)\n",
      "att_file: 510.npy\n",
      "n_context_tokens = 524, n_prompt_tokens = 519\n",
      "Initial shape: (42, 16, 527, 527)\n",
      "Final shape: (42, 16, 8, 523)\n",
      "att_file: 566.npy\n",
      "n_context_tokens = 830, n_prompt_tokens = 813\n",
      "Initial shape: (42, 16, 833, 833)\n",
      "Final shape: (42, 16, 8, 817)\n",
      "att_file: 177.npy\n",
      "n_context_tokens = 1476, n_prompt_tokens = 1471\n",
      "Initial shape: (42, 16, 1479, 1479)\n",
      "Final shape: (42, 16, 8, 1475)\n",
      "att_file: 149.npy\n",
      "n_context_tokens = 344, n_prompt_tokens = 327\n",
      "Initial shape: (42, 16, 347, 347)\n",
      "Final shape: (42, 16, 8, 331)\n",
      "att_file: 89.npy\n",
      "n_context_tokens = 2737, n_prompt_tokens = 2705\n",
      "Initial shape: (42, 16, 2740, 2740)\n",
      "Final shape: (42, 16, 8, 2709)\n",
      "att_file: 441.npy\n",
      "n_context_tokens = 362, n_prompt_tokens = 333\n",
      "Initial shape: (42, 16, 365, 365)\n",
      "Final shape: (42, 16, 8, 337)\n",
      "att_file: 105.npy\n",
      "n_context_tokens = 1577, n_prompt_tokens = 1532\n",
      "Initial shape: (42, 16, 1580, 1580)\n",
      "Final shape: (42, 16, 8, 1536)\n",
      "att_file: 572.npy\n",
      "n_context_tokens = 1205, n_prompt_tokens = 1178\n",
      "Initial shape: (42, 16, 1208, 1208)\n",
      "Final shape: (42, 16, 8, 1182)\n",
      "att_file: 637.npy\n",
      "n_context_tokens = 349, n_prompt_tokens = 310\n",
      "Initial shape: (42, 16, 352, 352)\n",
      "Final shape: (42, 16, 8, 314)\n",
      "att_file: 639.npy\n",
      "n_context_tokens = 481, n_prompt_tokens = 464\n",
      "Initial shape: (42, 16, 484, 484)\n",
      "Final shape: (42, 16, 8, 468)\n",
      "att_file: 363.npy\n",
      "n_context_tokens = 642, n_prompt_tokens = 638\n",
      "Initial shape: (42, 16, 645, 645)\n",
      "Final shape: (42, 16, 8, 642)\n",
      "att_file: 540.npy\n",
      "n_context_tokens = 403, n_prompt_tokens = 398\n",
      "Initial shape: (42, 16, 405, 405)\n",
      "Final shape: (42, 16, 8, 402)\n",
      "att_file: 245.npy\n",
      "n_context_tokens = 1396, n_prompt_tokens = 1380\n",
      "Initial shape: (42, 16, 1399, 1399)\n",
      "Final shape: (42, 16, 8, 1384)\n",
      "att_file: 136.npy\n",
      "n_context_tokens = 951, n_prompt_tokens = 949\n",
      "Initial shape: (42, 16, 954, 954)\n",
      "Final shape: (42, 16, 8, 953)\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    att_file = f\"{row['gpt_index']}.npy\"\n",
    "    print(f\"att_file: {att_file}\")\n",
    "\n",
    "    n_context_tokens = len(row['hallu_tokens'])\n",
    "    n_prompt_tokens = row['prompt_length']\n",
    "\n",
    "    Y.append(row['hallu_tokens'][n_prompt_tokens - OFFSET_SIZE: n_prompt_tokens + FIRST_N_TOKENS])\n",
    "\n",
    "    print(f\"{n_context_tokens = }, {n_prompt_tokens = }\")\n",
    "\n",
    "    att_path = os.path.join(ATT_PATH, att_file)\n",
    "    att_tensor = prep_att_pipe(att_path, n_prompt_tokens + FIRST_N_TOKENS, n_prompt_tokens, OFFSET_SIZE)\n",
    "\n",
    "    X.append(att_tensor)\n",
    "\n",
    "    if i == 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'hallucination-detection'\n",
    "bucket = client.bucket(bucket_name)\n",
    "\n",
    "blob_f = bucket.blob('train_attensions/0_reduced.npy').download_to_filename('0_reduced.npy')\n",
    "att = np.load('0_reduced.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "for y in Y:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
