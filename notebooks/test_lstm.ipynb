{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from collections import Counter\n",
    "import random\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/tscratch/people/plgmatpat/miniconda3/envs/hallu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import lightning as L\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchmetrics.classification import AUROC\n",
    "from lightning.pytorch.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'gemma_att'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/net/tscratch/people/plgmatpat'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df = None\n",
    "\n",
    "for f_ in os.listdir(os.path.join(EXP_NAME)):\n",
    "    \n",
    "    if f_.startswith('attension'):\n",
    "\n",
    "        if context_df is None:\n",
    "            context_df = pd.read_parquet(os.path.join(EXP_NAME, f_))\n",
    "        else:\n",
    "            context_df = pd.concat((context_df, pd.read_parquet(os.path.join(EXP_NAME, f_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "cnndm          19400\n",
       "nq              8030\n",
       "xsum            7776\n",
       "poquad_v2       6247\n",
       "hotpotqa_en     3121\n",
       "bioask          3056\n",
       "hotpotqa_pl     2208\n",
       "polqa           1869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_df['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df = context_df[context_df['dataset'].isin(['xsum', 'nq'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    14012\n",
       "1     1794\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HalluDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        _, (hn, _) = self.lstm(x)  # hn is (num_layers, batch_size, hidden_dim)\n",
    "        out = self.fc(hn[-1])  # Use the last layer's hidden state\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(L.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, lr=5e-4, num_layers=1, cls_weight=None):\n",
    "        super().__init__()\n",
    "        self.model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers=num_layers)\n",
    "        self.criterion = nn.BCEWithLogitsLoss(pos_weight=cls_weight)\n",
    "        self.lr = lr\n",
    "\n",
    "        self.test_dataloader = None\n",
    "\n",
    "        # AUROC metric for binary classification\n",
    "        self.train_auc = AUROC(task=\"binary\")\n",
    "        self.val_auc = AUROC(task=\"binary\")\n",
    "        self.test_auc = AUROC(task=\"binary\")\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "        preds = self(data)\n",
    "        labels = labels.view(-1, 1).float() \n",
    "\n",
    "        if preds.size() != labels.size():\n",
    "            preds = preds.view_as(labels)\n",
    "\n",
    "        loss = self.criterion(preds, labels)\n",
    "        # Calculate AUC during training\n",
    "        prob = torch.sigmoid(preds)\n",
    "        auc = self.train_auc(prob, labels)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_auc\", auc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "        preds = self(data)\n",
    "        labels = labels.view(-1, 1).float() \n",
    "\n",
    "\n",
    "        loss = self.criterion(preds, labels)\n",
    "        # Calculate AUC during validation\n",
    "        prob = torch.sigmoid(preds)\n",
    "        auc = self.val_auc(prob, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_auc\", auc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "        preds = self(data)\n",
    "        labels = labels.view(-1, 1).float() \n",
    "        loss = self.criterion(preds, labels)\n",
    "        # Calculate AUC during validation\n",
    "        prob = torch.sigmoid(preds)\n",
    "        auc = self.val_auc(prob, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_auc\", auc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        for i, batch in enumerate(self.test_dataloader):\n",
    "            batch = self.transfer_batch_to_device(batch, self.device, 0)\n",
    "            self.test_step(batch, i)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [col for col in context_df.columns if col not in ['dataset', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from collections import Counter\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_VAL = True\n",
    "INPUT_DIM = 16\n",
    "GEMMA_LAYERS = 42\n",
    "HIDDEN_DIM = 64\n",
    "OUTPUT_DIM = 1\n",
    "NUM_LSTM_LAYERS = 2\n",
    "LR = 1e-3\n",
    "MAX_EPOCHS = 25\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger \n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/tscratch/people/plgmatpat/miniconda3/envs/hallu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 10, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatpat\u001b[0m (\u001b[33mhallucination\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241208_111241-oe1hlx4t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hallucination/hallu_project/runs/oe1hlx4t' target=\"_blank\">tough-grass-23</a></strong> to <a href='https://wandb.ai/hallucination/hallu_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hallucination/hallu_project' target=\"_blank\">https://wandb.ai/hallucination/hallu_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hallucination/hallu_project/runs/oe1hlx4t' target=\"_blank\">https://wandb.ai/hallucination/hallu_project/runs/oe1hlx4t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model     | LSTMModel         | 54.3 K | train\n",
      "1 | criterion | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_auc | BinaryAUROC       | 0      | train\n",
      "3 | val_auc   | BinaryAUROC       | 0      | train\n",
      "4 | test_auc  | BinaryAUROC       | 0      | train\n",
      "--------------------------------------------------------\n",
      "54.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "54.3 K    Total params\n",
      "0.217     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/tscratch/people/plgmatpat/miniconda3/envs/hallu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 10, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/tscratch/people/plgmatpat/miniconda3/envs/hallu/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 7/7 [00:01<00:00,  4.14it/s, v_num=lx4t, val_loss=1.240, val_auc=0.532, train_loss=1.240, train_auc=0.497]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  2.46it/s, v_num=lx4t, val_loss=1.240, val_auc=0.529, train_loss=1.240, train_auc=0.526, test_loss=1.320, test_auc=0.387]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 7/7 [00:02<00:00,  2.39it/s, v_num=lx4t, val_loss=1.230, val_auc=0.533, train_loss=1.240, train_auc=0.526, test_loss=1.340, test_auc=0.389]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  2.62it/s, v_num=lx4t, val_loss=1.230, val_auc=0.538, train_loss=1.240, train_auc=0.534, test_loss=1.340, test_auc=0.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  2.57it/s, v_num=lx4t, val_loss=1.230, val_auc=0.552, train_loss=1.230, train_auc=0.548, test_loss=1.340, test_auc=0.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 7/7 [00:02<00:00,  2.67it/s, v_num=lx4t, val_loss=1.230, val_auc=0.556, train_loss=1.230, train_auc=0.575, test_loss=1.340, test_auc=0.389]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 1.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 7/7 [00:02<00:00,  2.61it/s, v_num=lx4t, val_loss=1.230, val_auc=0.553, train_loss=1.230, train_auc=0.559, test_loss=1.350, test_auc=0.387]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 7/7 [00:02<00:00,  2.57it/s, v_num=lx4t, val_loss=1.220, val_auc=0.567, train_loss=1.220, train_auc=0.615, test_loss=1.360, test_auc=0.385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 1.220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:02<00:00,  2.61it/s, v_num=lx4t, val_loss=1.220, val_auc=0.587, train_loss=1.190, train_auc=0.634, test_loss=1.370, test_auc=0.386]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 1.218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 7/7 [00:02<00:00,  2.53it/s, v_num=lx4t, val_loss=1.220, val_auc=0.597, train_loss=1.180, train_auc=0.643, test_loss=1.380, test_auc=0.384]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 1.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 7/7 [00:02<00:00,  2.47it/s, v_num=lx4t, val_loss=1.210, val_auc=0.606, train_loss=1.180, train_auc=0.651, test_loss=1.400, test_auc=0.380]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 1.208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 7/7 [00:02<00:00,  2.55it/s, v_num=lx4t, val_loss=1.200, val_auc=0.621, train_loss=1.160, train_auc=0.679, test_loss=1.350, test_auc=0.394]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 1.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 7/7 [00:02<00:00,  2.37it/s, v_num=lx4t, val_loss=1.200, val_auc=0.625, train_loss=1.140, train_auc=0.687, test_loss=1.430, test_auc=0.378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 1.198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 7/7 [00:02<00:00,  2.47it/s, v_num=lx4t, val_loss=1.190, val_auc=0.633, train_loss=1.130, train_auc=0.699, test_loss=1.390, test_auc=0.477]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 1.189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 7/7 [00:03<00:00,  2.31it/s, v_num=lx4t, val_loss=1.180, val_auc=0.632, train_loss=1.120, train_auc=0.707, test_loss=1.310, test_auc=0.586]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 1.184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 7/7 [00:02<00:00,  2.51it/s, v_num=lx4t, val_loss=1.180, val_auc=0.644, train_loss=1.100, train_auc=0.720, test_loss=1.320, test_auc=0.576]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 7/7 [00:02<00:00,  2.46it/s, v_num=lx4t, val_loss=1.190, val_auc=0.641, train_loss=1.080, train_auc=0.729, test_loss=1.410, test_auc=0.593]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 7/7 [00:04<00:00,  1.64it/s, v_num=lx4t, val_loss=1.190, val_auc=0.641, train_loss=1.080, train_auc=0.729, test_loss=1.410, test_auc=0.593]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 85.51it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_auc            0.5270460844039917\n",
      "        test_loss            1.354711651802063\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Test Loss: 1.354711651802063, Test AUC: 0.5270460844039917\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>test_auc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▄▄█▄▂▂▇▇█▆▆</td></tr><tr><td>test_loss</td><td>▁▂▂▂▂▂▂▂▂▃▃▂▂▃▄▂▃▁▃█▇▁▃▄▂▂</td></tr><tr><td>train_auc</td><td>▁▂▂▂▃▃▃▄▅▅▅▆▆▆▇▇▇▇▇█▇████</td></tr><tr><td>train_loss</td><td>██████▇▇▇▆▅▅▅▄▄▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_auc</td><td>▁▁▁▂▂▃▂▂▃▅▅▆▆▇▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█████▇▇█▆▆▅▄▅▃▃▃▄▂▁▂▅▂▁▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>test_auc</td><td>0.52705</td></tr><tr><td>test_loss</td><td>1.35471</td></tr><tr><td>train_auc</td><td>0.72862</td></tr><tr><td>train_loss</td><td>1.08386</td></tr><tr><td>trainer/global_step</td><td>175</td></tr><tr><td>val_auc</td><td>0.64109</td></tr><tr><td>val_loss</td><td>1.19477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">tough-grass-23</strong> at: <a href='https://wandb.ai/hallucination/hallu_project/runs/oe1hlx4t' target=\"_blank\">https://wandb.ai/hallucination/hallu_project/runs/oe1hlx4t</a><br/> View project at: <a href='https://wandb.ai/hallucination/hallu_project' target=\"_blank\">https://wandb.ai/hallucination/hallu_project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241208_111241-oe1hlx4t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/tscratch/people/plgmatpat/miniconda3/envs/hallu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 10, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241208_111434-o2vo1qqe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hallucination/hallu_project/runs/o2vo1qqe' target=\"_blank\">super-rain-24</a></strong> to <a href='https://wandb.ai/hallucination/hallu_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hallucination/hallu_project' target=\"_blank\">https://wandb.ai/hallucination/hallu_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hallucination/hallu_project/runs/o2vo1qqe' target=\"_blank\">https://wandb.ai/hallucination/hallu_project/runs/o2vo1qqe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model     | LSTMModel         | 54.3 K | train\n",
      "1 | criterion | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_auc | BinaryAUROC       | 0      | train\n",
      "3 | val_auc   | BinaryAUROC       | 0      | train\n",
      "4 | test_auc  | BinaryAUROC       | 0      | train\n",
      "--------------------------------------------------------\n",
      "54.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "54.3 K    Total params\n",
      "0.217     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/tscratch/people/plgmatpat/miniconda3/envs/hallu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 10, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/tscratch/people/plgmatpat/miniconda3/envs/hallu/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 7/7 [00:01<00:00,  4.34it/s, v_num=1qqe, val_loss=1.200, val_auc=0.598, train_loss=1.210, train_auc=0.592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  2.45it/s, v_num=1qqe, val_loss=1.180, val_auc=0.607, train_loss=1.180, train_auc=0.637, test_loss=1.160, test_auc=0.491]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.018 >= min_delta = 0.0. New best score: 1.181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  2.50it/s, v_num=1qqe, val_loss=1.160, val_auc=0.618, train_loss=1.150, train_auc=0.649, test_loss=1.260, test_auc=0.492]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 1.164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  2.48it/s, v_num=1qqe, val_loss=1.160, val_auc=0.626, train_loss=1.150, train_auc=0.653, test_loss=1.200, test_auc=0.498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 1.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 7/7 [00:02<00:00,  2.42it/s, v_num=1qqe, val_loss=1.150, val_auc=0.639, train_loss=1.140, train_auc=0.660, test_loss=1.180, test_auc=0.501]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 1.152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 7/7 [00:02<00:00,  2.45it/s, v_num=1qqe, val_loss=1.150, val_auc=0.651, train_loss=1.140, train_auc=0.668, test_loss=1.170, test_auc=0.506]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 1.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 7/7 [00:02<00:00,  2.55it/s, v_num=1qqe, val_loss=1.140, val_auc=0.665, train_loss=1.140, train_auc=0.675, test_loss=1.180, test_auc=0.511]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 1.142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 7/7 [00:02<00:00,  2.65it/s, v_num=1qqe, val_loss=1.130, val_auc=0.678, train_loss=1.130, train_auc=0.684, test_loss=1.170, test_auc=0.522]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 1.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:03<00:00,  2.21it/s, v_num=1qqe, val_loss=1.120, val_auc=0.692, train_loss=1.120, train_auc=0.691, test_loss=1.160, test_auc=0.528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.0. New best score: 1.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 7/7 [00:02<00:00,  2.44it/s, v_num=1qqe, val_loss=1.100, val_auc=0.700, train_loss=1.110, train_auc=0.697, test_loss=1.160, test_auc=0.543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.018 >= min_delta = 0.0. New best score: 1.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 7/7 [00:02<00:00,  2.44it/s, v_num=1qqe, val_loss=1.100, val_auc=0.735, train_loss=1.110, train_auc=0.698, test_loss=1.230, test_auc=0.535]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 1.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 7/7 [00:02<00:00,  2.37it/s, v_num=1qqe, val_loss=1.090, val_auc=0.738, train_loss=1.110, train_auc=0.709, test_loss=1.260, test_auc=0.520]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 1.092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 7/7 [00:02<00:00,  2.39it/s, v_num=1qqe, val_loss=1.080, val_auc=0.738, train_loss=1.110, train_auc=0.714, test_loss=1.190, test_auc=0.551]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 1.083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 7/7 [00:02<00:00,  2.37it/s, v_num=1qqe, val_loss=1.080, val_auc=0.742, train_loss=1.110, train_auc=0.718, test_loss=1.180, test_auc=0.552]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 7/7 [00:02<00:00,  2.50it/s, v_num=1qqe, val_loss=1.080, val_auc=0.746, train_loss=1.100, train_auc=0.720, test_loss=1.170, test_auc=0.551]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 1.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 7/7 [00:02<00:00,  2.41it/s, v_num=1qqe, val_loss=1.060, val_auc=0.741, train_loss=1.090, train_auc=0.722, test_loss=1.180, test_auc=0.551]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.0. New best score: 1.064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 7/7 [00:02<00:00,  2.39it/s, v_num=1qqe, val_loss=1.050, val_auc=0.751, train_loss=1.080, train_auc=0.729, test_loss=1.180, test_auc=0.553]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 1.049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 7/7 [00:03<00:00,  2.32it/s, v_num=1qqe, val_loss=1.040, val_auc=0.758, train_loss=1.070, train_auc=0.730, test_loss=1.200, test_auc=0.555]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 1.037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 7/7 [00:03<00:00,  2.32it/s, v_num=1qqe, val_loss=1.030, val_auc=0.762, train_loss=1.050, train_auc=0.746, test_loss=1.170, test_auc=0.550]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 1.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 7/7 [00:02<00:00,  2.38it/s, v_num=1qqe, val_loss=1.020, val_auc=0.767, train_loss=1.030, train_auc=0.757, test_loss=1.220, test_auc=0.533]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 1.021\n",
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 7/7 [00:04<00:00,  1.55it/s, v_num=1qqe, val_loss=1.020, val_auc=0.767, train_loss=1.030, train_auc=0.757, test_loss=1.220, test_auc=0.533]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 73.39it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_auc            0.5456796884536743\n",
      "        test_loss            1.154437780380249\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Test Loss: 1.154437780380249, Test AUC: 0.5456796884536743\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>test_auc</td><td>▁▁▁▂▂▃▃▄▅▇▆▄▇█▇▇████▇▇▇▆▇▇</td></tr><tr><td>test_loss</td><td>▂██▄▃▂▃▂▁▂▆█▄▃▂▃▃▄▅▄▂▁▁▅▁▁</td></tr><tr><td>train_auc</td><td>▁▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>val_auc</td><td>▁▁▂▂▂▃▃▄▄▅▅▇▇▇▇▇▇▇█████▇█</td></tr><tr><td>val_loss</td><td>█▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▂▂▃▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>test_auc</td><td>0.54568</td></tr><tr><td>test_loss</td><td>1.15444</td></tr><tr><td>train_auc</td><td>0.75719</td></tr><tr><td>train_loss</td><td>1.02767</td></tr><tr><td>trainer/global_step</td><td>175</td></tr><tr><td>val_auc</td><td>0.76703</td></tr><tr><td>val_loss</td><td>1.0205</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-rain-24</strong> at: <a href='https://wandb.ai/hallucination/hallu_project/runs/o2vo1qqe' target=\"_blank\">https://wandb.ai/hallucination/hallu_project/runs/o2vo1qqe</a><br/> View project at: <a href='https://wandb.ai/hallucination/hallu_project' target=\"_blank\">https://wandb.ai/hallucination/hallu_project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241208_111434-o2vo1qqe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_results = []\n",
    "\n",
    "# Loop over each unique dataset\n",
    "for dataset in context_df['dataset'].unique():\n",
    "\n",
    "    # run = wandb.init(entity=dataset, project=\"hallu_project\")\n",
    "\n",
    "    in_dist_sample = context_df.loc[context_df['dataset'] != dataset]\n",
    "    out_dist_sample = context_df.loc[context_df['dataset'] == dataset]\n",
    "\n",
    "    X_train, X_test = in_dist_sample[train_cols], out_dist_sample[train_cols]\n",
    "    y_train, y_test = in_dist_sample['label'].to_numpy().astype(np.int64), out_dist_sample['label'].to_numpy().astype(np.int64)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "    counter = Counter(y_train)\n",
    "    pos_weight = torch.tensor([counter[0] / counter[1]], dtype=torch.float32)\n",
    "\n",
    "    # rus = RandomUnderSampler(random_state=42)\n",
    "    # X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train).reshape(-1, GEMMA_LAYERS, INPUT_DIM)\n",
    "    X_val = scaler.transform(X_val).reshape(-1, GEMMA_LAYERS, INPUT_DIM)\n",
    "    X_test = scaler.transform(X_test).reshape(-1, GEMMA_LAYERS, INPUT_DIM)\n",
    "\n",
    "    train_dataset = HalluDataset(X_train, y_train)\n",
    "    val_dataset = HalluDataset(X_val, y_val)\n",
    "    test_dataset = HalluDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=16)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=16)\n",
    "\n",
    "\n",
    "    model = LSTMClassifier(\n",
    "        input_dim=INPUT_DIM, \n",
    "        hidden_dim=HIDDEN_DIM, \n",
    "        output_dim=OUTPUT_DIM, \n",
    "        lr=LR, \n",
    "        num_layers=NUM_LSTM_LAYERS,\n",
    "        cls_weight=pos_weight\n",
    "    )\n",
    "\n",
    "    model.test_dataloader = test_loader\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        # name=f\"lstm_on_{dataset}\",\n",
    "        project=\"hallu_project\",\n",
    "        group=f\"lstm_hallu\",\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    wandb_logger.experiment.config.update(\n",
    "        {\n",
    "            \"trained_on\": set(context_df['dataset'].unique()) - {dataset},\n",
    "            \"tested_on\": dataset,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # wandb_logger.log()\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        log_every_n_steps=10,\n",
    "        callbacks=[EarlyStopping(\n",
    "            monitor=\"val_loss\",  # The metric to monitor\n",
    "            patience=7,          # Number of epochs with no improvement after which training will stop\n",
    "            verbose=True,        # Display a message when stopping\n",
    "            mode=\"min\",          # Minimize the monitored metric (for loss)\n",
    "        )],\n",
    "        logger=wandb_logger\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    metrics = trainer.callback_metrics\n",
    "    res = {k: v.item() for k, v in metrics.items()}\n",
    "\n",
    "    test_res = trainer.test(model, test_loader)[0]\n",
    "    print(f\"Test Loss: {test_res['test_loss']}, Test AUC: {test_res['test_auc']}\")\n",
    "\n",
    "    validation_results.append({\n",
    "        'dataset': dataset,\n",
    "        'train_loss': res['train_loss'],\n",
    "        'val_loss': res['val_loss'],\n",
    "        'test_loss': res['test_loss'],\n",
    "        'train_auc': res['train_auc'],\n",
    "        'val_auc': res['val_auc'],\n",
    "        'test_auc': res['test_auc']\n",
    "    })\n",
    "\n",
    "    wandb_logger.finalize(\"success\")\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
